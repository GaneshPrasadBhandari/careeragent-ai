{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac14c06e-e3e1-407a-96f0-e390149fd80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d294fc-4e9b-4d09-af58-a2f4be30fa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† Root established at: /Users/ganeshprasadbhandari/Documents/D_drive/clark/careeragent-ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Move up if we are inside the notebooks folder\n",
    "if Path(os.getcwd()).name == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "print(f\"üè† Root established at: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a36cc2-77b3-423f-b5ac-ce8101c8c4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è pyproject.toml already includes required deps.\n",
      "‚úÖ Batch 9 files written:\n",
      " - src/careeragent/config.py\n",
      " - src/careeragent/api/main.py\n",
      " - app/main.py\n",
      " - run_app.py\n",
      "‚úÖ Smoke imports OK.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 0) Ensure directories exist\n",
    "# -----------------------------\n",
    "(Path(\"src/careeragent\") / \"__init__.py\").parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "Path(\"src/careeragent/agents\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/agents/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "Path(\"src/careeragent/services\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/services/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "Path(\"src/careeragent/api\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/api/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "Path(\"app\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "(Path(\"src/careeragent/artifacts\") / \"runs\").mkdir(parents=True, exist_ok=True)\n",
    "(Path(\"src/careeragent/artifacts\") / \"reports\").mkdir(parents=True, exist_ok=True)\n",
    "(Path(\"src/careeragent/artifacts\") / \"exports\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) src/careeragent/config.py\n",
    "# -----------------------------\n",
    "config_py = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "\n",
    "def repo_root() -> Path:\n",
    "    \"\"\"\n",
    "    Description: Resolve repository root from within src/ package.\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: Absolute Path to repo root\n",
    "    \"\"\"\n",
    "    # src/careeragent/config.py -> src/careeragent -> src -> repo root\n",
    "    return Path(__file__).resolve().parents[2]\n",
    "\n",
    "\n",
    "def artifacts_root() -> Path:\n",
    "    \"\"\"\n",
    "    Description: Canonical artifacts root required by CareerAgent-AI (local-first).\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: Path to src/careeragent/artifacts\n",
    "    \"\"\"\n",
    "    root = Path(__file__).resolve().parents[0] / \"artifacts\"\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "    return root\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Description: Central configuration loader for CareerAgent-AI.\n",
    "    Layer: L0\n",
    "    Input: .env in repo root + environment variables\n",
    "    Output: Strongly typed settings object\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=str(repo_root() / \".env\"),\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "    )\n",
    "\n",
    "    # Tracing\n",
    "    langsmith_api_key: Optional[str] = None\n",
    "    langsmith_project: str = \"careeragent-ai\"\n",
    "\n",
    "    # LLM backends (local-first)\n",
    "    ollama_base_url: Optional[str] = None\n",
    "\n",
    "    # Search\n",
    "    serper_api_key: Optional[str] = None\n",
    "\n",
    "    # Notifications\n",
    "    twilio_account_sid: Optional[str] = None\n",
    "    twilio_auth_token: Optional[str] = None\n",
    "    twilio_phone: Optional[str] = None  # From number\n",
    "    user_phone: Optional[str] = None    # To number for local testing\n",
    "\n",
    "    # Runtime\n",
    "    environment: str = \"local\"\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_settings() -> Settings:\n",
    "    \"\"\"\n",
    "    Description: Cached settings accessor for FastAPI/Streamlit.\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: Settings\n",
    "    \"\"\"\n",
    "    return Settings()\n",
    "'''\n",
    "Path(\"src/careeragent/config.py\").write_text(config_py.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Refactor NotificationService (Twilio SDK preferred; safe fallback)\n",
    "#    src/careeragent/services/notification_service.py\n",
    "# -----------------------------\n",
    "notification_py = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, Literal, Optional\n",
    "\n",
    "from careeragent.config import get_settings\n",
    "from careeragent.orchestration.state import OrchestrationState\n",
    "\n",
    "\n",
    "class NotificationService:\n",
    "    \"\"\"\n",
    "    Description: L7 notifications service using Twilio SMS for critical run status changes.\n",
    "    Layer: L7\n",
    "    Input: OrchestrationState transitions and quota/security events\n",
    "    Output: SMS send attempts logged to state.meta['notifications']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *, dry_run: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Description: Initialize notification service.\n",
    "        Layer: L0\n",
    "        Input: dry_run flag\n",
    "        Output: NotificationService\n",
    "        \"\"\"\n",
    "        self._settings = get_settings()\n",
    "        self._dry_run = bool(dry_run)\n",
    "\n",
    "    def _twilio_ready(self) -> bool:\n",
    "        \"\"\"\n",
    "        Description: Check Twilio credential presence.\n",
    "        Layer: L0\n",
    "        Input: Settings\n",
    "        Output: bool\n",
    "        \"\"\"\n",
    "        s = self._settings\n",
    "        return bool(s.twilio_account_sid and s.twilio_auth_token and s.twilio_phone)\n",
    "\n",
    "    def send_sms(self, *, to_phone: str, body: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: Send SMS via Twilio (SDK if installed, otherwise safe error).\n",
    "        Layer: L7\n",
    "        Input: to_phone + body\n",
    "        Output: dict result\n",
    "        \"\"\"\n",
    "        payload = {\"to\": to_phone, \"from\": self._settings.twilio_phone, \"body\": body}\n",
    "\n",
    "        if self._dry_run or not self._twilio_ready():\n",
    "            return {\"sent\": False, \"dry_run\": True, \"reason\": \"dry_run_or_missing_twilio_config\", \"payload\": payload}\n",
    "\n",
    "        try:\n",
    "            from twilio.rest import Client  # type: ignore\n",
    "        except Exception as e:\n",
    "            return {\"sent\": False, \"dry_run\": True, \"reason\": f\"twilio_sdk_missing:{e}\", \"payload\": payload}\n",
    "\n",
    "        client = Client(self._settings.twilio_account_sid, self._settings.twilio_auth_token)\n",
    "        msg = client.messages.create(to=to_phone, from_=self._settings.twilio_phone, body=body)\n",
    "        return {\"sent\": True, \"sid\": getattr(msg, \"sid\", None), \"payload\": payload}\n",
    "\n",
    "    def notify(\n",
    "        self,\n",
    "        *,\n",
    "        state: OrchestrationState,\n",
    "        event: Literal[\"needs_human_approval\", \"completed\", \"quota_error\"],\n",
    "        extra: Optional[Dict[str, Any]] = None,\n",
    "        to_phone: Optional[str] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: Send critical status notification and log it in OrchestrationState.meta.\n",
    "        Layer: L7\n",
    "        Input: state + event + extra + optional to_phone override\n",
    "        Output: result dict\n",
    "        \"\"\"\n",
    "        extra = extra or {}\n",
    "        to = (to_phone or self._settings.user_phone or \"\").strip()\n",
    "        if not to:\n",
    "            result = {\"sent\": False, \"dry_run\": True, \"reason\": \"missing_user_phone\", \"event\": event}\n",
    "        else:\n",
    "            if event == \"needs_human_approval\":\n",
    "                body = f\"CareerAgent-AI: Run {state.run_id} needs human approval. Open the dashboard to review.\"\n",
    "            elif event == \"completed\":\n",
    "                body = f\"CareerAgent-AI: Run {state.run_id} completed successfully.\"\n",
    "            else:\n",
    "                provider = extra.get(\"provider\", \"unknown\")\n",
    "                body = f\"CareerAgent-AI: Run {state.run_id} blocked due to API quota error ({provider}).\"\n",
    "            result = self.send_sms(to_phone=to, body=body)\n",
    "\n",
    "        state.meta.setdefault(\"notifications\", [])\n",
    "        state.meta[\"notifications\"].append({\"event\": event, \"to\": to, \"result\": result, \"extra\": extra})\n",
    "        state.touch()\n",
    "        return result\n",
    "'''\n",
    "Path(\"src/careeragent/services/notification_service.py\").write_text(notification_py.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FastAPI Brain: src/careeragent/api/main.py\n",
    "# -----------------------------\n",
    "api_main_py = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from careeragent.config import artifacts_root, get_settings\n",
    "from careeragent.orchestration.state import OrchestrationState\n",
    "from careeragent.agents.security_agent import SanitizeAgent\n",
    "from careeragent.services.notification_service import NotificationService\n",
    "\n",
    "from careeragent.agents.parser_agent_service import ParserAgentService\n",
    "from careeragent.agents.parser_evaluator_service import ParserEvaluatorService\n",
    "\n",
    "from careeragent.agents.matcher_agent_schema import JobDescription\n",
    "from careeragent.agents.matcher_agent_service import MatcherAgentService\n",
    "from careeragent.agents.strategy_agent_service import StrategyAgentService\n",
    "from careeragent.agents.cover_letter_service import CoverLetterService\n",
    "from careeragent.agents.apply_executor_service import ApplyExecutorService\n",
    "\n",
    "from careeragent.services.xai_service import XAIService\n",
    "from careeragent.services.exporter import CareerDossierExporter\n",
    "\n",
    "\n",
    "app = FastAPI(title=\"CareerAgent-AI Beta Brain\", version=\"0.1.0\")\n",
    "\n",
    "\n",
    "def _run_dir(run_id: str) -> Path:\n",
    "    \"\"\"\n",
    "    Description: Resolve run directory under canonical artifacts path.\n",
    "    Layer: L0\n",
    "    Input: run_id\n",
    "    Output: Path artifacts/runs/<run_id>\n",
    "    \"\"\"\n",
    "    p = artifacts_root() / \"runs\" / run_id\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "def _state_path(run_id: str) -> Path:\n",
    "    \"\"\"\n",
    "    Description: Resolve persistent state.json for a run.\n",
    "    Layer: L0\n",
    "    Input: run_id\n",
    "    Output: Path artifacts/runs/<run_id>/state.json\n",
    "    \"\"\"\n",
    "    return _run_dir(run_id) / \"state.json\"\n",
    "\n",
    "\n",
    "def persist_state(state: OrchestrationState) -> None:\n",
    "    \"\"\"\n",
    "    Description: Persist orchestration state to disk for polling from UI.\n",
    "    Layer: L8\n",
    "    Input: OrchestrationState\n",
    "    Output: state.json written\n",
    "    \"\"\"\n",
    "    _state_path(state.run_id).write_text(json.dumps(state.model_dump(), indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def load_state(run_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Load state.json for status polling.\n",
    "    Layer: L8\n",
    "    Input: run_id\n",
    "    Output: dict\n",
    "    \"\"\"\n",
    "    p = _state_path(run_id)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(run_id)\n",
    "    return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "class AnalyzeRequest(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: API input payload for /analyze.\n",
    "    Layer: L1\n",
    "    Input: resume_text + job payload\n",
    "    Output: triggers pipeline\n",
    "    \"\"\"\n",
    "    resume_text: str = Field(..., min_length=10)\n",
    "    job: Dict[str, Any] = Field(..., description=\"JobDescription-like JSON\")\n",
    "    user_phone: Optional[str] = None\n",
    "\n",
    "\n",
    "class AnalyzeResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: API response for /analyze.\n",
    "    Layer: L1\n",
    "    Input: Pipeline result\n",
    "    Output: run_id + key artifact paths\n",
    "    \"\"\"\n",
    "    run_id: str\n",
    "    status: str\n",
    "    artifacts: Dict[str, Any]\n",
    "\n",
    "\n",
    "def run_pipeline(*, resume_text: str, job_payload: Dict[str, Any], user_phone: Optional[str] = None) -> OrchestrationState:\n",
    "    \"\"\"\n",
    "    Description: Execute L2‚ÄìL9 pipeline (local-first) and persist artifacts/state for UI polling.\n",
    "    Layer: L2-L9\n",
    "    Input: resume_text + job payload\n",
    "    Output: OrchestrationState\n",
    "    \"\"\"\n",
    "    settings = get_settings()\n",
    "    notifier = NotificationService(dry_run=not (settings.twilio_account_sid and settings.user_phone))\n",
    "    sec = SanitizeAgent()\n",
    "\n",
    "    st = OrchestrationState.new(env=settings.environment, mode=\"agentic\", git_sha=None)\n",
    "    st.meta.update({\"w1_skill_overlap\": 0.45, \"w2_experience_alignment\": 0.35, \"w3_ats_score\": 0.20})\n",
    "    if user_phone:\n",
    "        st.meta[\"user_phone_override\"] = user_phone\n",
    "\n",
    "    # L0 Security\n",
    "    st.start_step(\"l0_security\", layer_id=\"L0\", tool_name=\"sanitize_before_llm\", input_ref={})\n",
    "    safe = sec.sanitize_before_llm(\n",
    "        state=st, step_id=\"l0_security\", tool_name=\"sanitize_before_llm\", user_text=resume_text, context=\"resume\"\n",
    "    )\n",
    "    if safe is None:\n",
    "        persist_state(st)\n",
    "        # Notify user on block (security)\n",
    "        if (user_phone or settings.user_phone):\n",
    "            notifier.notify(state=st, event=\"needs_human_approval\", to_phone=(user_phone or settings.user_phone))\n",
    "        return st\n",
    "    st.end_step(\"l0_security\", status=\"ok\", output_ref={\"sanitized\": True}, message=\"security_pass\")\n",
    "\n",
    "    # Parse JobDescription\n",
    "    try:\n",
    "        job = JobDescription(**job_payload)\n",
    "    except Exception as e:\n",
    "        st.status = \"failed\"\n",
    "        st.meta[\"run_failure_code\"] = \"BAD_JOB_PAYLOAD\"\n",
    "        st.meta[\"run_failure_detail\"] = str(e)\n",
    "        persist_state(st)\n",
    "        return st\n",
    "\n",
    "    # Seed evaluator keyword context\n",
    "    st.meta[\"target_role_keywords\"] = list(set((job.required_skills or []) + (job.preferred_skills or [])))\n",
    "    st.meta[\"target_requirements_text\"] = job.requirements_text\n",
    "    if job.market_competition_factor:\n",
    "        st.meta[\"market_competition_factor\"] = float(job.market_competition_factor)\n",
    "\n",
    "    out_dir = _run_dir(st.run_id)\n",
    "\n",
    "    # Save raw inputs as artifacts\n",
    "    (out_dir / \"resume_raw.txt\").write_text(safe, encoding=\"utf-8\")\n",
    "    (out_dir / \"job.json\").write_text(json.dumps(job.model_dump(), indent=2), encoding=\"utf-8\")\n",
    "    st.add_artifact(\"resume_raw\", str(out_dir / \"resume_raw.txt\"), content_type=\"text/plain\")\n",
    "    st.add_artifact(f\"job_{job.job_id}\", str(out_dir / \"job.json\"), content_type=\"application/json\")\n",
    "    persist_state(st)\n",
    "\n",
    "    # L2 Parser + L3 Evaluator recursive gate\n",
    "    parser = ParserAgentService()\n",
    "    parser_eval = ParserEvaluatorService()\n",
    "    feedback = []\n",
    "    extracted = None\n",
    "    for attempt in range(4):\n",
    "        sid = f\"l2_parse_{attempt+1}\"\n",
    "        st.start_step(sid, layer_id=\"L2\", tool_name=\"parser_agent_service\", input_ref={\"attempt\": attempt+1})\n",
    "        extracted = parser.parse(raw_text=safe, orchestration_state=st, feedback=feedback)\n",
    "        p = out_dir / f\"extracted_resume_attempt_{attempt+1}.json\"\n",
    "        p.write_text(json.dumps(extracted.to_json_dict(), indent=2), encoding=\"utf-8\")\n",
    "        st.add_artifact(f\"extracted_resume_attempt_{attempt+1}\", str(p), content_type=\"application/json\")\n",
    "        st.end_step(sid, status=\"ok\", output_ref={\"artifact_key\": f\"extracted_resume_attempt_{attempt+1}\"}, message=\"parsed\")\n",
    "\n",
    "        ev = parser_eval.evaluate(\n",
    "            orchestration_state=st,\n",
    "            raw_text=safe,\n",
    "            extracted=extracted,\n",
    "            target_id=\"resume_main\",\n",
    "            threshold=0.80,\n",
    "            retry_count=attempt,\n",
    "            max_retries=3,\n",
    "        )\n",
    "        decision = st.apply_recursive_gate(target_id=\"resume_main\", layer_id=\"L3\")\n",
    "        persist_state(st)\n",
    "        if decision == \"pass\":\n",
    "            break\n",
    "        if decision == \"human_approval\":\n",
    "            # Notify user\n",
    "            st.status = \"needs_human_approval\"\n",
    "            persist_state(st)\n",
    "            if (user_phone or settings.user_phone):\n",
    "                notifier.notify(state=st, event=\"needs_human_approval\", to_phone=(user_phone or settings.user_phone))\n",
    "            return st\n",
    "        feedback = ev.feedback\n",
    "\n",
    "    # L4 Match\n",
    "    matcher = MatcherAgentService()\n",
    "    st.start_step(\"l4_match\", layer_id=\"L4\", tool_name=\"matcher_agent_service\", input_ref={\"job_id\": job.job_id})\n",
    "    report = matcher.match(resume=extracted, job=job, orchestration_state=st)\n",
    "    mr = out_dir / f\"match_report_{job.job_id}.json\"\n",
    "    mr.write_text(json.dumps(report.model_dump(), indent=2), encoding=\"utf-8\")\n",
    "    st.add_artifact(f\"match_report_{job.job_id}\", str(mr), content_type=\"application/json\")\n",
    "    st.meta.setdefault(\"job_scores\", {})\n",
    "    st.meta.setdefault(\"job_components\", {})\n",
    "    st.meta.setdefault(\"job_meta\", {})\n",
    "    st.meta[\"job_scores\"][job.job_id] = float(report.interview_chance_score)\n",
    "    st.meta[\"job_components\"][job.job_id] = report.components.model_dump()\n",
    "    st.meta[\"job_meta\"][job.job_id] = {\"role_title\": job.role_title, \"company\": job.company}\n",
    "    st.end_step(\"l4_match\", status=\"ok\", output_ref={\"artifact_key\": f\"match_report_{job.job_id}\"}, message=\"matched\")\n",
    "    persist_state(st)\n",
    "\n",
    "    # L5 Strategy\n",
    "    strategist = StrategyAgentService()\n",
    "    st.start_step(\"l5_strategy\", layer_id=\"L5\", tool_name=\"strategy_agent_service\", input_ref={\"job_id\": job.job_id})\n",
    "    strategy = strategist.generate(resume=extracted, job=job, match_report=report, orchestration_state=st, feedback=[])\n",
    "    sp = out_dir / f\"pivot_strategy_{job.job_id}.json\"\n",
    "    sp.write_text(json.dumps(strategy.model_dump(), indent=2), encoding=\"utf-8\")\n",
    "    st.add_artifact(f\"pivot_strategy_{job.job_id}\", str(sp), content_type=\"application/json\")\n",
    "    st.end_step(\"l5_strategy\", status=\"ok\", output_ref={\"artifact_key\": f\"pivot_strategy_{job.job_id}\"}, message=\"strategy\")\n",
    "    persist_state(st)\n",
    "\n",
    "    # L6 Cover Letter\n",
    "    cover = CoverLetterService()\n",
    "    st.start_step(\"l6_cover\", layer_id=\"L6\", tool_name=\"cover_letter_service\", input_ref={\"job_id\": job.job_id})\n",
    "    draft = cover.draft(\n",
    "        resume=extracted, job=job, match_report=report, orchestration_state=st, feedback=[\"Include contact header\"]\n",
    "    )\n",
    "    cp = out_dir / f\"cover_letter_{job.job_id}.md\"\n",
    "    cp.write_text(draft.body, encoding=\"utf-8\")\n",
    "    st.add_artifact(f\"cover_letter_{job.job_id}\", str(cp), content_type=\"text/markdown\")\n",
    "    st.end_step(\"l6_cover\", status=\"ok\", output_ref={\"artifact_key\": f\"cover_letter_{job.job_id}\"}, message=\"cover_letter\")\n",
    "    persist_state(st)\n",
    "\n",
    "    # L7 Apply (simulated) ‚Äî only after this do we mark completed (ApplyExecutorService does it)\n",
    "    apply_exec = ApplyExecutorService()\n",
    "    st.start_step(\"l7_apply\", layer_id=\"L7\", tool_name=\"apply_executor_service\", input_ref={\"job_id\": job.job_id})\n",
    "    submission = apply_exec.submit(\n",
    "        orchestration_state=st,\n",
    "        job_id=job.job_id,\n",
    "        resume_artifact_key=\"extracted_resume_attempt_1\",\n",
    "        cover_letter_artifact_key=f\"cover_letter_{job.job_id}\",\n",
    "        notes=\"Beta submit (simulated).\",\n",
    "    )\n",
    "    subp = out_dir / f\"submission_{submission.submission_id}.json\"\n",
    "    subp.write_text(json.dumps(submission.model_dump(), indent=2), encoding=\"utf-8\")\n",
    "    st.add_artifact(f\"submission_{submission.submission_id}\", str(subp), content_type=\"application/json\")\n",
    "    st.end_step(\"l7_apply\", status=\"ok\", output_ref={\"submission_id\": submission.submission_id}, message=\"submitted\")\n",
    "    persist_state(st)\n",
    "\n",
    "    # L9 XAI outputs + dossier export\n",
    "    xai = XAIService()\n",
    "    xai_paths = xai.write_outputs(state=st, require_reportlab=False)\n",
    "    st.add_artifact(\"transparency_matrix_json\", xai_paths[\"json\"], content_type=\"application/json\")\n",
    "    st.add_artifact(\"xai_transparency_pdf\", xai_paths[\"pdf\"], content_type=\"application/pdf\")\n",
    "\n",
    "    exporter = CareerDossierExporter()\n",
    "    bundle = exporter.bundle_reports(run_id=st.run_id, final_pdf_path=xai_paths[\"pdf\"])\n",
    "    st.add_artifact(\"career_dossier_zip\", bundle[\"zip\"], content_type=\"application/zip\")\n",
    "    persist_state(st)\n",
    "\n",
    "    # Notify completion\n",
    "    if (user_phone or settings.user_phone):\n",
    "        notifier.notify(state=st, event=\"completed\", to_phone=(user_phone or settings.user_phone))\n",
    "\n",
    "    return st\n",
    "\n",
    "\n",
    "@app.post(\"/analyze\", response_model=AnalyzeResponse)\n",
    "def analyze(req: AnalyzeRequest) -> AnalyzeResponse:\n",
    "    \"\"\"\n",
    "    Description: Trigger L2‚ÄìL9 pipeline for a resume + job payload.\n",
    "    Layer: L1\n",
    "    Input: AnalyzeRequest\n",
    "    Output: AnalyzeResponse (run_id + artifacts)\n",
    "    \"\"\"\n",
    "    st = run_pipeline(resume_text=req.resume_text, job_payload=req.job, user_phone=req.user_phone)\n",
    "    persist_state(st)\n",
    "    return AnalyzeResponse(run_id=st.run_id, status=st.status, artifacts={k: v.model_dump() for k, v in st.artifacts.items()})\n",
    "\n",
    "\n",
    "@app.get(\"/status/{run_id}\")\n",
    "def status(run_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Poll the persisted OrchestrationState for a run_id.\n",
    "    Layer: L1\n",
    "    Input: run_id\n",
    "    Output: State JSON dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return load_state(run_id)\n",
    "    except FileNotFoundError:\n",
    "        raise HTTPException(status_code=404, detail=\"run_id not found\")\n",
    "'''\n",
    "Path(\"src/careeragent/api/main.py\").write_text(api_main_py.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Streamlit Frontend: app/main.py\n",
    "# -----------------------------\n",
    "streamlit_py = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "API_BASE = st.secrets.get(\"API_BASE\", \"http://127.0.0.1:8000\")\n",
    "\n",
    "\n",
    "def _download_button_from_path(label: str, path: str, mime: str) -> None:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        st.warning(f\"Missing file: {path}\")\n",
    "        return\n",
    "    st.download_button(label=label, data=p.read_bytes(), file_name=p.name, mime=mime)\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"CareerAgent-AI Beta\", layout=\"wide\")\n",
    "st.title(\"CareerAgent-AI ‚Äî Beta Dashboard\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.subheader(\"Backend\")\n",
    "    API_BASE = st.text_input(\"API Base URL\", value=API_BASE)\n",
    "    st.caption(\"FastAPI Brain must be running.\")\n",
    "    st.divider()\n",
    "    st.subheader(\"Inputs\")\n",
    "\n",
    "resume_text = st.text_area(\"Resume (raw text)\", height=220, placeholder=\"Paste resume text here...\")\n",
    "job_json = st.text_area(\n",
    "    \"Job (JobDescription JSON)\",\n",
    "    height=220,\n",
    "    value=json.dumps(\n",
    "        {\n",
    "            \"job_id\": \"job_001\",\n",
    "            \"role_title\": \"Data Scientist\",\n",
    "            \"company\": \"ExampleCo\",\n",
    "            \"country_code\": \"US\",\n",
    "            \"required_skills\": [\"python\", \"sql\", \"fastapi\"],\n",
    "            \"preferred_skills\": [\"mlflow\", \"docker\"],\n",
    "            \"requirements_text\": \"python sql fastapi mlflow docker production\",\n",
    "            \"applicants_count\": 200,\n",
    "        },\n",
    "        indent=2,\n",
    "    ),\n",
    ")\n",
    "user_phone = st.text_input(\"Your phone (optional, Twilio)\", value=\"\")\n",
    "\n",
    "colA, colB = st.columns([1, 1])\n",
    "with colA:\n",
    "    run_btn = st.button(\"Run Analyze\", type=\"primary\", use_container_width=True)\n",
    "with colB:\n",
    "    run_id_input = st.text_input(\"Run ID (to poll)\", value=\"\")\n",
    "\n",
    "if run_btn:\n",
    "    try:\n",
    "        job = json.loads(job_json)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Invalid Job JSON: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    if not resume_text.strip():\n",
    "        st.error(\"Paste resume text.\")\n",
    "        st.stop()\n",
    "\n",
    "    payload = {\"resume_text\": resume_text, \"job\": job, \"user_phone\": (user_phone.strip() or None)}\n",
    "    r = requests.post(f\"{API_BASE}/analyze\", json=payload, timeout=120)\n",
    "    if r.status_code >= 400:\n",
    "        st.error(f\"/analyze failed: {r.status_code} {r.text[:500]}\")\n",
    "        st.stop()\n",
    "\n",
    "    data = r.json()\n",
    "    st.session_state[\"run_id\"] = data[\"run_id\"]\n",
    "    st.success(f\"Started run: {data['run_id']} (status: {data['status']})\")\n",
    "\n",
    "run_id = st.session_state.get(\"run_id\") or run_id_input.strip()\n",
    "if run_id:\n",
    "    st.subheader(f\"Run: {run_id}\")\n",
    "\n",
    "    poll = st.button(\"Poll Status\", use_container_width=True)\n",
    "    if poll or True:\n",
    "        r = requests.get(f\"{API_BASE}/status/{run_id}\", timeout=30)\n",
    "        if r.status_code == 404:\n",
    "            st.warning(\"Run not found yet.\")\n",
    "        else:\n",
    "            st_data: Dict[str, Any] = r.json()\n",
    "\n",
    "            # Progress visualization from steps\n",
    "            steps = st_data.get(\"steps\", [])\n",
    "            total = max(1, len(steps))\n",
    "            done = sum(1 for s in steps if s.get(\"finished_at_utc\"))\n",
    "            st.progress(done / total)\n",
    "\n",
    "            status = st_data.get(\"status\", \"unknown\")\n",
    "            st.metric(\"Run Status\", status)\n",
    "\n",
    "            # Match score gauge (simple)\n",
    "            meta = st_data.get(\"meta\", {}) or {}\n",
    "            job_scores = meta.get(\"job_scores\", {}) or {}\n",
    "            if job_scores:\n",
    "                job_id, score = next(iter(job_scores.items()))\n",
    "                pct = float(score) * 100.0\n",
    "                st.metric(\"Match Score (InterviewChance)\", f\"{pct:.2f}%\")\n",
    "                st.progress(min(1.0, max(0.0, pct / 100.0)))\n",
    "\n",
    "            # Audit trail\n",
    "            with st.expander(\"Audit Trail (Steps)\"):\n",
    "                for s in steps:\n",
    "                    st.write(f\"- [{s.get('layer_id')}] {s.get('tool_name')} | {s.get('status')} | {s.get('step_id')}\")\n",
    "\n",
    "            # Downloads (dossier zip + XAI PDF)\n",
    "            artifacts = st_data.get(\"artifacts\", {}) or {}\n",
    "            zip_ref = artifacts.get(\"career_dossier_zip\")\n",
    "            pdf_ref = artifacts.get(\"xai_transparency_pdf\")\n",
    "\n",
    "            d1, d2 = st.columns(2)\n",
    "            with d1:\n",
    "                if zip_ref and zip_ref.get(\"path\"):\n",
    "                    _download_button_from_path(\"Download Career Dossier (ZIP)\", zip_ref[\"path\"], \"application/zip\")\n",
    "            with d2:\n",
    "                if pdf_ref and pdf_ref.get(\"path\"):\n",
    "                    _download_button_from_path(\"Download XAI Transparency (PDF)\", pdf_ref[\"path\"], \"application/pdf\")\n",
    "\n",
    "            with st.expander(\"Full State JSON\"):\n",
    "                st.json(st_data)\n",
    "'''\n",
    "Path(\"app/main.py\").write_text(streamlit_py.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) run_app.py launcher\n",
    "# -----------------------------\n",
    "run_app_py = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def main() -> int:\n",
    "    \"\"\"\n",
    "    Description: Launch FastAPI (uvicorn) and Streamlit dashboard locally.\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: process exit code\n",
    "    \"\"\"\n",
    "    # Prefer correct module path: careeragent.api.main:app\n",
    "    uvicorn_cmd = [sys.executable, \"-m\", \"uvicorn\", \"careeragent.api.main:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"]\n",
    "    streamlit_cmd = [sys.executable, \"-m\", \"streamlit\", \"run\", \"app/main.py\", \"--server.port\", \"8501\"]\n",
    "\n",
    "    print(\"Starting FastAPI:\", \" \".join(uvicorn_cmd))\n",
    "    api = subprocess.Popen(uvicorn_cmd)\n",
    "\n",
    "    # small delay so backend boots\n",
    "    time.sleep(1.2)\n",
    "\n",
    "    print(\"Starting Streamlit:\", \" \".join(streamlit_cmd))\n",
    "    ui = subprocess.Popen(streamlit_cmd)\n",
    "\n",
    "    try:\n",
    "        api.wait()\n",
    "        ui.wait()\n",
    "        return 0\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping...\")\n",
    "        api.terminate()\n",
    "        ui.terminate()\n",
    "        return 130\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    raise SystemExit(main())\n",
    "'''\n",
    "Path(\"run_app.py\").write_text(run_app_py.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Environment sync: patch pyproject.toml dependencies\n",
    "# -----------------------------\n",
    "pyproject = Path(\"pyproject.toml\")\n",
    "if pyproject.exists():\n",
    "    raw = pyproject.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # naive but safe-ish: ensure required deps appear in [project].dependencies list\n",
    "    required = [\n",
    "        \"fastapi\",\n",
    "        \"uvicorn\",\n",
    "        \"streamlit\",\n",
    "        \"reportlab\",\n",
    "        \"twilio\",\n",
    "        \"pydantic-settings\",\n",
    "    ]\n",
    "\n",
    "    # Find dependencies array block\n",
    "    dep_block = re.search(r'(?s)\\[project\\].*?dependencies\\s*=\\s*\\[(.*?)\\]\\s*', raw)\n",
    "    if dep_block:\n",
    "        inside = dep_block.group(1)\n",
    "        existing = set(re.findall(r'\"([^\"]+)\"', inside))\n",
    "        # Keep any version pins if present; check by prefix match before adding\n",
    "        def has_prefix(pkg: str) -> bool:\n",
    "            return any(e.lower().startswith(pkg.lower()) for e in existing)\n",
    "\n",
    "        to_add = []\n",
    "        for pkg in required:\n",
    "            if not has_prefix(pkg):\n",
    "                # minimal pins; keep compatible\n",
    "                if pkg == \"uvicorn\":\n",
    "                    to_add.append('\"uvicorn>=0.27\"')\n",
    "                elif pkg == \"streamlit\":\n",
    "                    to_add.append('\"streamlit>=1.33\"')\n",
    "                elif pkg == \"reportlab\":\n",
    "                    to_add.append('\"reportlab>=4.0\"')\n",
    "                elif pkg == \"twilio\":\n",
    "                    to_add.append('\"twilio>=9.0\"')\n",
    "                elif pkg == \"pydantic-settings\":\n",
    "                    to_add.append('\"pydantic-settings>=2.2\"')\n",
    "                else:\n",
    "                    to_add.append(f'\"{pkg}>=0\"')\n",
    "\n",
    "        if to_add:\n",
    "            # inject before closing bracket of dependencies list\n",
    "            new_inside = inside.rstrip()\n",
    "            if new_inside.strip() and not new_inside.strip().endswith(\",\"):\n",
    "                new_inside = new_inside + \",\\n  \" + \",\\n  \".join(to_add) + \"\\n\"\n",
    "            else:\n",
    "                new_inside = new_inside + \"\\n  \" + \",\\n  \".join(to_add) + \"\\n\"\n",
    "            raw = raw.replace(inside, new_inside)\n",
    "            pyproject.write_text(raw, encoding=\"utf-8\")\n",
    "            print(\"‚úÖ Patched pyproject.toml dependencies:\", to_add)\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è pyproject.toml already includes required deps.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not find [project].dependencies block to patch. Please add deps manually.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è pyproject.toml not found. Add deps to your environment manually.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Smoke imports (no server start)\n",
    "# -----------------------------\n",
    "import sys\n",
    "sys.path.insert(0, str(Path(\"src\").resolve()))\n",
    "\n",
    "from careeragent.config import get_settings\n",
    "from careeragent.api.main import app as fastapi_app\n",
    "\n",
    "s = get_settings()\n",
    "assert fastapi_app is not None\n",
    "\n",
    "print(\"‚úÖ Batch 9 files written:\")\n",
    "print(\" - src/careeragent/config.py\")\n",
    "print(\" - src/careeragent/api/main.py\")\n",
    "print(\" - app/main.py\")\n",
    "print(\" - run_app.py\")\n",
    "print(\"‚úÖ Smoke imports OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14b758-04f4-440a-a53d-7fa4c0dcaab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careeragent-ai (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
