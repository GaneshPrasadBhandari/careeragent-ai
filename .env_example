# ===== CareerOS Config Template (Safe to commit) =====

# === Runtime ===
ENV=dev
DEMO_MODE=true
ORCHESTRATION_MODE=pipeline   # pipeline | agents
API_URL=http://localhost:8000
PORT=8000
DEBUG=True



# === LLM / Generation ===
# Local OSS default (no key): run ollama locally
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_SUMMARY_MODEL=llama3
# Optional hosted fallback
HF_TOKEN=hf_your_actual_token_here
HUGGINGFACE_API_KEY=hf_your_actual_token_here
HUGGINGFACE_API_KEY=your_HL_key_here_do_not_share
HF_SUMMARY_MODEL=google/flan-t5-base
HUGGINGFACEHUB_API_TOKEN=hf_your_actual_token_here  # Added for LangChain safety


#Gemini api key
GEMINI_API_KEY=your_google_api_key
OPENAI_API_KEY=sk-proj_your_actual_token_here 


# === Embeddings + Vector DB ===
# Default OSS local persistent vector DB
VECTOR_DB=chroma               # chroma | qdrant | none
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHROMA_PERSIST_DIR=outputs/phase3/chroma
CHROMA_COLLECTION=careeros_runs

# Hosted/managed Qdrant (optional)
QDRANT_URL=your_Qdrant_key_here_do_not_share
QDRANT_API_KEY=your_Qdrant_key_here_do_not_share
QDRANT_COLLECTION=careeros_runs

# === Job discovery / scraping ===
# At least one recommended for richer top-8 portal discovery:
SERPER_API_KEY=your_serper_key_here_do_not_share
TAVILY_API_KEY=your_tavily_key_here_do_not_share
# Optional scraper for JS-heavy job pages (free trials available)
SCRAPINGBEE_API_KEY=your_scrapingbee_key_here_do_not_share

# === OCR ===
# Required only if you upload image resumes (png/jpg/webp/bmp/tiff)
# Also install tesseract binary on your machine.
PYTESSERACT_LANG=eng

# === Optional Agentic / Observability ===
#LANGSMITH_API_KEY=your_langsmith_key_here_do_not_share
#LANGSMITH_PROJECT="careeragent-ai"
# === Traceability (The "No Black Box" requirement) ===
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_PROJECT="careeragent-ai-new"


MCP_SERVER_URL=your_mcp_server_url_here
TAVILY_MCP_URL=https://mcp.tavily.com/mcp/?tavilyApiKey=your_tavily_key_here_do_not_share

# --- DATABASE & Analytics (Cloud-Ready SQLite) ---
# Local: sqlite:///career_os.db
# Cloud: sqlitecloud://your-id.sqlite.cloud:8860/career_os.db?apikey=your_key
DATABASE_URL=sqlite:///career_os.db



# --- Email & Communication ---
RESEND_API_KEY=re_your_resend_key_here
SENDER_EMAIL=your-verified-domain-email@example.com
SENDGRID_API_KEY=your_sendgrid_key_here. #twilio api key



# === Advanced RAG Config ===
RAG_TOP_K=10                      # Number of documents to retrieve for CRAG
RELEVANCE_THRESHOLD=0.7           # Minimum score for Evaluator Agent to accept a retrieved doc
SEARCH_BACKUP_ENABLED=true        # If RAG fails, trigger web search (CRAG logic)


# === LangGraph Orchestration & Quality Gates ===
RETRY_LIMIT=3                     # Max retries for an Evaluator Agent before failing
FALLBACK_MODEL=llama3             # Use local Ollama if primary APIs fail
AUTO_RECOVERY=true                # Allow agents to self-correct based on Evaluator feedback

# === Advanced RAG Parameters ===
# These guide the CRAG (Corrective RAG) logic
RELEVANCE_THRESHOLD=0.7           # Min score (0-1) to accept a job match
RAG_TOP_K=10                      # Documents to pull for Self-RAG reflection
WEB_SEARCH_TOP_K=5                # Results to fetch if VectorDB is insufficient

# === Traceability (The "No Black Box" requirement) ===
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_PROJECT="careeragent-ai"

