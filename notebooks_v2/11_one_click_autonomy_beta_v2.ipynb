{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f4138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACKUP: src/careeragent/config.py.bak_20260220_203044\n",
      "WROTE: src/careeragent/config.py\n",
      "BACKUP: src/careeragent/services/db_service.py.bak_20260220_203044\n",
      "WROTE: src/careeragent/services/db_service.py\n",
      "BACKUP: src/careeragent/services/notification_service.py.bak_20260220_203044\n",
      "WROTE: src/careeragent/services/notification_service.py\n",
      "BACKUP: src/careeragent/orchestration.py.bak_20260220_203044\n",
      "WROTE: src/careeragent/orchestration.py\n",
      "BACKUP: src/careeragent/api/main.py.bak_20260220_203044\n",
      "WROTE: src/careeragent/api/main.py\n",
      "BACKUP: app/ui/dashboard.py.bak_20260220_203044\n",
      "WROTE: app/ui/dashboard.py\n",
      "BACKUP: app/main.py.bak_20260220_203044\n",
      "WROTE: app/main.py\n",
      "BACKUP: run_app.py.bak_20260220_203044\n",
      "WROTE: run_app.py\n",
      "\n",
      "NEXT: Ensure deps installed:\n",
      "uv add fastapi uvicorn streamlit reportlab twilio pydantic-settings httpx pypdf\n",
      "uv sync\n",
      "\n",
      "Then run:\n",
      "uv run python run_app.py\n"
     ]
    }
   ],
   "source": [
    "# NOTEBOOK CELL — OVERWRITE the Beta automation core (orchestration + API brain + Mission Control UI)\n",
    "# Creates timestamped backups before overwriting.\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "OVERWRITE = True  # you asked to overwrite\n",
    "\n",
    "def safe_overwrite(path: str, content: str, overwrite: bool = OVERWRITE) -> None:\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if p.exists() and not overwrite:\n",
    "        print(f\"SKIP (exists): {p}\")\n",
    "        return\n",
    "    if p.exists() and overwrite:\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup = p.with_suffix(p.suffix + f\".bak_{ts}\")\n",
    "        backup.write_text(p.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "        print(f\"BACKUP: {backup}\")\n",
    "    p.write_text(content, encoding=\"utf-8\")\n",
    "    print(f\"WROTE: {p}\")\n",
    "\n",
    "# Ensure folders\n",
    "Path(\"src/careeragent/api\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/services\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"src/careeragent/agents\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"app/ui\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"src/careeragent/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "Path(\"src/careeragent/api/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "Path(\"src/careeragent/services/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "Path(\"src/careeragent/agents/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "Path(\"app/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "Path(\"app/ui/__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "CONFIG_PY = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "\n",
    "def repo_root() -> Path:\n",
    "    \"\"\"\n",
    "    Description: Resolve repository root from within src/ package.\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: Absolute Path to repo root\n",
    "    \"\"\"\n",
    "    return Path(__file__).resolve().parents[2]\n",
    "\n",
    "\n",
    "def artifacts_root() -> Path:\n",
    "    \"\"\"\n",
    "    Description: Canonical artifacts root (local-first).\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: Path to src/careeragent/artifacts\n",
    "    \"\"\"\n",
    "    root = Path(__file__).resolve().parents[0] / \"artifacts\"\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "    return root\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Description: Central configuration loader for CareerAgent-AI.\n",
    "    Layer: L0\n",
    "    Input: .env (repo root) + environment variables\n",
    "    Output: Strongly typed settings object\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=str(repo_root() / \".env\"),\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "    )\n",
    "\n",
    "    environment: str = \"local\"\n",
    "\n",
    "    # Local LLM (Ollama)\n",
    "    ollama_base_url: Optional[str] = None\n",
    "    ollama_model: str = \"llama3.2\"\n",
    "\n",
    "    # Search\n",
    "    serper_api_key: Optional[str] = None\n",
    "\n",
    "    # LangSmith tracing\n",
    "    langsmith_api_key: Optional[str] = None\n",
    "    langsmith_project: str = \"careeragent-ai\"\n",
    "\n",
    "    # Twilio\n",
    "    twilio_account_sid: Optional[str] = None\n",
    "    twilio_auth_token: Optional[str] = None\n",
    "    twilio_phone: Optional[str] = None    # FROM number\n",
    "    user_phone: Optional[str] = None      # default TO number\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_settings() -> Settings:\n",
    "    \"\"\"\n",
    "    Description: Cached settings accessor.\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: Settings\n",
    "    \"\"\"\n",
    "    return Settings()\n",
    "'''\n",
    "safe_overwrite(\"src/careeragent/config.py\", CONFIG_PY)\n",
    "\n",
    "DB_SERVICE = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from careeragent.config import artifacts_root\n",
    "\n",
    "\n",
    "class SqliteStateStore:\n",
    "    \"\"\"\n",
    "    Description: Local-first persistence of OrchestrationState using SQLite.\n",
    "    Layer: L8\n",
    "    Input: state JSON blobs\n",
    "    Output: durable run state + status polling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Description: Initialize sqlite db under artifacts/db/.\n",
    "        Layer: L0\n",
    "        Input: None\n",
    "        Output: SqliteStateStore\n",
    "        \"\"\"\n",
    "        db_dir = artifacts_root() / \"db\"\n",
    "        db_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self._db = db_dir / \"careeragent.db\"\n",
    "        self._init_schema()\n",
    "\n",
    "    def _init_schema(self) -> None:\n",
    "        \"\"\"\n",
    "        Description: Create schema if missing.\n",
    "        Layer: L0\n",
    "        Input: None\n",
    "        Output: SQLite tables ready\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self._db) as con:\n",
    "            con.execute(\n",
    "                \"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS runs (\n",
    "                    run_id TEXT PRIMARY KEY,\n",
    "                    status TEXT,\n",
    "                    state_json TEXT,\n",
    "                    updated_at_utc TEXT\n",
    "                )\n",
    "                \"\"\"\n",
    "            )\n",
    "            con.execute(\n",
    "                \"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS actions (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    run_id TEXT,\n",
    "                    action_type TEXT,\n",
    "                    payload_json TEXT,\n",
    "                    created_at_utc TEXT\n",
    "                )\n",
    "                \"\"\"\n",
    "            )\n",
    "            con.commit()\n",
    "\n",
    "    def upsert_state(self, *, run_id: str, status: str, state: Dict[str, Any], updated_at_utc: str) -> None:\n",
    "        \"\"\"\n",
    "        Description: Upsert a run state.\n",
    "        Layer: L8\n",
    "        Input: run_id + state JSON\n",
    "        Output: persistent snapshot\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self._db) as con:\n",
    "            con.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO runs(run_id, status, state_json, updated_at_utc)\n",
    "                VALUES(?,?,?,?)\n",
    "                ON CONFLICT(run_id) DO UPDATE SET\n",
    "                    status=excluded.status,\n",
    "                    state_json=excluded.state_json,\n",
    "                    updated_at_utc=excluded.updated_at_utc\n",
    "                \"\"\",\n",
    "                (run_id, status, json.dumps(state), updated_at_utc),\n",
    "            )\n",
    "            con.commit()\n",
    "\n",
    "    def get_state(self, *, run_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Description: Fetch persisted run state.\n",
    "        Layer: L8\n",
    "        Input: run_id\n",
    "        Output: dict | None\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self._db) as con:\n",
    "            cur = con.execute(\"SELECT state_json FROM runs WHERE run_id=?\", (run_id,))\n",
    "            row = cur.fetchone()\n",
    "            if not row:\n",
    "                return None\n",
    "            return json.loads(row[0])\n",
    "\n",
    "    def insert_action(self, *, run_id: str, action_type: str, payload: Dict[str, Any], created_at_utc: str) -> None:\n",
    "        \"\"\"\n",
    "        Description: Record user/HITL action for auditability.\n",
    "        Layer: L5\n",
    "        Input: action payload\n",
    "        Output: persisted action log\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self._db) as con:\n",
    "            con.execute(\n",
    "                \"INSERT INTO actions(run_id, action_type, payload_json, created_at_utc) VALUES(?,?,?,?)\",\n",
    "                (run_id, action_type, json.dumps(payload), created_at_utc),\n",
    "            )\n",
    "            con.commit()\n",
    "'''\n",
    "safe_overwrite(\"src/careeragent/services/db_service.py\", DB_SERVICE)\n",
    "\n",
    "NOTIF_SERVICE = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, Literal, Optional\n",
    "\n",
    "from careeragent.config import get_settings\n",
    "from careeragent.orchestration.state import OrchestrationState\n",
    "\n",
    "\n",
    "class NotificationService:\n",
    "    \"\"\"\n",
    "    Description: L7 notifications using Twilio SMS for critical run events.\n",
    "    Layer: L7\n",
    "    Input: OrchestrationState + event type\n",
    "    Output: SMS send attempts logged to state.meta['notifications']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *, dry_run: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Description: Initialize service (local-first safe).\n",
    "        Layer: L0\n",
    "        Input: dry_run\n",
    "        Output: NotificationService\n",
    "        \"\"\"\n",
    "        self._s = get_settings()\n",
    "        self._dry = bool(dry_run)\n",
    "\n",
    "    def _ready(self) -> bool:\n",
    "        \"\"\"\n",
    "        Description: Validate Twilio env presence.\n",
    "        Layer: L0\n",
    "        Input: Settings\n",
    "        Output: bool\n",
    "        \"\"\"\n",
    "        return bool(self._s.twilio_account_sid and self._s.twilio_auth_token and self._s.twilio_phone)\n",
    "\n",
    "    def send_sms(self, *, to_phone: str, body: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: Send SMS via Twilio SDK (if installed) with safe fallback.\n",
    "        Layer: L7\n",
    "        Input: to_phone + body\n",
    "        Output: dict result\n",
    "        \"\"\"\n",
    "        payload = {\"to\": to_phone, \"from\": self._s.twilio_phone, \"body\": body}\n",
    "\n",
    "        if self._dry or not self._ready():\n",
    "            return {\"sent\": False, \"dry_run\": True, \"reason\": \"dry_run_or_missing_twilio_config\", \"payload\": payload}\n",
    "\n",
    "        try:\n",
    "            from twilio.rest import Client  # type: ignore\n",
    "        except Exception as e:\n",
    "            return {\"sent\": False, \"dry_run\": True, \"reason\": f\"twilio_sdk_missing:{e}\", \"payload\": payload}\n",
    "\n",
    "        client = Client(self._s.twilio_account_sid, self._s.twilio_auth_token)\n",
    "        msg = client.messages.create(to=to_phone, from_=self._s.twilio_phone, body=body)\n",
    "        return {\"sent\": True, \"sid\": getattr(msg, \"sid\", None), \"payload\": payload}\n",
    "\n",
    "    def notify(self, *, state: OrchestrationState, event: Literal[\"needs_human_approval\", \"completed\", \"quota_error\"], extra: Optional[Dict[str, Any]] = None, to_phone: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: Notify on critical run state transitions.\n",
    "        Layer: L7\n",
    "        Input: state + event + extra\n",
    "        Output: logged result\n",
    "        \"\"\"\n",
    "        extra = extra or {}\n",
    "        to = (to_phone or self._s.user_phone or \"\").strip()\n",
    "        if not to:\n",
    "            result = {\"sent\": False, \"dry_run\": True, \"reason\": \"missing_user_phone\", \"event\": event}\n",
    "        else:\n",
    "            if event == \"needs_human_approval\":\n",
    "                body = f\"CareerAgent-AI: Run {state.run_id} needs human approval. Open dashboard to review.\"\n",
    "            elif event == \"completed\":\n",
    "                body = f\"CareerAgent-AI: Run {state.run_id} completed successfully.\"\n",
    "            else:\n",
    "                provider = extra.get(\"provider\", \"unknown\")\n",
    "                body = f\"CareerAgent-AI: Run {state.run_id} blocked due to API quota error ({provider}).\"\n",
    "            result = self.send_sms(to_phone=to, body=body)\n",
    "\n",
    "        state.meta.setdefault(\"notifications\", [])\n",
    "        state.meta[\"notifications\"].append({\"event\": event, \"to\": to, \"result\": result, \"extra\": extra})\n",
    "        state.touch()\n",
    "        return result\n",
    "'''\n",
    "safe_overwrite(\"src/careeragent/services/notification_service.py\", NOTIF_SERVICE)\n",
    "\n",
    "# Main autonomous orchestration with HITL actions\n",
    "ORCHESTRATION_PY = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import re\n",
    "import threading\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple\n",
    "from uuid import uuid4\n",
    "\n",
    "import httpx\n",
    "\n",
    "from careeragent.config import artifacts_root, get_settings\n",
    "from careeragent.orchestration.state import OrchestrationState\n",
    "from careeragent.services.db_service import SqliteStateStore\n",
    "from careeragent.services.notification_service import NotificationService\n",
    "from careeragent.services.health_service import HealthService\n",
    "\n",
    "from careeragent.agents.security_agent import SanitizeAgent\n",
    "from careeragent.agents.guardrail_service import OutputGuard\n",
    "\n",
    "from careeragent.agents.parser_agent_service import ParserAgentService, ExtractedResume\n",
    "from careeragent.agents.parser_evaluator_service import ParserEvaluatorService\n",
    "\n",
    "from careeragent.agents.matcher_agent_schema import JobDescription\n",
    "from careeragent.agents.matcher_agent_service import MatcherAgentService\n",
    "from careeragent.agents.matcher_evaluator_service import MatchEvaluatorService\n",
    "\n",
    "from careeragent.agents.strategy_agent_service import StrategyAgentService\n",
    "from careeragent.agents.strategy_evaluator_service import StrategyEvaluatorService\n",
    "\n",
    "from careeragent.agents.cover_letter_service import CoverLetterService\n",
    "from careeragent.agents.cover_letter_evaluator_service import CoverLetterEvaluatorService\n",
    "\n",
    "from careeragent.agents.apply_executor_service import ApplyExecutorService\n",
    "from careeragent.agents.apply_executor_evaluator_service import ApplyExecutorEvaluatorService\n",
    "\n",
    "from careeragent.services.xai_service import XAIService\n",
    "from careeragent.services.exporter import CareerDossierExporter\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class JobBoard:\n",
    "    \"\"\"\n",
    "    Description: Job board registry entry for Serper discovery.\n",
    "    Layer: L3\n",
    "    Input: None\n",
    "    Output: JobBoard record\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    domain: str\n",
    "\n",
    "\n",
    "DEFAULT_JOB_BOARDS: Tuple[JobBoard, ...] = (\n",
    "    JobBoard(\"LinkedIn Jobs\", \"linkedin.com/jobs\"),\n",
    "    JobBoard(\"Indeed\", \"indeed.com\"),\n",
    "    JobBoard(\"Glassdoor\", \"glassdoor.com\"),\n",
    "    JobBoard(\"ZipRecruiter\", \"ziprecruiter.com\"),\n",
    "    JobBoard(\"Monster\", \"monster.com\"),\n",
    "    JobBoard(\"Dice\", \"dice.com\"),\n",
    "    JobBoard(\"Lever\", \"jobs.lever.co\"),\n",
    "    JobBoard(\"Greenhouse\", \"boards.greenhouse.io\"),\n",
    ")\n",
    "\n",
    "\n",
    "def _run_dir(run_id: str) -> Path:\n",
    "    \"\"\"\n",
    "    Description: Resolve run directory under artifacts/runs/<run_id>.\n",
    "    Layer: L0\n",
    "    Input: run_id\n",
    "    Output: Path\n",
    "    \"\"\"\n",
    "    d = artifacts_root() / \"runs\" / run_id\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "def _save_json(p: Path, obj: Any) -> None:\n",
    "    \"\"\"\n",
    "    Description: Safe JSON writer.\n",
    "    Layer: L0\n",
    "    Input: path + obj\n",
    "    Output: file write\n",
    "    \"\"\"\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class LiveFeed:\n",
    "    \"\"\"\n",
    "    Description: Live Agent Feed logger (UI consumes it).\n",
    "    Layer: L1\n",
    "    Input: state + feed event\n",
    "    Output: appended events + persistence\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def emit(state: OrchestrationState, *, layer: str, agent: str, message: str) -> None:\n",
    "        state.meta.setdefault(\"live_feed\", [])\n",
    "        state.meta[\"live_feed\"].append({\"layer\": layer, \"agent\": agent, \"message\": message})\n",
    "        state.touch()\n",
    "\n",
    "\n",
    "class LocalResumeExtractor:\n",
    "    \"\"\"\n",
    "    Description: Extract resume text from PDF/TXT bytes (local-first).\n",
    "    Layer: L2\n",
    "    Input: filename + bytes\n",
    "    Output: extracted text\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text(*, filename: str, data: bytes) -> str:\n",
    "        name = (filename or \"\").lower()\n",
    "        if name.endswith(\".txt\"):\n",
    "            return data.decode(\"utf-8\", errors=\"replace\")\n",
    "        if name.endswith(\".pdf\"):\n",
    "            try:\n",
    "                from pypdf import PdfReader  # type: ignore\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\"Missing pypdf for PDF extraction. Install: uv add pypdf\") from e\n",
    "            import io\n",
    "            reader = PdfReader(io.BytesIO(data))\n",
    "            parts = []\n",
    "            for page in reader.pages:\n",
    "                parts.append(page.extract_text() or \"\")\n",
    "            return \"\\n\".join(parts)\n",
    "        return data.decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "\n",
    "class OllamaClient:\n",
    "    \"\"\"\n",
    "    Description: Local LLM client for query refinement and reasoning (optional).\n",
    "    Layer: L4-L5\n",
    "    Input: prompts\n",
    "    Output: text responses\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_url: Optional[str], model: str) -> None:\n",
    "        self._base = (base_url or \"\").strip()\n",
    "        self._model = model\n",
    "\n",
    "    def available(self) -> bool:\n",
    "        return bool(self._base)\n",
    "\n",
    "    def generate(self, *, prompt: str) -> str:\n",
    "        if not self.available():\n",
    "            return \"\"\n",
    "        url = self._base.rstrip(\"/\") + \"/api/generate\"\n",
    "        payload = {\"model\": self._model, \"prompt\": prompt, \"stream\": False}\n",
    "        with httpx.Client(timeout=60.0) as client:\n",
    "            r = client.post(url, json=payload)\n",
    "        if r.status_code >= 400:\n",
    "            return \"\"\n",
    "        return (r.json().get(\"response\") or \"\").strip()\n",
    "\n",
    "\n",
    "class DiscoveryService:\n",
    "    \"\"\"\n",
    "    Description: Serper-based discovery across job boards.\n",
    "    Layer: L3\n",
    "    Input: query + boards\n",
    "    Output: normalized results\n",
    "    \"\"\"\n",
    "\n",
    "    SERPER_URL = \"https://google.serper.dev/search\"\n",
    "\n",
    "    def __init__(self, *, api_key: str, health: HealthService) -> None:\n",
    "        self._key = api_key\n",
    "        self._health = health\n",
    "\n",
    "    def search_board(self, *, state: OrchestrationState, step_id: str, board: JobBoard, query: str, num: int = 10) -> List[Dict[str, Any]]:\n",
    "        headers = {\"X-API-KEY\": self._key, \"Content-Type\": \"application/json\"}\n",
    "        q = f\"{query} site:{board.domain}\"\n",
    "\n",
    "        try:\n",
    "            with httpx.Client(timeout=30.0) as client:\n",
    "                r = client.post(self.SERPER_URL, headers=headers, json={\"q\": q, \"num\": num})\n",
    "        except Exception as e:\n",
    "            state.status = \"api_failure\"\n",
    "            state.meta[\"run_failure_code\"] = \"API_FAILURE\"\n",
    "            state.meta[\"run_failure_provider\"] = \"serper\"\n",
    "            LiveFeed.emit(state, layer=\"L3\", agent=\"DiscoveryService\", message=f\"Serper request failed: {e}\")\n",
    "            return []\n",
    "\n",
    "        # Quota enforcement: 403 => blocked + UI alert (HealthService does it)\n",
    "        if self._health.quota.handle_serper_response(\n",
    "            state=state, step_id=step_id, status_code=r.status_code, tool_name=\"serper.search\", error_detail=r.text[:200]\n",
    "        ):\n",
    "            return []\n",
    "\n",
    "        if r.status_code >= 400:\n",
    "            state.status = \"api_failure\"\n",
    "            state.meta[\"run_failure_code\"] = \"API_FAILURE\"\n",
    "            state.meta[\"run_failure_provider\"] = \"serper\"\n",
    "            LiveFeed.emit(state, layer=\"L3\", agent=\"DiscoveryService\", message=f\"Serper error {r.status_code}: {r.text[:140]}\")\n",
    "            return []\n",
    "\n",
    "        organic = (r.json().get(\"organic\") or [])\n",
    "        out = []\n",
    "        for it in organic:\n",
    "            out.append(\n",
    "                {\n",
    "                    \"title\": it.get(\"title\") or \"\",\n",
    "                    \"link\": it.get(\"link\") or \"\",\n",
    "                    \"snippet\": it.get(\"snippet\") or \"\",\n",
    "                    \"source\": board.name,\n",
    "                    \"domain\": board.domain,\n",
    "                }\n",
    "            )\n",
    "        return out\n",
    "\n",
    "\n",
    "class ScraperAgent:\n",
    "    \"\"\"\n",
    "    Description: Best-effort job page scraper.\n",
    "    Layer: L3-L4\n",
    "    Input: url + fallback snippet\n",
    "    Output: job text\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_text(*, url: str, snippet: str) -> str:\n",
    "        if not url:\n",
    "            return snippet or \"\"\n",
    "        try:\n",
    "            with httpx.Client(timeout=15.0, follow_redirects=True) as client:\n",
    "                r = client.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "            if r.status_code >= 400:\n",
    "                return snippet or \"\"\n",
    "            html = r.text\n",
    "            txt = re.sub(r\"<(script|style)[^>]*>.*?</\\1>\", \" \", html, flags=re.S | re.I)\n",
    "            txt = re.sub(r\"<[^>]+>\", \" \", txt)\n",
    "            txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "            return (txt[:14000] if txt else (snippet or \"\"))\n",
    "        except Exception:\n",
    "            return snippet or \"\"\n",
    "\n",
    "\n",
    "class DiscoveryEvaluatorAgent:\n",
    "    \"\"\"\n",
    "    Description: L5 evaluator for discovery quality (controls recursive query loop).\n",
    "    Layer: L5\n",
    "    Input: ranking scores\n",
    "    Output: EvaluationEvent + feedback (for loop-back)\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate(self, *, state: OrchestrationState, target_id: str, ranking: List[Dict[str, Any]], threshold: float, retry_count: int, max_retries: int):\n",
    "        scores = [float(x.get(\"interview_chance_score\", 0.0)) for x in ranking]\n",
    "        top = max(scores) if scores else 0.0\n",
    "        avg = sum(scores) / max(1, len(scores))\n",
    "\n",
    "        # Score is a confidence metric for the discovery itself (not the job scores)\n",
    "        discovery_quality = min(1.0, (0.55 * top) + (0.45 * avg))\n",
    "        fb: List[str] = []\n",
    "        if len(ranking) < 8:\n",
    "            fb.append(\"Too few valid jobs. Widen query/location or broaden boards.\")\n",
    "            discovery_quality -= 0.15\n",
    "        if top < threshold:\n",
    "            fb.append(f\"Low confidence: top score {top*100:.1f}% below threshold {threshold*100:.0f}%.\")\n",
    "            fb.append(\"Refine query using top resume skills + role synonyms + remove noise terms.\")\n",
    "            discovery_quality -= 0.10\n",
    "\n",
    "        discovery_quality = max(0.0, min(1.0, discovery_quality))\n",
    "\n",
    "        ev = state.record_evaluation(\n",
    "            layer_id=\"L5\",\n",
    "            target_id=target_id,\n",
    "            generator_agent=\"DiscoveryAgent\",\n",
    "            evaluator_agent=\"DiscoveryEvaluatorAgent\",\n",
    "            evaluation_score=float(discovery_quality),\n",
    "            threshold=float(threshold),\n",
    "            feedback=fb,\n",
    "            retry_count=int(retry_count),\n",
    "            max_retries=int(max_retries),\n",
    "            interview_chance=None,\n",
    "        )\n",
    "        return ev, top, avg\n",
    "\n",
    "\n",
    "class OneClickAutomationEngine:\n",
    "    \"\"\"\n",
    "    Description: Production-ready autonomous one-click engine with HITL gates.\n",
    "    Layer: L0-L9\n",
    "    Input: resume upload + preferences\n",
    "    Output: stateful run with artifacts + approvals + downloadable dossier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._settings = get_settings()\n",
    "        self._store = SqliteStateStore()\n",
    "        self._health = HealthService()\n",
    "        self._health.load_env(dotenv_path=str(Path(\".env\")))\n",
    "        self._health.enable_langsmith_tracing(project=self._settings.langsmith_project)\n",
    "\n",
    "        self._notifier = NotificationService(dry_run=not bool(self._settings.twilio_account_sid))\n",
    "        self._sanitize = SanitizeAgent()\n",
    "        self._out_guard = OutputGuard()\n",
    "\n",
    "        self._ollama = OllamaClient(self._settings.ollama_base_url, self._settings.ollama_model)\n",
    "\n",
    "        self._parser = ParserAgentService()\n",
    "        self._parser_eval = ParserEvaluatorService()\n",
    "\n",
    "        self._matcher = MatcherAgentService()\n",
    "        self._matcher_eval = MatchEvaluatorService()\n",
    "\n",
    "        self._strategist = StrategyAgentService()\n",
    "        self._strategy_eval = StrategyEvaluatorService()\n",
    "\n",
    "        self._cover = CoverLetterService()\n",
    "        self._cover_eval = CoverLetterEvaluatorService()\n",
    "\n",
    "        self._apply = ApplyExecutorService()\n",
    "        self._apply_eval = ApplyExecutorEvaluatorService()\n",
    "\n",
    "        self._disc_eval = DiscoveryEvaluatorAgent()\n",
    "\n",
    "    # ---------- persistence ----------\n",
    "    def _persist(self, state: OrchestrationState) -> None:\n",
    "        d = _run_dir(state.run_id)\n",
    "        _save_json(d / \"state.json\", state.model_dump())\n",
    "        self._store.upsert_state(run_id=state.run_id, status=state.status, state=state.model_dump(), updated_at_utc=state.updated_at_utc)\n",
    "\n",
    "    def load(self, run_id: str) -> Optional[Dict[str, Any]]:\n",
    "        return self._store.get_state(run_id=run_id)\n",
    "\n",
    "    # ---------- run lifecycle ----------\n",
    "    def start_run(\n",
    "        self,\n",
    "        *,\n",
    "        filename: str,\n",
    "        data: bytes,\n",
    "        prefs: Dict[str, Any],\n",
    "    ) -> OrchestrationState:\n",
    "        state = OrchestrationState.new(env=self._settings.environment, mode=\"agentic\", git_sha=None)\n",
    "        state.meta[\"preferences\"] = prefs\n",
    "        state.meta.setdefault(\"job_scores\", {})\n",
    "        state.meta.setdefault(\"job_components\", {})\n",
    "        state.meta.setdefault(\"job_meta\", {})\n",
    "\n",
    "        LiveFeed.emit(state, layer=\"L1\", agent=\"Dashboard\", message=\"Run created. Starting autonomous pipeline…\")\n",
    "        self._persist(state)\n",
    "\n",
    "        # run in background thread (local-first, UI polls)\n",
    "        t = threading.Thread(target=self._run_autonomous, args=(state.run_id, filename, data), daemon=True)\n",
    "        t.start()\n",
    "        return state\n",
    "\n",
    "    def submit_action(self, *, run_id: str, action_type: str, payload: Dict[str, Any]) -> OrchestrationState:\n",
    "        raw = self.load(run_id)\n",
    "        if not raw:\n",
    "            raise ValueError(\"run_id not found\")\n",
    "        state = OrchestrationState(**raw)\n",
    "\n",
    "        # audit action\n",
    "        self._store.insert_action(run_id=run_id, action_type=action_type, payload=payload, created_at_utc=state.updated_at_utc)\n",
    "\n",
    "        LiveFeed.emit(state, layer=\"L5\", agent=\"HITL\", message=f\"User action received: {action_type}\")\n",
    "        state.meta[\"last_user_action\"] = {\"type\": action_type, \"payload\": payload}\n",
    "        self._persist(state)\n",
    "\n",
    "        # Continue in background\n",
    "        t = threading.Thread(target=self._continue_after_hitl, args=(run_id,), daemon=True)\n",
    "        t.start()\n",
    "        return state\n",
    "\n",
    "    # ---------- autonomous core ----------\n",
    "    def _run_autonomous(self, run_id: str, filename: str, data: bytes) -> None:\n",
    "        raw = self.load(run_id)\n",
    "        if not raw:\n",
    "            return\n",
    "        state = OrchestrationState(**raw)\n",
    "        run_dir = _run_dir(run_id)\n",
    "\n",
    "        # L2: Extract text from file upload\n",
    "        state.start_step(\"l2_resume_extract\", layer_id=\"L2\", tool_name=\"ResumeExtractor\", input_ref={\"filename\": filename})\n",
    "        try:\n",
    "            text = LocalResumeExtractor.extract_text(filename=filename, data=data)\n",
    "        except Exception as e:\n",
    "            state.end_step(\"l2_resume_extract\", status=\"failed\", output_ref={}, message=str(e))\n",
    "            state.status = \"needs_human_approval\"\n",
    "            state.meta[\"pending_action\"] = \"resume_extract_failed\"\n",
    "            LiveFeed.emit(state, layer=\"L2\", agent=\"ParserAgent\", message=f\"Resume extraction failed: {e}\")\n",
    "            self._persist(state)\n",
    "            self._notify(state, event=\"needs_human_approval\")\n",
    "            return\n",
    "\n",
    "        (run_dir / \"resume_raw.txt\").write_text(text, encoding=\"utf-8\")\n",
    "        state.add_artifact(\"resume_raw\", str(run_dir / \"resume_raw.txt\"), content_type=\"text/plain\")\n",
    "        state.end_step(\"l2_resume_extract\", status=\"ok\", output_ref={\"artifact_key\": \"resume_raw\"}, message=\"extracted\")\n",
    "        LiveFeed.emit(state, layer=\"L2\", agent=\"ParserAgent\", message=\"Resume extracted from upload.\")\n",
    "        self._persist(state)\n",
    "\n",
    "        # L0: Sanitize\n",
    "        state.start_step(\"l0_sanitize\", layer_id=\"L0\", tool_name=\"SanitizeAgent\", input_ref={})\n",
    "        safe = self._sanitize.sanitize_before_llm(state=state, step_id=\"l0_sanitize\", tool_name=\"sanitize_before_llm\", user_text=text, context=\"resume\")\n",
    "        if safe is None:\n",
    "            LiveFeed.emit(state, layer=\"L0\", agent=\"SanitizeAgent\", message=\"Prompt injection detected. Run blocked.\")\n",
    "            self._persist(state)\n",
    "            self._notify(state, event=\"quota_error\", extra={\"provider\": \"security_block\"})\n",
    "            return\n",
    "        state.end_step(\"l0_sanitize\", status=\"ok\", output_ref={\"sanitized\": True}, message=\"pass\")\n",
    "        LiveFeed.emit(state, layer=\"L0\", agent=\"SanitizeAgent\", message=\"Security check passed.\")\n",
    "        self._persist(state)\n",
    "\n",
    "        # L2/L3: Parse + eval loop\n",
    "        extracted = self._parse_with_gate(state=state, safe_text=safe, run_dir=run_dir)\n",
    "        self._persist(state)\n",
    "        if state.status == \"needs_human_approval\":\n",
    "            self._notify(state, event=\"needs_human_approval\")\n",
    "            return\n",
    "\n",
    "        # L3-L5: Autonomous job hunt with recursive refinement\n",
    "        self._hunt_loop(state=state, extracted=extracted, run_dir=run_dir)\n",
    "        self._persist(state)\n",
    "        if state.status == \"needs_human_approval\":\n",
    "            self._notify(state, event=\"needs_human_approval\")\n",
    "            return\n",
    "\n",
    "    def _continue_after_hitl(self, run_id: str) -> None:\n",
    "        raw = self.load(run_id)\n",
    "        if not raw:\n",
    "            return\n",
    "        state = OrchestrationState(**raw)\n",
    "        run_dir = _run_dir(run_id)\n",
    "\n",
    "        pending = state.meta.get(\"pending_action\")\n",
    "        action = (state.meta.get(\"last_user_action\") or {}).get(\"type\")\n",
    "        payload = (state.meta.get(\"last_user_action\") or {}).get(\"payload\") or {}\n",
    "\n",
    "        # If user rejected ranking => restart discovery with refined preference notes\n",
    "        if pending == \"review_ranking\" and action == \"reject_ranking\":\n",
    "            state.status = \"running\"\n",
    "            state.meta[\"pending_action\"] = None\n",
    "            state.meta.setdefault(\"user_refinement_notes\", [])\n",
    "            state.meta[\"user_refinement_notes\"].append(payload.get(\"reason\", \"User rejected ranking\"))\n",
    "            LiveFeed.emit(state, layer=\"L5\", agent=\"HITL\", message=\"Ranking rejected. Re-running discovery loop with refined query…\")\n",
    "            self._persist(state)\n",
    "\n",
    "            # Reload extracted resume\n",
    "            ex_ref = state.artifacts.get(\"extracted_resume\")\n",
    "            if not ex_ref:\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"missing_extracted_resume\"\n",
    "                self._persist(state)\n",
    "                return\n",
    "            extracted = ExtractedResume(**json.loads(Path(ex_ref.path).read_text(encoding=\"utf-8\")))\n",
    "            self._hunt_loop(state=state, extracted=extracted, run_dir=run_dir)\n",
    "            self._persist(state)\n",
    "            if state.status == \"needs_human_approval\":\n",
    "                self._notify(state, event=\"needs_human_approval\")\n",
    "            return\n",
    "\n",
    "        # Approve ranking => generate strategy + cover letters + eval + guardrails, then pause for draft review\n",
    "        if pending == \"review_ranking\" and action == \"approve_ranking\":\n",
    "            LiveFeed.emit(state, layer=\"L6\", agent=\"Generator\", message=\"Ranking approved. Generating strategies + cover letters…\")\n",
    "            self._persist(state)\n",
    "\n",
    "            ranking_path = Path(run_dir / \"ranking.json\")\n",
    "            if not ranking_path.exists():\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"ranking_missing\"\n",
    "                self._persist(state)\n",
    "                return\n",
    "            ranking = json.loads(ranking_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "            self._generate_drafts_bundle(state=state, extracted=None, ranking=ranking, run_dir=run_dir)\n",
    "            state.status = \"needs_human_approval\"\n",
    "            state.meta[\"pending_action\"] = \"review_drafts\"\n",
    "            LiveFeed.emit(state, layer=\"L5\", agent=\"HITL\", message=\"Drafts ready for review. Approve to submit (simulated).\")\n",
    "            self._persist(state)\n",
    "            self._notify(state, event=\"needs_human_approval\")\n",
    "            return\n",
    "\n",
    "        # Approve drafts => apply + XAI + dossier => completed\n",
    "        if pending == \"review_drafts\" and action == \"approve_drafts\":\n",
    "            LiveFeed.emit(state, layer=\"L7\", agent=\"ApplyExecutor\", message=\"Drafts approved. Submitting applications (simulated)…\")\n",
    "            self._persist(state)\n",
    "            self._apply_and_finalize(state=state, run_dir=run_dir)\n",
    "            self._persist(state)\n",
    "            if state.status == \"completed\":\n",
    "                self._notify(state, event=\"completed\")\n",
    "            return\n",
    "\n",
    "        # Reject drafts => return to review_ranking (or rerun generation)\n",
    "        if pending == \"review_drafts\" and action == \"reject_drafts\":\n",
    "            state.status = \"needs_human_approval\"\n",
    "            state.meta[\"pending_action\"] = \"review_ranking\"\n",
    "            state.meta.setdefault(\"user_refinement_notes\", [])\n",
    "            state.meta[\"user_refinement_notes\"].append(payload.get(\"reason\", \"User rejected drafts\"))\n",
    "            LiveFeed.emit(state, layer=\"L5\", agent=\"HITL\", message=\"Drafts rejected. Returning to ranking review / refinement.\")\n",
    "            self._persist(state)\n",
    "            self._notify(state, event=\"needs_human_approval\")\n",
    "            return\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _notify(self, state: OrchestrationState, *, event: Literal[\"needs_human_approval\", \"completed\", \"quota_error\"], extra: Optional[Dict[str, Any]] = None) -> None:\n",
    "        to = (state.meta.get(\"preferences\", {}) or {}).get(\"user_phone\") or self._settings.user_phone\n",
    "        if to:\n",
    "            self._notifier.notify(state=state, event=event, extra=extra, to_phone=str(to))\n",
    "\n",
    "    def _parse_with_gate(self, *, state: OrchestrationState, safe_text: str, run_dir: Path) -> ExtractedResume:\n",
    "        feedback: List[str] = []\n",
    "        extracted: Optional[ExtractedResume] = None\n",
    "\n",
    "        for attempt in range(0, 4):\n",
    "            sid = f\"l2_parse_{attempt+1}\"\n",
    "            state.start_step(sid, layer_id=\"L2\", tool_name=\"ParserAgentService\", input_ref={\"attempt\": attempt+1})\n",
    "            extracted = self._parser.parse(raw_text=safe_text, orchestration_state=state, feedback=feedback)\n",
    "            p = run_dir / f\"extracted_resume_attempt_{attempt+1}.json\"\n",
    "            _save_json(p, extracted.to_json_dict())\n",
    "            state.add_artifact(f\"extracted_resume_attempt_{attempt+1}\", str(p), content_type=\"application/json\")\n",
    "            state.end_step(sid, status=\"ok\", output_ref={\"artifact_key\": f\"extracted_resume_attempt_{attempt+1}\"}, message=\"parsed\")\n",
    "\n",
    "            ev = self._parser_eval.evaluate(\n",
    "                orchestration_state=state,\n",
    "                raw_text=safe_text,\n",
    "                extracted=extracted,\n",
    "                target_id=\"resume_main\",\n",
    "                threshold=0.80,\n",
    "                retry_count=attempt,\n",
    "                max_retries=3,\n",
    "            )\n",
    "            decision = state.apply_recursive_gate(target_id=\"resume_main\", layer_id=\"L3\")\n",
    "            LiveFeed.emit(state, layer=\"L3\", agent=\"ParserEvaluator\", message=f\"Parse score={ev.evaluation_score:.2f} decision={decision}\")\n",
    "\n",
    "            if decision == \"pass\":\n",
    "                state.add_artifact(\"extracted_resume\", str(p), content_type=\"application/json\")\n",
    "                LiveFeed.emit(state, layer=\"L2\", agent=\"ParserAgent\", message=\"Profile extracted successfully.\")\n",
    "                return extracted\n",
    "\n",
    "            if decision == \"human_approval\":\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"resume_cleanup\"\n",
    "                LiveFeed.emit(state, layer=\"L3\", agent=\"ParserEvaluator\", message=\"Low confidence parsing. Needs human cleanup.\")\n",
    "                return extracted\n",
    "\n",
    "            feedback = ev.feedback\n",
    "\n",
    "        state.status = \"needs_human_approval\"\n",
    "        state.meta[\"pending_action\"] = \"resume_cleanup\"\n",
    "        return extracted or ExtractedResume()\n",
    "\n",
    "    def _hunt_loop(self, *, state: OrchestrationState, extracted: ExtractedResume, run_dir: Path) -> None:\n",
    "        prefs = state.meta.get(\"preferences\", {}) or {}\n",
    "        target_role = str(prefs.get(\"target_role\", \"Data Scientist\"))\n",
    "        country = str(prefs.get(\"country\", \"US\"))\n",
    "        location = str(prefs.get(\"location\", \"United States\"))\n",
    "        remote = bool(prefs.get(\"remote\", True))\n",
    "        salary = str(prefs.get(\"salary\", \"\"))\n",
    "\n",
    "        # weights\n",
    "        state.meta[\"w1_skill_overlap\"] = 0.45\n",
    "        state.meta[\"w2_experience_alignment\"] = 0.35\n",
    "        state.meta[\"w3_ats_score\"] = 0.20\n",
    "\n",
    "        # Discovery ready?\n",
    "        if not self._settings.serper_api_key:\n",
    "            state.status = \"needs_human_approval\"\n",
    "            state.meta[\"pending_action\"] = \"missing_serper_key\"\n",
    "            LiveFeed.emit(state, layer=\"L3\", agent=\"DiscoveryService\", message=\"Missing SERPER_API_KEY. Add it to .env.\")\n",
    "            return\n",
    "\n",
    "        discovery = DiscoveryService(api_key=self._settings.serper_api_key, health=self._health)\n",
    "        guard_threshold = float(prefs.get(\"discovery_threshold\", 0.70))\n",
    "        max_refine = int(prefs.get(\"max_refinements\", 3))\n",
    "\n",
    "        # build query\n",
    "        top_skills = (extracted.skills or [])[:6]\n",
    "        intent = \"remote\" if remote else \"on-site\"\n",
    "        salary_part = f'\"{salary}\"' if salary else \"\"\n",
    "        base_query = f'{target_role} {location} {intent} {salary_part} ' + \" \".join(top_skills)\n",
    "\n",
    "        # incorporate user refinement notes\n",
    "        notes = state.meta.get(\"user_refinement_notes\", []) or []\n",
    "        if notes:\n",
    "            base_query += \" \" + \" \".join([str(n)[:40] for n in notes[-2:]])\n",
    "\n",
    "        for attempt in range(0, max_refine + 1):\n",
    "            sid = f\"l3_discovery_{attempt+1}\"\n",
    "            state.start_step(sid, layer_id=\"L3\", tool_name=\"DiscoveryService\", input_ref={\"attempt\": attempt+1, \"query\": base_query})\n",
    "            LiveFeed.emit(state, layer=\"L3\", agent=\"DiscoveryAgent\", message=f\"Searching across job boards… (attempt {attempt+1})\")\n",
    "\n",
    "            results = self._search_all_boards(state=state, discovery=discovery, query=base_query)\n",
    "            state.end_step(sid, status=\"ok\", output_ref={\"results\": len(results)}, message=\"discovery_done\")\n",
    "\n",
    "            if state.status in (\"blocked\", \"api_failure\"):\n",
    "                LiveFeed.emit(state, layer=\"L3\", agent=\"DiscoveryAgent\", message=\"Discovery halted due to API block/failure.\")\n",
    "                if state.status == \"blocked\":\n",
    "                    self._notify(state, event=\"quota_error\", extra={\"provider\": \"serper\"})\n",
    "                return\n",
    "\n",
    "            # Scrape + embed (local)\n",
    "            docs = []\n",
    "            LiveFeed.emit(state, layer=\"L4\", agent=\"VectorAgent\", message=f\"Scraping + embedding {min(8,len(results))} jobs…\")\n",
    "            for it in results[:8]:\n",
    "                s2 = f\"l4_scrape_{uuid4().hex[:8]}\"\n",
    "                state.start_step(s2, layer_id=\"L4\", tool_name=\"ScraperAgent\", input_ref={\"url\": it.get('link'), \"source\": it.get(\"source\")})\n",
    "                text = ScraperAgent.fetch_text(url=it.get(\"link\") or \"\", snippet=it.get(\"snippet\") or \"\")\n",
    "                doc_id = uuid4().hex\n",
    "                meta = {\"title\": it.get(\"title\"), \"url\": it.get(\"link\"), \"source\": it.get(\"source\")}\n",
    "                docs.append({\"doc_id\": doc_id, \"text\": text, \"meta\": meta})\n",
    "                state.end_step(s2, status=\"ok\", output_ref={\"doc_id\": doc_id}, message=\"scraped\")\n",
    "                LiveFeed.emit(state, layer=\"L4\", agent=\"VectorAgent\", message=f\"Embedded: {meta['source']} | {str(meta['title'])[:60]}\")\n",
    "\n",
    "            # Match + evaluator twin consistency check (math)\n",
    "            ranking = self._match_and_rank(state=state, extracted=extracted, docs=docs, target_role=target_role, country=country)\n",
    "            _save_json(run_dir / \"ranking.json\", ranking)\n",
    "            state.add_artifact(\"ranking\", str(run_dir / \"ranking.json\"), content_type=\"application/json\")\n",
    "\n",
    "            ev, top, avg = self._disc_eval.evaluate(state=state, target_id=\"discovery_quality\", ranking=ranking, threshold=guard_threshold, retry_count=attempt, max_retries=max_refine)\n",
    "            decision = state.apply_recursive_gate(target_id=\"discovery_quality\", layer_id=\"L5\")\n",
    "\n",
    "            LiveFeed.emit(state, layer=\"L5\", agent=\"EvaluatorAgent\",\n",
    "                          message=f\"Search results validated. top={top*100:.1f}% avg={avg*100:.1f}% decision={decision}\")\n",
    "\n",
    "            # HITL pause when either low confidence after retries OR when ranking ready\n",
    "            if decision == \"pass\":\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"review_ranking\"\n",
    "                LiveFeed.emit(state, layer=\"L1\", agent=\"Dashboard\", message=\"One-Click ranking ready for review.\")\n",
    "                return\n",
    "\n",
    "            if decision == \"human_approval\":\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"low_confidence_discovery\"\n",
    "                LiveFeed.emit(state, layer=\"L5\", agent=\"EvaluatorAgent\", message=\"Low confidence discovery. Needs guidance.\")\n",
    "                return\n",
    "\n",
    "            # retry => refine query autonomously (LLM if available, else deterministic)\n",
    "            base_query = self._refine_query(state=state, base_query=base_query, extracted=extracted, ranking=ranking, feedback=ev.feedback, target_role=target_role, location=location)\n",
    "            LiveFeed.emit(state, layer=\"L3\", agent=\"DiscoveryAgent\", message=f\"Refining search… new query: {base_query[:140]}\")\n",
    "\n",
    "    def _search_all_boards(self, *, state: OrchestrationState, discovery: DiscoveryService, query: str) -> List[Dict[str, Any]]:\n",
    "        seen = set()\n",
    "        out: List[Dict[str, Any]] = []\n",
    "        for b in DEFAULT_JOB_BOARDS:\n",
    "            step_id = f\"l3_serper_{b.domain.replace('/','_')}\"\n",
    "            state.start_step(step_id, layer_id=\"L3\", tool_name=\"serper.search\", input_ref={\"board\": b.name})\n",
    "            items = discovery.search_board(state=state, step_id=step_id, board=b, query=query, num=6)\n",
    "            state.end_step(step_id, status=\"ok\", output_ref={\"count\": len(items)}, message=b.name)\n",
    "\n",
    "            for it in items:\n",
    "                link = it.get(\"link\") or \"\"\n",
    "                if not link or link in seen:\n",
    "                    continue\n",
    "                seen.add(link)\n",
    "                out.append(it)\n",
    "        return out\n",
    "\n",
    "    def _match_and_rank(self, *, state: OrchestrationState, extracted: ExtractedResume, docs: List[Dict[str, Any]], target_role: str, country: str) -> List[Dict[str, Any]]:\n",
    "        # dictionary for quick skill extraction from job text\n",
    "        dictionary = list(dict.fromkeys([(s or \"\").lower() for s in (extracted.skills or []) if s]))[:40]\n",
    "        if not dictionary:\n",
    "            dictionary = [\"python\", \"sql\", \"mlflow\", \"docker\", \"kubernetes\", \"fastapi\", \"azure\", \"aws\", \"rag\", \"langgraph\"]\n",
    "\n",
    "        ranked: List[Dict[str, Any]] = []\n",
    "        for d in docs:\n",
    "            text_low = (d.get(\"text\") or \"\").lower()\n",
    "            req = [s for s in dictionary if s in text_low][:12]\n",
    "            pref = [s for s in dictionary if s in text_low][12:18]\n",
    "            meta = d.get(\"meta\") or {}\n",
    "            job = JobDescription(\n",
    "                job_id=str(d.get(\"doc_id\")),\n",
    "                role_title=str(meta.get(\"title\") or target_role),\n",
    "                company=str(meta.get(\"source\") or \"unknown\"),\n",
    "                country_code=str(country),\n",
    "                required_skills=[str(x) for x in req],\n",
    "                preferred_skills=[str(x) for x in pref],\n",
    "                responsibilities=[],\n",
    "                requirements_text=str(meta.get(\"title\") or \"\") + \" \" + (d.get(\"text\") or \"\")[:2500],\n",
    "                applicants_count=None,\n",
    "                market_competition_factor=None,\n",
    "            )\n",
    "\n",
    "            s_match = f\"l4_match_{uuid4().hex[:8]}\"\n",
    "            state.start_step(s_match, layer_id=\"L4\", tool_name=\"MatcherAgent\", input_ref={\"job_id\": job.job_id})\n",
    "            report = self._matcher.match(resume=extracted, job=job, orchestration_state=state)\n",
    "            state.end_step(s_match, status=\"ok\", output_ref={\"score\": report.interview_chance_score}, message=\"matched\")\n",
    "\n",
    "            # Evaluator twin checks scoring math\n",
    "            ev = self._matcher_eval.evaluate(\n",
    "                orchestration_state=state,\n",
    "                resume=extracted,\n",
    "                job=job,\n",
    "                report=report,\n",
    "                target_id=f\"match::{job.job_id}\",\n",
    "                threshold=0.80,\n",
    "                retry_count=0,\n",
    "                max_retries=3,\n",
    "            )\n",
    "            _ = state.apply_recursive_gate(target_id=f\"match::{job.job_id}\", layer_id=\"L4\")\n",
    "\n",
    "            state.meta.setdefault(\"job_scores\", {})\n",
    "            state.meta.setdefault(\"job_components\", {})\n",
    "            state.meta.setdefault(\"job_meta\", {})\n",
    "            state.meta[\"job_scores\"][job.job_id] = float(report.interview_chance_score)\n",
    "            state.meta[\"job_components\"][job.job_id] = report.components.model_dump()\n",
    "            state.meta[\"job_meta\"][job.job_id] = {\"role_title\": job.role_title, \"company\": job.company, \"url\": meta.get(\"url\"), \"source\": meta.get(\"source\")}\n",
    "\n",
    "            ranked.append(\n",
    "                {\n",
    "                    \"job_id\": job.job_id,\n",
    "                    \"role_title\": job.role_title,\n",
    "                    \"company\": job.company,\n",
    "                    \"source\": meta.get(\"source\"),\n",
    "                    \"url\": meta.get(\"url\"),\n",
    "                    \"interview_chance_score\": float(report.interview_chance_score),\n",
    "                    \"overall_match_percent\": float(report.overall_match_percent),\n",
    "                    \"matched_skills\": report.matched_skills[:10],\n",
    "                    \"missing_required_skills\": report.missing_required_skills[:10],\n",
    "                    \"evaluator_score\": float(ev.evaluation_score),\n",
    "                    \"evaluator_feedback\": (ev.feedback[:2] if ev.feedback else []),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        ranked.sort(key=lambda x: x[\"interview_chance_score\"], reverse=True)\n",
    "        return ranked\n",
    "\n",
    "    def _refine_query(self, *, state: OrchestrationState, base_query: str, extracted: ExtractedResume, ranking: List[Dict[str, Any]], feedback: List[str], target_role: str, location: str) -> str:\n",
    "        top = ranking[0] if ranking else {}\n",
    "        top_skills = (top.get(\"matched_skills\") or [])[:5]\n",
    "        resume_skills = (extracted.skills or [])[:5]\n",
    "        hints = \" \".join(list(dict.fromkeys([*top_skills, *resume_skills]))[:8])\n",
    "\n",
    "        # LLM refinement if available and safe\n",
    "        if self._ollama.available():\n",
    "            prompt = (\n",
    "                \"Refine a job search query for Serper.\\n\"\n",
    "                f\"Target role: {target_role}\\nLocation: {location}\\n\"\n",
    "                f\"Current query: {base_query}\\n\"\n",
    "                f\"Resume skills hint: {hints}\\n\"\n",
    "                f\"Evaluator feedback: {feedback}\\n\"\n",
    "                \"Return ONE improved concise query string only.\"\n",
    "            )\n",
    "            # sanitize prompt injection risk (treat as user-provided)\n",
    "            sid = f\"l0_refine_sanitize_{uuid4().hex[:6]}\"\n",
    "            state.start_step(sid, layer_id=\"L0\", tool_name=\"SanitizeAgent\", input_ref={\"context\": \"query_refine\"})\n",
    "            safe = self._sanitize.sanitize_before_llm(state=state, step_id=sid, tool_name=\"sanitize_before_llm\", user_text=prompt, context=\"chat\")\n",
    "            if safe is None:\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"query_refine_blocked\"\n",
    "                return base_query\n",
    "            state.end_step(sid, status=\"ok\", output_ref={}, message=\"ok\")\n",
    "\n",
    "            out = self._ollama.generate(prompt=safe)\n",
    "            if out:\n",
    "                return out.strip().replace(\"\\n\", \" \")[:220]\n",
    "\n",
    "        # deterministic fallback\n",
    "        return f'{target_role} {location} {hints} \"apply\"'\n",
    "\n",
    "    def _generate_drafts_bundle(self, *, state: OrchestrationState, extracted: Optional[ExtractedResume], ranking: List[Dict[str, Any]], run_dir: Path) -> None:\n",
    "        # load extracted if not provided\n",
    "        if extracted is None:\n",
    "            ex_ref = state.artifacts.get(\"extracted_resume\")\n",
    "            if ex_ref and Path(ex_ref.path).exists():\n",
    "                extracted = ExtractedResume(**json.loads(Path(ex_ref.path).read_text(encoding=\"utf-8\")))\n",
    "            else:\n",
    "                state.status = \"needs_human_approval\"\n",
    "                state.meta[\"pending_action\"] = \"missing_extracted_resume\"\n",
    "                return\n",
    "\n",
    "        drafts: List[Dict[str, Any]] = []\n",
    "        strategies: List[Dict[str, Any]] = []\n",
    "\n",
    "        top_jobs = ranking[:5]\n",
    "        for j in top_jobs:\n",
    "            # Build minimal JobDescription from meta for strategy/cover\n",
    "            job = JobDescription(\n",
    "                job_id=str(j[\"job_id\"]),\n",
    "                role_title=str(j.get(\"role_title\") or \"Role\"),\n",
    "                company=str(j.get(\"company\") or \"Company\"),\n",
    "                country_code=\"US\",\n",
    "                required_skills=[],\n",
    "                preferred_skills=[],\n",
    "                responsibilities=[],\n",
    "                requirements_text=\"\",\n",
    "                applicants_count=None,\n",
    "                market_competition_factor=None,\n",
    "            )\n",
    "\n",
    "            # strategy\n",
    "            s_id = f\"l5_strategy_{uuid4().hex[:6]}\"\n",
    "            state.start_step(s_id, layer_id=\"L5\", tool_name=\"StrategyAgent\", input_ref={\"job_id\": job.job_id})\n",
    "            # we don't have full MatchReport object here without re-running; keep it lightweight:\n",
    "            # create a pseudo MatchReport by reading components already in meta (optional)\n",
    "            # For now, strategy is optional; if missing, still proceed.\n",
    "            try:\n",
    "                # reconstruct a small match report file if exists, else skip\n",
    "                # (keeps this robust even if job boards block scraping)\n",
    "                from careeragent.agents.matcher_agent_schema import MatchReport, MatchComponents\n",
    "                comps = state.meta.get(\"job_components\", {}).get(job.job_id, {})\n",
    "                match_report = MatchReport(\n",
    "                    job_id=job.job_id,\n",
    "                    role_title=job.role_title,\n",
    "                    company=job.company,\n",
    "                    matched_skills=j.get(\"matched_skills\") or [],\n",
    "                    missing_required_skills=j.get(\"missing_required_skills\") or [],\n",
    "                    missing_preferred_skills=[],\n",
    "                    components=MatchComponents(**comps) if comps else MatchComponents(skill_overlap=0.0, experience_alignment=0.0, ats_score=0.0, market_competition_factor=1.0),\n",
    "                    interview_chance_score=float(j.get(\"interview_chance_score\", 0.0)),\n",
    "                    overall_match_percent=float(j.get(\"overall_match_percent\", 0.0)),\n",
    "                    rationale=[],\n",
    "                )\n",
    "                strat = self._strategist.generate(resume=extracted, job=job, match_report=match_report, orchestration_state=state, feedback=[])\n",
    "                strategies.append(strat.model_dump())\n",
    "            except Exception:\n",
    "                strategies.append({\"job_id\": job.job_id, \"note\": \"strategy generation skipped (insufficient match object).\"})\n",
    "            state.end_step(s_id, status=\"ok\", output_ref={}, message=\"strategy_done\")\n",
    "\n",
    "            # cover letter + evaluator + output guard\n",
    "            c_id = f\"l6_cover_{uuid4().hex[:6]}\"\n",
    "            state.start_step(c_id, layer_id=\"L6\", tool_name=\"CoverLetterService\", input_ref={\"job_id\": job.job_id})\n",
    "            try:\n",
    "                from careeragent.agents.matcher_agent_schema import MatchReport, MatchComponents\n",
    "                comps = state.meta.get(\"job_components\", {}).get(job.job_id, {})\n",
    "                match_report = MatchReport(\n",
    "                    job_id=job.job_id,\n",
    "                    role_title=job.role_title,\n",
    "                    company=job.company,\n",
    "                    matched_skills=j.get(\"matched_skills\") or [],\n",
    "                    missing_required_skills=j.get(\"missing_required_skills\") or [],\n",
    "                    missing_preferred_skills=[],\n",
    "                    components=MatchComponents(**comps) if comps else MatchComponents(skill_overlap=0.0, experience_alignment=0.0, ats_score=0.0, market_competition_factor=1.0),\n",
    "                    interview_chance_score=float(j.get(\"interview_chance_score\", 0.0)),\n",
    "                    overall_match_percent=float(j.get(\"overall_match_percent\", 0.0)),\n",
    "                    rationale=[],\n",
    "                )\n",
    "                draft = self._cover.draft(resume=extracted, job=job, match_report=match_report, orchestration_state=state, feedback=[\"Include contact header\"])\n",
    "                # evaluator twin\n",
    "                ev = self._cover_eval.evaluate(orchestration_state=state, resume=extracted, job=job, match_report=match_report, draft=draft, target_id=f\"cover::{job.job_id}\", threshold=0.80, retry_count=0, max_retries=3)\n",
    "                _ = state.apply_recursive_gate(target_id=f\"cover::{job.job_id}\", layer_id=\"L6\")\n",
    "\n",
    "                # output guard\n",
    "                guard = self._out_guard.check_cover_letter(state=state, draft_text=draft.body, resume=extracted, match_report=match_report, country_code=\"US\")\n",
    "                if guard.action == \"needs_revision\":\n",
    "                    LiveFeed.emit(state, layer=\"L0\", agent=\"OutputGuard\", message=f\"Cover letter flagged for {job.job_id}: {guard.issues[:1]}\")\n",
    "                # persist\n",
    "                p = run_dir / f\"cover_letter_{job.job_id}.md\"\n",
    "                p.write_text(draft.body, encoding=\"utf-8\")\n",
    "                state.add_artifact(f\"cover_letter_{job.job_id}\", str(p), content_type=\"text/markdown\")\n",
    "                drafts.append({\"job_id\": job.job_id, \"path\": str(p), \"evaluator_score\": float(ev.evaluation_score), \"guard_action\": guard.action, \"guard_issues\": guard.issues[:3]})\n",
    "            except Exception as e:\n",
    "                drafts.append({\"job_id\": job.job_id, \"error\": str(e)})\n",
    "            state.end_step(c_id, status=\"ok\", output_ref={}, message=\"cover_done\")\n",
    "\n",
    "        _save_json(run_dir / \"drafts.json\", {\"drafts\": drafts, \"strategies\": strategies})\n",
    "        state.add_artifact(\"drafts_bundle\", str(run_dir / \"drafts.json\"), content_type=\"application/json\")\n",
    "        LiveFeed.emit(state, layer=\"L6\", agent=\"Generator\", message=f\"Generated drafts for {len(drafts)} jobs.\")\n",
    "\n",
    "    def _apply_and_finalize(self, *, state: OrchestrationState, run_dir: Path) -> None:\n",
    "        # Apply to top 3 cover letters that exist\n",
    "        ranking_path = run_dir / \"ranking.json\"\n",
    "        if not ranking_path.exists():\n",
    "            state.status = \"needs_human_approval\"\n",
    "            state.meta[\"pending_action\"] = \"ranking_missing\"\n",
    "            return\n",
    "\n",
    "        ranking = json.loads(ranking_path.read_text(encoding=\"utf-8\"))[:3]\n",
    "        submissions = []\n",
    "        for j in ranking:\n",
    "            job_id = str(j[\"job_id\"])\n",
    "            cover_key = f\"cover_letter_{job_id}\"\n",
    "            if cover_key not in state.artifacts:\n",
    "                continue\n",
    "            s_id = f\"l7_apply_{uuid4().hex[:6]}\"\n",
    "            state.start_step(s_id, layer_id=\"L7\", tool_name=\"ApplyExecutorService\", input_ref={\"job_id\": job_id})\n",
    "            sub = self._apply.submit(orchestration_state=state, job_id=job_id, resume_artifact_key=\"extracted_resume\", cover_letter_artifact_key=cover_key, notes=\"Simulated submit (beta).\")\n",
    "            submissions.append(sub.model_dump())\n",
    "            state.end_step(s_id, status=\"ok\", output_ref={\"submission_id\": sub.submission_id}, message=\"submitted\")\n",
    "\n",
    "            ev = self._apply_eval.evaluate(orchestration_state=state, submission=sub, target_id=f\"apply::{sub.submission_id}\", threshold=0.90, retry_count=0, max_retries=3)\n",
    "            _ = state.apply_recursive_gate(target_id=f\"apply::{sub.submission_id}\", layer_id=\"L7\")\n",
    "\n",
    "        _save_json(run_dir / \"submissions.json\", {\"submissions\": submissions})\n",
    "        state.add_artifact(\"submissions\", str(run_dir / \"submissions.json\"), content_type=\"application/json\")\n",
    "\n",
    "        # XAI PDF + dossier\n",
    "        xai = XAIService()\n",
    "        xai_paths = xai.write_outputs(state=state, require_reportlab=False)\n",
    "        state.add_artifact(\"xai_transparency_pdf\", xai_paths[\"pdf\"], content_type=\"application/pdf\")\n",
    "        state.add_artifact(\"transparency_matrix_json\", xai_paths[\"json\"], content_type=\"application/json\")\n",
    "\n",
    "        exporter = CareerDossierExporter()\n",
    "        bundle = exporter.bundle_reports(run_id=state.run_id, final_pdf_path=xai_paths[\"pdf\"])\n",
    "        state.add_artifact(\"career_dossier_zip\", bundle[\"zip\"], content_type=\"application/zip\")\n",
    "\n",
    "        state.status = \"completed\"\n",
    "        LiveFeed.emit(state, layer=\"L9\", agent=\"Analytics\", message=\"Finalized dossier (XAI PDF + ZIP). Run completed.\")\n",
    "\n",
    "\n",
    "# Singleton engine for API usage\n",
    "ENGINE = OneClickAutomationEngine()\n",
    "'''\n",
    "safe_overwrite(\"src/careeragent/orchestration.py\", ORCHESTRATION_PY)\n",
    "\n",
    "API_MAIN = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from fastapi import FastAPI, File, Form, HTTPException, UploadFile\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from careeragent.orchestration import ENGINE\n",
    "\n",
    "\n",
    "app = FastAPI(title=\"CareerAgent-AI Beta Brain\", version=\"0.2.0\")\n",
    "\n",
    "\n",
    "class AnalyzeResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: /analyze response\n",
    "    Layer: L1\n",
    "    Input: run result init\n",
    "    Output: run_id + status\n",
    "    \"\"\"\n",
    "    run_id: str\n",
    "    status: str\n",
    "\n",
    "\n",
    "class ActionRequest(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: HITL action request payload.\n",
    "    Layer: L5\n",
    "    Input: action_type + payload\n",
    "    Output: state transition\n",
    "    \"\"\"\n",
    "    action_type: str = Field(..., description=\"approve_ranking | reject_ranking | approve_drafts | reject_drafts\")\n",
    "    payload: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "@app.post(\"/analyze\", response_model=AnalyzeResponse)\n",
    "async def analyze(\n",
    "    resume: UploadFile = File(...),\n",
    "    preferences_json: str = Form(...),\n",
    ") -> AnalyzeResponse:\n",
    "    \"\"\"\n",
    "    Description: One-click analyze endpoint. Accepts resume file + preferences JSON.\n",
    "    Layer: L1\n",
    "    Input: multipart form\n",
    "    Output: run_id\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prefs = json.loads(preferences_json)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Invalid preferences_json: {e}\")\n",
    "\n",
    "    data = await resume.read()\n",
    "    st = ENGINE.start_run(filename=resume.filename, data=data, prefs=prefs)\n",
    "    return AnalyzeResponse(run_id=st.run_id, status=st.status)\n",
    "\n",
    "\n",
    "@app.get(\"/status/{run_id}\")\n",
    "def status(run_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Poll persisted state.\n",
    "    Layer: L1\n",
    "    Input: run_id\n",
    "    Output: state JSON\n",
    "    \"\"\"\n",
    "    st = ENGINE.load(run_id)\n",
    "    if not st:\n",
    "        raise HTTPException(status_code=404, detail=\"run_id not found\")\n",
    "    return st\n",
    "\n",
    "\n",
    "@app.post(\"/action/{run_id}\")\n",
    "def action(run_id: str, req: ActionRequest) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Submit HITL action and continue automation.\n",
    "    Layer: L5\n",
    "    Input: action_type + payload\n",
    "    Output: updated state JSON\n",
    "    \"\"\"\n",
    "    try:\n",
    "        st = ENGINE.submit_action(run_id=run_id, action_type=req.action_type, payload=req.payload)\n",
    "    except ValueError:\n",
    "        raise HTTPException(status_code=404, detail=\"run_id not found\")\n",
    "    return st.model_dump()\n",
    "'''\n",
    "safe_overwrite(\"src/careeragent/api/main.py\", API_MAIN)\n",
    "\n",
    "DASHBOARD = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Description: Mission Control dashboard (Live Agent Feed + HITL approvals + downloads).\n",
    "    Layer: L1\n",
    "    Input: user resume + preferences\n",
    "    Output: interactive one-click automation UI\n",
    "    \"\"\"\n",
    "    st.set_page_config(page_title=\"CareerAgent-AI Mission Control\", layout=\"wide\")\n",
    "    st.title(\"CareerAgent-AI — Mission Control (One-Click Automation)\")\n",
    "\n",
    "    API_BASE = st.sidebar.text_input(\"API Base URL\", value=\"http://127.0.0.1:8000\")\n",
    "\n",
    "    st.sidebar.subheader(\"Upload + Preferences\")\n",
    "    resume_file = st.sidebar.file_uploader(\"Resume (PDF/TXT)\", type=[\"pdf\", \"txt\"])\n",
    "    target_role = st.sidebar.text_input(\"Target Role\", value=\"Data Scientist\")\n",
    "    country = st.sidebar.text_input(\"Country\", value=\"US\")\n",
    "    location = st.sidebar.text_input(\"Location\", value=\"United States\")\n",
    "    remote = st.sidebar.checkbox(\"Remote preferred\", value=True)\n",
    "    salary = st.sidebar.text_input(\"Salary preference (optional)\", value=\"\")\n",
    "    user_phone = st.sidebar.text_input(\"Phone for SMS (optional)\", value=\"\")\n",
    "\n",
    "    st.sidebar.subheader(\"Loop Controls\")\n",
    "    discovery_threshold = st.sidebar.slider(\"Discovery confidence threshold\", 0.50, 0.90, 0.70, 0.05)\n",
    "    max_refinements = st.sidebar.slider(\"Max refinements\", 1, 5, 3, 1)\n",
    "\n",
    "    run_btn = st.sidebar.button(\"🚀 RUN ONE-CLICK\", type=\"primary\", use_container_width=True, disabled=(resume_file is None))\n",
    "\n",
    "    st.sidebar.subheader(\"Existing Run\")\n",
    "    run_id_in = st.sidebar.text_input(\"Run ID\", value=st.session_state.get(\"run_id\", \"\"))\n",
    "\n",
    "    def _poll(run_id: str) -> Optional[Dict[str, Any]]:\n",
    "        try:\n",
    "            r = requests.get(f\"{API_BASE}/status/{run_id}\", timeout=20)\n",
    "            if r.status_code != 200:\n",
    "                return None\n",
    "            return r.json()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    if run_btn:\n",
    "        prefs = {\n",
    "            \"target_role\": target_role,\n",
    "            \"country\": country,\n",
    "            \"location\": location,\n",
    "            \"remote\": remote,\n",
    "            \"salary\": salary,\n",
    "            \"user_phone\": user_phone.strip() or None,\n",
    "            \"discovery_threshold\": float(discovery_threshold),\n",
    "            \"max_refinements\": int(max_refinements),\n",
    "        }\n",
    "\n",
    "        files = {\"resume\": (resume_file.name, resume_file.getvalue())}\n",
    "        data = {\"preferences_json\": json.dumps(prefs)}\n",
    "        r = requests.post(f\"{API_BASE}/analyze\", files=files, data=data, timeout=120)\n",
    "        if r.status_code >= 400:\n",
    "            st.error(f\"/analyze failed: {r.status_code} {r.text[:500]}\")\n",
    "        else:\n",
    "            out = r.json()\n",
    "            st.session_state[\"run_id\"] = out[\"run_id\"]\n",
    "            st.success(f\"Run started: {out['run_id']} (status: {out['status']})\")\n",
    "\n",
    "    run_id = st.session_state.get(\"run_id\") or run_id_in.strip()\n",
    "    if not run_id:\n",
    "        st.info(\"Upload a resume and click RUN, or paste an existing run_id in the sidebar.\")\n",
    "        return\n",
    "\n",
    "    st.subheader(f\"Run: {run_id}\")\n",
    "    colA, colB, colC = st.columns([1, 1, 1])\n",
    "    with colA:\n",
    "        if st.button(\"🔄 Refresh\"):\n",
    "            pass\n",
    "    data = _poll(run_id)\n",
    "    if not data:\n",
    "        st.warning(\"Run not found yet. Try refresh.\")\n",
    "        return\n",
    "\n",
    "    status = data.get(\"status\", \"unknown\")\n",
    "    meta = data.get(\"meta\", {}) or {}\n",
    "    feed = meta.get(\"live_feed\", []) or []\n",
    "    steps = data.get(\"steps\", []) or []\n",
    "    artifacts = data.get(\"artifacts\", {}) or {}\n",
    "    pending = meta.get(\"pending_action\")\n",
    "\n",
    "    with colA:\n",
    "        st.metric(\"Status\", status)\n",
    "    with colB:\n",
    "        st.metric(\"Pending Action\", str(pending))\n",
    "    with colC:\n",
    "        js = (meta.get(\"job_scores\") or {})\n",
    "        if js:\n",
    "            job_id, score = next(iter(js.items()))\n",
    "            st.metric(\"Top Match Score\", f\"{float(score)*100:.2f}%\")\n",
    "\n",
    "    # Live Agent Feed\n",
    "    st.markdown(\"### Live Agent Feed\")\n",
    "    if not feed:\n",
    "        st.info(\"No feed yet.\")\n",
    "    else:\n",
    "        for ev in feed[-120:]:\n",
    "            st.write(f\"**[{ev.get('layer')} {ev.get('agent')}]** {ev.get('message')}\")\n",
    "\n",
    "    # Audit Trail\n",
    "    st.markdown(\"### Audit Trail (Steps)\")\n",
    "    with st.expander(\"Show steps\"):\n",
    "        for s in steps:\n",
    "            st.write(f\"- [{s.get('layer_id')}] {s.get('tool_name')} | {s.get('status')} | {s.get('step_id')}\")\n",
    "\n",
    "    # Ranking view\n",
    "    st.markdown(\"### One-Click Ranking\")\n",
    "    ranking_ref = artifacts.get(\"ranking\")\n",
    "    ranking = None\n",
    "    if ranking_ref and ranking_ref.get(\"path\") and Path(ranking_ref[\"path\"]).exists():\n",
    "        ranking = json.loads(Path(ranking_ref[\"path\"]).read_text(encoding=\"utf-8\"))\n",
    "        st.dataframe(\n",
    "            [{\n",
    "                \"score_%\": round(float(x.get(\"overall_match_percent\",0.0)), 2),\n",
    "                \"role\": x.get(\"role_title\"),\n",
    "                \"company\": x.get(\"company\"),\n",
    "                \"source\": x.get(\"source\"),\n",
    "                \"url\": x.get(\"url\"),\n",
    "                \"missing_required\": \", \".join((x.get(\"missing_required_skills\") or [])[:5]),\n",
    "            } for x in ranking],\n",
    "            use_container_width=True\n",
    "        )\n",
    "    else:\n",
    "        st.caption(\"Ranking not available yet.\")\n",
    "\n",
    "    # HITL controls\n",
    "    st.markdown(\"### Human-in-the-Loop Controls\")\n",
    "    if status == \"needs_human_approval\" and pending == \"review_ranking\":\n",
    "        c1, c2 = st.columns(2)\n",
    "        with c1:\n",
    "            if st.button(\"✅ Approve Ranking → Generate Drafts\", type=\"primary\", use_container_width=True):\n",
    "                rr = requests.post(f\"{API_BASE}/action/{run_id}\", json={\"action_type\": \"approve_ranking\", \"payload\": {}}, timeout=30)\n",
    "                st.success(\"Approved. Draft generation started.\")\n",
    "        with c2:\n",
    "            reason = st.text_input(\"Reason to refine ranking (optional)\", value=\"\")\n",
    "            if st.button(\"❌ Reject Ranking → Re-run Discovery\", use_container_width=True):\n",
    "                rr = requests.post(f\"{API_BASE}/action/{run_id}\", json={\"action_type\": \"reject_ranking\", \"payload\": {\"reason\": reason}}, timeout=30)\n",
    "                st.warning(\"Rejected. Discovery refinement started.\")\n",
    "\n",
    "    if status == \"needs_human_approval\" and pending == \"review_drafts\":\n",
    "        c1, c2 = st.columns(2)\n",
    "        with c1:\n",
    "            if st.button(\"✅ Approve Drafts → Submit (Simulated)\", type=\"primary\", use_container_width=True):\n",
    "                rr = requests.post(f\"{API_BASE}/action/{run_id}\", json={\"action_type\": \"approve_drafts\", \"payload\": {}}, timeout=30)\n",
    "                st.success(\"Approved. Submission started.\")\n",
    "        with c2:\n",
    "            reason = st.text_input(\"Reason to revise drafts (optional)\", value=\"\")\n",
    "            if st.button(\"❌ Reject Drafts → Back to Ranking\", use_container_width=True):\n",
    "                rr = requests.post(f\"{API_BASE}/action/{run_id}\", json={\"action_type\": \"reject_drafts\", \"payload\": {\"reason\": reason}}, timeout=30)\n",
    "                st.warning(\"Rejected drafts. Returning to ranking review.\")\n",
    "\n",
    "    # Drafts bundle preview\n",
    "    st.markdown(\"### Drafts + Strategies\")\n",
    "    drafts_ref = artifacts.get(\"drafts_bundle\")\n",
    "    if drafts_ref and drafts_ref.get(\"path\") and Path(drafts_ref[\"path\"]).exists():\n",
    "        bundle = json.loads(Path(drafts_ref[\"path\"]).read_text(encoding=\"utf-8\"))\n",
    "        st.json(bundle)\n",
    "    else:\n",
    "        st.caption(\"Draft bundle not available yet.\")\n",
    "\n",
    "    # Downloads\n",
    "    st.markdown(\"### Downloads\")\n",
    "    d1, d2 = st.columns(2)\n",
    "    with d1:\n",
    "        zip_ref = artifacts.get(\"career_dossier_zip\")\n",
    "        if zip_ref and zip_ref.get(\"path\") and Path(zip_ref[\"path\"]).exists():\n",
    "            p = Path(zip_ref[\"path\"])\n",
    "            st.download_button(\"Download Career Dossier (ZIP)\", data=p.read_bytes(), file_name=p.name, mime=\"application/zip\")\n",
    "        else:\n",
    "            st.caption(\"Dossier ZIP not ready.\")\n",
    "    with d2:\n",
    "        pdf_ref = artifacts.get(\"xai_transparency_pdf\")\n",
    "        if pdf_ref and pdf_ref.get(\"path\") and Path(pdf_ref[\"path\"]).exists():\n",
    "            p = Path(pdf_ref[\"path\"])\n",
    "            st.download_button(\"Download XAI Transparency (PDF)\", data=p.read_bytes(), file_name=p.name, mime=\"application/pdf\")\n",
    "        else:\n",
    "            st.caption(\"XAI PDF not ready.\")\n",
    "\n",
    "    with st.expander(\"Full State JSON\"):\n",
    "        st.json(data)\n",
    "'''\n",
    "safe_overwrite(\"app/ui/dashboard.py\", DASHBOARD)\n",
    "\n",
    "APP_MAIN = r'''\n",
    "from __future__ import annotations\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ensure src/ is on path for streamlit local runs\n",
    "ROOT = Path(__file__).resolve().parents[1]\n",
    "SRC = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from app.ui.dashboard import main\n",
    "\n",
    "main()\n",
    "'''\n",
    "safe_overwrite(\"app/main.py\", APP_MAIN)\n",
    "\n",
    "RUN_APP = r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def main() -> int:\n",
    "    \"\"\"\n",
    "    Description: Launch FastAPI brain + Streamlit Mission Control locally (indestructible).\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: exit code\n",
    "    \"\"\"\n",
    "    root = Path(__file__).resolve().parent\n",
    "    env = os.environ.copy()\n",
    "    env[\"PYTHONPATH\"] = str(root / \"src\") + (os.pathsep + env.get(\"PYTHONPATH\", \"\") if env.get(\"PYTHONPATH\") else \"\")\n",
    "\n",
    "    uvicorn_cmd = [sys.executable, \"-m\", \"uvicorn\", \"careeragent.api.main:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\", \"--reload\"]\n",
    "    streamlit_cmd = [sys.executable, \"-m\", \"streamlit\", \"run\", \"app/main.py\", \"--server.port\", \"8501\"]\n",
    "\n",
    "    print(\"Starting FastAPI:\", \" \".join(uvicorn_cmd))\n",
    "    api = subprocess.Popen(uvicorn_cmd, env=env)\n",
    "\n",
    "    time.sleep(1.2)\n",
    "\n",
    "    print(\"Starting Streamlit:\", \" \".join(streamlit_cmd))\n",
    "    ui = subprocess.Popen(streamlit_cmd, env=env)\n",
    "\n",
    "    try:\n",
    "        api.wait()\n",
    "        ui.wait()\n",
    "        return 0\n",
    "    except KeyboardInterrupt:\n",
    "        api.terminate()\n",
    "        ui.terminate()\n",
    "        return 130\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    raise SystemExit(main())\n",
    "'''\n",
    "safe_overwrite(\"run_app.py\", RUN_APP)\n",
    "\n",
    "# Minimal dependency hint (not auto-editing pyproject here to avoid accidental toml corruption)\n",
    "print(\"\\nNEXT: Ensure deps installed:\")\n",
    "print(\"uv add fastapi uvicorn streamlit reportlab twilio pydantic-settings httpx pypdf\")\n",
    "print(\"uv sync\")\n",
    "print(\"\\nThen run:\")\n",
    "print(\"uv run python run_app.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06b9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careeragent-ai (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
