{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef6aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CWD = /Users/ganeshprasadbhandari/Documents/D_drive/clark/careeragent-ai\n",
      "BACKUP: /Users/ganeshprasadbhandari/Documents/D_drive/clark/careeragent-ai/src/careeragent/langgraph/runtime_nodes.py.bak_20260221_174648\n",
      "WROTE: /Users/ganeshprasadbhandari/Documents/D_drive/clark/careeragent-ai/src/careeragent/langgraph/runtime_nodes.py\n",
      "✅ Patched runtime_nodes: L3 is now timeout-safe + saves job URLs to artifacts + daily_jobs.\n",
      "Restart backend and start a NEW run.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "if ROOT.name == \"notebooks_v2\":\n",
    "    os.chdir(ROOT.parent)\n",
    "ROOT = Path.cwd().resolve()\n",
    "assert (ROOT / \"src\").exists(), f\"Not at repo root. CWD={ROOT}\"\n",
    "print(\"✅ CWD =\", ROOT)\n",
    "\n",
    "def backup_write(rel_path: str, content: str) -> None:\n",
    "    p = ROOT / rel_path\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if p.exists():\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        bak = p.with_suffix(p.suffix + f\".bak_{ts}\")\n",
    "        bak.write_text(p.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "        print(\"BACKUP:\", bak)\n",
    "    p.write_text(content, encoding=\"utf-8\")\n",
    "    print(\"WROTE:\", p)\n",
    "\n",
    "backup_write(\"src/careeragent/langgraph/runtime_nodes.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import urllib.parse\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "import httpx\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _utc_now() -> str:\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "\n",
    "def _apply_delta(state: Dict[str, Any], delta: Any) -> Dict[str, Any]:\n",
    "    if not isinstance(delta, dict):\n",
    "        return state\n",
    "\n",
    "    # list reducers\n",
    "    for k in (\"live_feed\", \"attempts\", \"gates\", \"evaluations\", \"steps\"):\n",
    "        if k in delta and isinstance(delta[k], list):\n",
    "            state.setdefault(k, [])\n",
    "            state[k].extend(delta[k])\n",
    "\n",
    "    # dict reducers\n",
    "    if \"artifacts\" in delta and isinstance(delta[\"artifacts\"], dict):\n",
    "        state.setdefault(\"artifacts\", {})\n",
    "        state[\"artifacts\"].update(delta[\"artifacts\"])\n",
    "\n",
    "    # overwrite remaining keys\n",
    "    for k, v in delta.items():\n",
    "        if k in (\"live_feed\", \"attempts\", \"gates\", \"evaluations\", \"steps\", \"artifacts\"):\n",
    "            continue\n",
    "        state[k] = v\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def _feed(state: Dict[str, Any], layer: str, agent: str, message: str) -> None:\n",
    "    state.setdefault(\"live_feed\", [])\n",
    "    state[\"live_feed\"].append({\"layer\": layer, \"agent\": agent, \"message\": message})\n",
    "\n",
    "\n",
    "def _log_attempt(\n",
    "    state: Dict[str, Any],\n",
    "    *,\n",
    "    layer: str,\n",
    "    agent: str,\n",
    "    tool: str,\n",
    "    model: Optional[str],\n",
    "    status: str,\n",
    "    confidence: float,\n",
    "    error: Optional[str] = None,\n",
    ") -> None:\n",
    "    state.setdefault(\"attempts\", [])\n",
    "    state[\"attempts\"].append({\n",
    "        \"layer_id\": layer,\n",
    "        \"agent\": agent,\n",
    "        \"tool\": tool,\n",
    "        \"model\": model,\n",
    "        \"status\": status,\n",
    "        \"confidence\": float(confidence),\n",
    "        \"error\": error,\n",
    "        \"at_utc\": _utc_now(),\n",
    "    })\n",
    "\n",
    "\n",
    "def _pick_fn(mod: Any, *names: str) -> Optional[Callable[..., Any]]:\n",
    "    for n in names:\n",
    "        fn = getattr(mod, n, None)\n",
    "        if callable(fn):\n",
    "            return fn\n",
    "    return None\n",
    "\n",
    "\n",
    "def _artifacts_root() -> Path:\n",
    "    # local-first standard\n",
    "    return Path(\"src/careeragent/artifacts\").resolve()\n",
    "\n",
    "\n",
    "def _runs_dir(run_id: str) -> Path:\n",
    "    d = _artifacts_root() / \"runs\" / run_id\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "def _daily_dir() -> Path:\n",
    "    day = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    d = _artifacts_root() / \"daily_jobs\" / day\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "def _save_json(path: Path, obj: Any) -> str:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "    return str(path)\n",
    "\n",
    "\n",
    "def _fast_l0_guard(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    resume = (state.get(\"resume_text\") or \"\").lower()\n",
    "    signals = [\"ignore previous instructions\", \"system prompt\", \"developer message\", \"jailbreak\", \"exfiltrate\"]\n",
    "    blocked = any(s in resume for s in signals)\n",
    "\n",
    "    attempt = {\n",
    "        \"layer_id\": \"L0\",\n",
    "        \"agent\": \"SanitizeAgent\",\n",
    "        \"tool\": \"local.prompt_injection_heuristic\",\n",
    "        \"model\": None,\n",
    "        \"status\": \"failed\" if blocked else \"ok\",\n",
    "        \"confidence\": 0.10 if blocked else 0.95,\n",
    "        \"error\": \"prompt_injection\" if blocked else None,\n",
    "        \"at_utc\": _utc_now(),\n",
    "    }\n",
    "\n",
    "    msg = \"Security passed.\" if not blocked else \"Blocked: prompt injection detected.\"\n",
    "    delta: Dict[str, Any] = {\"live_feed\": [{\"layer\": \"L0\", \"agent\": \"SanitizeAgent\", \"message\": msg}], \"attempts\": [attempt]}\n",
    "    if blocked:\n",
    "        delta[\"status\"] = \"blocked\"\n",
    "        delta[\"pending_action\"] = \"security_blocked\"\n",
    "    return delta\n",
    "\n",
    "\n",
    "# ---------- L3 SAFE DISCOVERY ----------\n",
    "async def _serper_search(api_key: str, query: str, *, num: int = 10, tbs: Optional[str] = None, timeout_s: float = 12.0) -> Dict[str, Any]:\n",
    "    headers = {\"X-API-KEY\": api_key, \"Content-Type\": \"application/json\"}\n",
    "    payload: Dict[str, Any] = {\"q\": query, \"num\": num}\n",
    "    if tbs:\n",
    "        payload[\"tbs\"] = tbs\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=timeout_s) as client:\n",
    "        r = await client.post(\"https://google.serper.dev/search\", headers=headers, json=payload)\n",
    "\n",
    "    if r.status_code == 403:\n",
    "        return {\"ok\": False, \"error\": \"serper_403_quota\", \"items\": []}\n",
    "    if r.status_code >= 400:\n",
    "        return {\"ok\": False, \"error\": f\"serper_{r.status_code}\", \"items\": []}\n",
    "\n",
    "    organic = (r.json().get(\"organic\") or [])\n",
    "    items = [{\"title\": x.get(\"title\") or \"\", \"url\": x.get(\"link\") or \"\", \"snippet\": x.get(\"snippet\") or \"\"} for x in organic]\n",
    "    return {\"ok\": True, \"error\": None, \"items\": items}\n",
    "\n",
    "\n",
    "async def _mcp_search(server_url: str, token: str, queries: List[str], recency_hours: float, *, timeout_s: float = 15.0) -> Dict[str, Any]:\n",
    "    url = server_url.rstrip(\"/\") + \"/invoke\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"tool\": \"jobs.search\", \"payload\": {\"queries\": queries, \"recency_hours\": recency_hours}}\n",
    "    async with httpx.AsyncClient(timeout=timeout_s) as client:\n",
    "        r = await client.post(url, headers=headers, json=payload)\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        return {\"ok\": False, \"error\": f\"mcp_{r.status_code}\", \"items\": []}\n",
    "\n",
    "    data = r.json()\n",
    "    hits = data.get(\"results\") or data.get(\"jobs\") or []\n",
    "    items = []\n",
    "    for it in hits:\n",
    "        u = it.get(\"url\") or it.get(\"link\") or \"\"\n",
    "        items.append({\"title\": it.get(\"title\") or \"\", \"url\": u, \"snippet\": it.get(\"snippet\") or \"\", \"source\": \"mcp\"})\n",
    "    return {\"ok\": True, \"error\": None, \"items\": items}\n",
    "\n",
    "\n",
    "def _fallback_board_urls(role: str, location: str) -> List[Dict[str, Any]]:\n",
    "    q = urllib.parse.quote_plus(f\"{role} {location}\")\n",
    "    loc = urllib.parse.quote_plus(location)\n",
    "\n",
    "    return [\n",
    "        {\"title\": f\"LinkedIn search: {role}\", \"url\": f\"https://www.linkedin.com/jobs/search/?keywords={q}&location={loc}\", \"snippet\": \"Fallback job-board search\"},\n",
    "        {\"title\": f\"Indeed search: {role}\", \"url\": f\"https://www.indeed.com/jobs?q={q}&l={loc}\", \"snippet\": \"Fallback job-board search\"},\n",
    "        {\"title\": f\"Dice search: {role}\", \"url\": f\"https://www.dice.com/jobs?q={q}&location={loc}\", \"snippet\": \"Fallback job-board search\"},\n",
    "        {\"title\": f\"ZipRecruiter search: {role}\", \"url\": f\"https://www.ziprecruiter.com/jobs-search?search={q}&location={loc}\", \"snippet\": \"Fallback job-board search\"},\n",
    "        {\"title\": f\"Glassdoor search: {role}\", \"url\": f\"https://www.google.com/search?q=site:glassdoor.com+{q}\", \"snippet\": \"Fallback via Google\"},\n",
    "        {\"title\": f\"Monster search: {role}\", \"url\": f\"https://www.google.com/search?q=site:monster.com+{q}\", \"snippet\": \"Fallback via Google\"},\n",
    "        {\"title\": f\"Lever search: {role}\", \"url\": f\"https://www.google.com/search?q=site:jobs.lever.co+{q}\", \"snippet\": \"Fallback via Google\"},\n",
    "        {\"title\": f\"Greenhouse search: {role}\", \"url\": f\"https://www.google.com/search?q=site:boards.greenhouse.io+{q}\", \"snippet\": \"Fallback via Google\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "async def _l3_discovery_safe(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    prefs = state.get(\"preferences\") or {}\n",
    "    roles = prefs.get(\"target_roles\") or [prefs.get(\"target_role\") or \"Data Scientist\"]\n",
    "    roles = [str(r).strip() for r in roles if str(r).strip()][:4]\n",
    "    location = str(prefs.get(\"location\") or \"United States\")\n",
    "    recency_h = float(prefs.get(\"recency_hours\") or 36.0)\n",
    "    tbs = \"qdr:d\" if recency_h <= 36 else None\n",
    "    max_jobs = int(prefs.get(\"max_jobs\") or 40)\n",
    "\n",
    "    api_key = os.getenv(\"SERPER_API_KEY\", \"\")\n",
    "    mcp_url = os.getenv(\"MCP_SERVER_URL\", \"\")\n",
    "    mcp_tok = os.getenv(\"MCP_API_KEY\") or os.getenv(\"MCP_AUTH_TOKEN\") or \"\"\n",
    "\n",
    "    # Build 8 board-focused Serper queries (keeps quota sane)\n",
    "    board_domains = [\n",
    "        \"linkedin.com/jobs\",\n",
    "        \"indeed.com\",\n",
    "        \"glassdoor.com\",\n",
    "        \"ziprecruiter.com\",\n",
    "        \"monster.com\",\n",
    "        \"dice.com\",\n",
    "        \"jobs.lever.co\",\n",
    "        \"boards.greenhouse.io\",\n",
    "    ]\n",
    "    # Use only the strongest role for board queries; keep others as generic\n",
    "    primary_role = roles[0] if roles else \"Data Scientist\"\n",
    "    queries = [f'site:{d} \"{primary_role}\" \"{location}\"' for d in board_domains]\n",
    "    queries.extend([f'{r} {location} apply' for r in roles[:2]])\n",
    "    state[\"discovery_queries\"] = queries\n",
    "\n",
    "    items: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Tool A: Serper (concurrent, each capped)\n",
    "    if api_key:\n",
    "        async def one(q: str):\n",
    "            try:\n",
    "                return await asyncio.wait_for(_serper_search(api_key, q, num=10, tbs=tbs, timeout_s=12.0), timeout=14.0)\n",
    "            except Exception as e:\n",
    "                return {\"ok\": False, \"error\": str(e), \"items\": []}\n",
    "\n",
    "        results = await asyncio.gather(*[one(q) for q in queries[:10]], return_exceptions=False)\n",
    "        for r in results:\n",
    "            ok = bool(r.get(\"ok\"))\n",
    "            err = r.get(\"error\")\n",
    "            conf = 0.75 if ok and r.get(\"items\") else 0.30\n",
    "            _log_attempt(state, layer=\"L3\", agent=\"DiscoveryAgent\", tool=\"serper.search\", model=None,\n",
    "                         status=\"ok\" if ok else \"failed\", confidence=conf, error=err)\n",
    "            items.extend([{\"title\": x[\"title\"], \"url\": x[\"url\"], \"snippet\": x[\"snippet\"], \"source\": \"serper\"} for x in (r.get(\"items\") or [])])\n",
    "\n",
    "    # Tool B: MCP fallback if Serper empty or quota\n",
    "    if (not items) and mcp_url and mcp_tok:\n",
    "        try:\n",
    "            r = await asyncio.wait_for(_mcp_search(mcp_url, mcp_tok, queries, recency_h, timeout_s=15.0), timeout=18.0)\n",
    "            ok = bool(r.get(\"ok\"))\n",
    "            err = r.get(\"error\")\n",
    "            conf = 0.85 if ok and r.get(\"items\") else 0.30\n",
    "            _log_attempt(state, layer=\"L3\", agent=\"DiscoveryAgent\", tool=\"mcp.jobs.search\", model=None,\n",
    "                         status=\"ok\" if ok else \"failed\", confidence=conf, error=err)\n",
    "            items.extend(r.get(\"items\") or [])\n",
    "        except Exception as e:\n",
    "            _log_attempt(state, layer=\"L3\", agent=\"DiscoveryAgent\", tool=\"mcp.jobs.search\", model=None,\n",
    "                         status=\"failed\", confidence=0.0, error=str(e))\n",
    "\n",
    "    # Tool C: local fallback URLs (always returns quickly)\n",
    "    if not items:\n",
    "        _log_attempt(state, layer=\"L3\", agent=\"DiscoveryAgent\", tool=\"local.fallback_board_urls\", model=None,\n",
    "                     status=\"ok\", confidence=0.55, error=None)\n",
    "        items = _fallback_board_urls(primary_role, location)\n",
    "\n",
    "    # Normalize + dedupe\n",
    "    seen = set()\n",
    "    jobs_raw: List[Dict[str, Any]] = []\n",
    "    for it in items:\n",
    "        url = (it.get(\"url\") or \"\").strip()\n",
    "        if not url:\n",
    "            continue\n",
    "        if url in seen:\n",
    "            continue\n",
    "        seen.add(url)\n",
    "        jobs_raw.append({\n",
    "            \"title\": it.get(\"title\") or \"\",\n",
    "            \"url\": url,\n",
    "            \"snippet\": it.get(\"snippet\") or \"\",\n",
    "            \"source\": it.get(\"source\") or \"unknown\",\n",
    "        })\n",
    "        if len(jobs_raw) >= max_jobs:\n",
    "            break\n",
    "\n",
    "    # Persist artifacts\n",
    "    run_id = str(state.get(\"run_id\") or \"run\")\n",
    "    run_dir = _runs_dir(run_id)\n",
    "    jobs_path = run_dir / \"jobs_raw.json\"\n",
    "    daily_path = _daily_dir() / f\"{run_id}_jobs_raw.json\"\n",
    "\n",
    "    artifacts = {\n",
    "        \"jobs_raw\": {\"path\": _save_json(jobs_path, jobs_raw), \"content_type\": \"application/json\"},\n",
    "        \"jobs_raw_daily\": {\"path\": _save_json(daily_path, {\"run_id\": run_id, \"at_utc\": _utc_now(), \"jobs\": jobs_raw}), \"content_type\": \"application/json\"},\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"jobs_raw\": jobs_raw,\n",
    "        \"artifacts\": artifacts,\n",
    "        \"live_feed\": [{\"layer\": \"L3\", \"agent\": \"DiscoveryAgent\", \"message\": f\"Discovery completed: {len(jobs_raw)} jobs (saved to artifacts).\"}],\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- public API (used by RunManagerService) ----------\n",
    "async def run_single_layer(state: Dict[str, Any], layer: str) -> Dict[str, Any]:\n",
    "    layer = (layer or \"\").upper().strip()\n",
    "\n",
    "    # L0 always instant\n",
    "    if layer == \"L0\":\n",
    "        return _apply_delta(state, _fast_l0_guard(state))\n",
    "\n",
    "    # L3 is now indestructible\n",
    "    if layer == \"L3\":\n",
    "        return _apply_delta(state, await _l3_discovery_safe(state))\n",
    "\n",
    "    # L2/L4/L5 use your existing nodes.py (name-flexible)\n",
    "    if layer in (\"L2\", \"L4\", \"L5\"):\n",
    "        from careeragent.langgraph import nodes as nodes_mod\n",
    "\n",
    "        l2 = _pick_fn(nodes_mod, \"l2_parser_node\", \"l2_parse_node\", \"l2_intake_node\", \"parser_node\")\n",
    "        l4 = _pick_fn(nodes_mod, \"l4_match_node\", \"matcher_node\", \"match_node\", \"score_node\")\n",
    "        l5 = _pick_fn(nodes_mod, \"l5_rank_node\", \"rank_node\", \"evaluator_rank_node\")\n",
    "\n",
    "        fn_map = {\"L2\": l2, \"L4\": l4, \"L5\": l5}\n",
    "        fn = fn_map.get(layer)\n",
    "        if not fn:\n",
    "            _feed(state, \"L1\", \"Runtime\", f\"{layer} node not found in careeragent.langgraph.nodes.py\")\n",
    "            state[\"status\"] = \"needs_human_approval\"\n",
    "            state[\"pending_action\"] = f\"missing_{layer.lower()}_node\"\n",
    "            return state\n",
    "\n",
    "        delta = await fn(state)  # type: ignore[misc]\n",
    "        state = _apply_delta(state, delta)\n",
    "\n",
    "        if layer == \"L5\" and state.get(\"ranking\") and not state.get(\"pending_action\"):\n",
    "            state[\"status\"] = \"needs_human_approval\"\n",
    "            state[\"pending_action\"] = \"review_ranking\"\n",
    "        return state\n",
    "\n",
    "    # L6–L9 (if present)\n",
    "    if layer in (\"L6\", \"L7\", \"L8\", \"L9\"):\n",
    "        from careeragent.langgraph.nodes_l6_l9 import (\n",
    "            l6_draft_node, l6_evaluator_node,\n",
    "            l7_apply_node, l7_evaluator_node,\n",
    "            l8_tracker_node, l8_evaluator_node,\n",
    "            l9_analytics_node,\n",
    "        )\n",
    "\n",
    "        if layer == \"L6\":\n",
    "            state = _apply_delta(state, await l6_draft_node(state))      # type: ignore[arg-type]\n",
    "            state = _apply_delta(state, await l6_evaluator_node(state))  # type: ignore[arg-type]\n",
    "            return state\n",
    "        if layer == \"L7\":\n",
    "            state = _apply_delta(state, await l7_apply_node(state))      # type: ignore[arg-type]\n",
    "            state = _apply_delta(state, await l7_evaluator_node(state))  # type: ignore[arg-type]\n",
    "            return state\n",
    "        if layer == \"L8\":\n",
    "            state = _apply_delta(state, await l8_tracker_node(state))      # type: ignore[arg-type]\n",
    "            state = _apply_delta(state, await l8_evaluator_node(state))    # type: ignore[arg-type]\n",
    "            return state\n",
    "        if layer == \"L9\":\n",
    "            state = _apply_delta(state, await l9_analytics_node(state))    # type: ignore[arg-type]\n",
    "            return state\n",
    "\n",
    "    _feed(state, \"L1\", \"Runtime\", f\"Layer {layer} not implemented.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "async def approve_ranking_flow(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    from careeragent.langgraph.nodes_l6_l9 import l6_draft_node, l6_evaluator_node\n",
    "    state[\"status\"] = \"running\"\n",
    "    state[\"pending_action\"] = None\n",
    "    _feed(state, \"L6\", \"HITL\", \"Ranking approved. Generating drafts…\")\n",
    "    state = _apply_delta(state, await l6_draft_node(state))      # type: ignore[arg-type]\n",
    "    state = _apply_delta(state, await l6_evaluator_node(state))  # type: ignore[arg-type]\n",
    "    state[\"status\"] = \"needs_human_approval\"\n",
    "    state[\"pending_action\"] = \"review_drafts\"\n",
    "    return state\n",
    "\n",
    "\n",
    "async def approve_drafts_flow(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    from careeragent.langgraph.nodes_l6_l9 import (\n",
    "        l7_apply_node, l7_evaluator_node,\n",
    "        l8_tracker_node, l8_evaluator_node,\n",
    "        l9_analytics_node,\n",
    "    )\n",
    "    state[\"status\"] = \"running\"\n",
    "    state[\"pending_action\"] = None\n",
    "    _feed(state, \"L7\", \"HITL\", \"Drafts approved. Applying + tracking + analytics…\")\n",
    "    state = _apply_delta(state, await l7_apply_node(state))      # type: ignore[arg-type]\n",
    "    state = _apply_delta(state, await l7_evaluator_node(state))  # type: ignore[arg-type]\n",
    "    if state.get(\"status\") == \"needs_human_approval\":\n",
    "        return state\n",
    "    state = _apply_delta(state, await l8_tracker_node(state))      # type: ignore[arg-type]\n",
    "    state = _apply_delta(state, await l8_evaluator_node(state))    # type: ignore[arg-type]\n",
    "    if state.get(\"status\") == \"needs_human_approval\":\n",
    "        return state\n",
    "    state = _apply_delta(state, await l9_analytics_node(state))    # type: ignore[arg-type]\n",
    "    state[\"status\"] = \"completed\"\n",
    "    state[\"pending_action\"] = None\n",
    "    _feed(state, \"L9\", \"HITL\", \"Run completed.\")\n",
    "    return state\n",
    "''')\n",
    "\n",
    "print(\"✅ Patched runtime_nodes: L3 is now timeout-safe + saves job URLs to artifacts + daily_jobs.\")\n",
    "print(\"Restart backend and start a NEW run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID=b5d608fef245469881507ae41e266156\n",
    "curl -sS \"http://127.0.0.1:8000/status/$RUN_ID\" | python -c \"import sys,json; s=json.load(sys.stdin); print('steps',[(x.get('layer_id'),x.get('status'),x.get('finished_at_utc')) for x in (s.get('steps') or [])]); print('jobs_raw',len(s.get('jobs_raw') or [])); print('jobs_file',(s.get('artifacts') or {}).get('jobs_raw'))\"\n",
    "ls -la \"src/careeragent/artifacts/runs/$RUN_ID/jobs_raw.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careeragent-ai (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
