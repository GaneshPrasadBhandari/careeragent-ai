{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "if ROOT.name == \"notebooks_v2\":\n",
    "    os.chdir(ROOT.parent)\n",
    "ROOT = Path.cwd().resolve()\n",
    "assert (ROOT / \"src\").exists(), f\"Not at repo root. CWD={ROOT}\"\n",
    "print(\"âœ… CWD =\", ROOT)\n",
    "\n",
    "def backup_write(rel_path: str, content: str) -> None:\n",
    "    p = ROOT / rel_path\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if p.exists():\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        bak = p.with_suffix(p.suffix + f\".bak_{ts}\")\n",
    "        bak.write_text(p.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "        print(\"BACKUP:\", bak)\n",
    "    p.write_text(content, encoding=\"utf-8\")\n",
    "    print(\"WROTE:\", p)\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Backend: run_manager_service.py\n",
    "#    - store selected_job_urls\n",
    "#    - support reject_ranking / reject_drafts\n",
    "# -------------------------------\n",
    "backup_write(\"src/careeragent/api/run_manager_service.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import concurrent.futures as cf\n",
    "import copy\n",
    "import threading\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "from uuid import uuid4\n",
    "\n",
    "from careeragent.services.db_service import SqliteStateStore\n",
    "from careeragent.langgraph.runtime_nodes import run_single_layer, approve_ranking_flow, approve_drafts_flow\n",
    "\n",
    "\n",
    "def utc_now() -> str:\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "\n",
    "def artifacts_root() -> Path:\n",
    "    return Path(\"src/careeragent/artifacts\").resolve()\n",
    "\n",
    "\n",
    "class RunManagerService:\n",
    "    \"\"\"\n",
    "    Description: Indestructible background runner with hard timeouts + HITL actions.\n",
    "    Layer: L8\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._store = SqliteStateStore()\n",
    "\n",
    "    def _runs_dir(self, run_id: str) -> Path:\n",
    "        d = artifacts_root() / \"runs\" / run_id\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "        return d\n",
    "\n",
    "    def save_state(self, *, run_id: str, state: Dict[str, Any]) -> None:\n",
    "        state.setdefault(\"meta\", {})\n",
    "        state[\"meta\"][\"heartbeat_utc\"] = utc_now()\n",
    "        self._store.upsert_state(run_id=run_id, status=str(state.get(\"status\", \"unknown\")), state=state, updated_at_utc=utc_now())\n",
    "\n",
    "    def get_state(self, run_id: str) -> Optional[Dict[str, Any]]:\n",
    "        return self._store.get_state(run_id=run_id)\n",
    "\n",
    "    def create_run(self, *, resume_filename: str, resume_text: str, resume_bytes: bytes, preferences: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        run_id = uuid4().hex\n",
    "        run_dir = self._runs_dir(run_id)\n",
    "        (run_dir / \"resume_upload.bin\").write_bytes(resume_bytes)\n",
    "        (run_dir / \"resume_raw.txt\").write_text(resume_text, encoding=\"utf-8\")\n",
    "\n",
    "        thresholds = (preferences.get(\"thresholds\") or {})\n",
    "        if \"default\" in thresholds:\n",
    "            d = float(thresholds[\"default\"])\n",
    "            thresholds.setdefault(\"parser\", d)\n",
    "            thresholds.setdefault(\"discovery\", d)\n",
    "            thresholds.setdefault(\"match\", d)\n",
    "            thresholds.setdefault(\"draft\", d)\n",
    "\n",
    "        state: Dict[str, Any] = {\n",
    "            \"run_id\": run_id,\n",
    "            \"status\": \"running\",\n",
    "            \"pending_action\": None,\n",
    "            \"hitl_reason\": None,\n",
    "            \"hitl_payload\": {},\n",
    "            \"thresholds\": thresholds,\n",
    "            \"max_retries\": int(preferences.get(\"max_refinements\", 3)),\n",
    "            \"layer_retry_count\": {},\n",
    "            \"preferences\": preferences,\n",
    "            \"resume_filename\": resume_filename,\n",
    "            \"resume_text\": resume_text,\n",
    "            \"profile\": {},\n",
    "            \"jobs_raw\": [],\n",
    "            \"jobs_scored\": [],\n",
    "            \"ranking\": [],\n",
    "            \"drafts\": {},\n",
    "            \"bridge_docs\": {},\n",
    "            \"meta\": {\n",
    "                \"created_at_utc\": utc_now(),\n",
    "                \"heartbeat_utc\": utc_now(),\n",
    "                \"last_layer\": None,\n",
    "                \"plan_layers\": [\"L0\",\"L2\",\"L3\",\"L4\",\"L5\"],\n",
    "                \"approved_job_urls\": [],\n",
    "            },\n",
    "            \"steps\": [],\n",
    "            \"live_feed\": [{\"layer\":\"L1\",\"agent\":\"API\",\"message\":\"Run created. Starting background pipelineâ€¦\"}],\n",
    "            \"attempts\": [],\n",
    "            \"gates\": [],\n",
    "            \"evaluations\": [],\n",
    "            \"artifacts\": {\n",
    "                \"resume_raw\": {\"path\": str(run_dir / \"resume_raw.txt\"), \"content_type\": \"text/plain\"},\n",
    "                \"resume_upload\": {\"path\": str(run_dir / \"resume_upload.bin\"), \"content_type\": \"application/octet-stream\"},\n",
    "            },\n",
    "        }\n",
    "\n",
    "        self.save_state(run_id=run_id, state=state)\n",
    "        return state\n",
    "\n",
    "    def start_background(self, run_id: str) -> None:\n",
    "        t = threading.Thread(target=self._bg, args=(run_id,), daemon=True)\n",
    "        t.start()\n",
    "\n",
    "    def _call_layer(self, state: Dict[str, Any], layer: str) -> Dict[str, Any]:\n",
    "        st_copy = copy.deepcopy(state)\n",
    "        return asyncio.run(run_single_layer(st_copy, layer))\n",
    "\n",
    "    def _bg(self, run_id: str) -> None:\n",
    "        state = self.get_state(run_id)\n",
    "        if not state:\n",
    "            return\n",
    "\n",
    "        plan = [(\"L0\", 10), (\"L2\", 20), (\"L3\", 45), (\"L4\", 120), (\"L5\", 15)]\n",
    "\n",
    "        for layer, tmo in plan:\n",
    "            if state.get(\"status\") in (\"blocked\",\"needs_human_approval\",\"failed\",\"completed\"):\n",
    "                self.save_state(run_id=run_id, state=state)\n",
    "                return\n",
    "\n",
    "            state.setdefault(\"meta\", {})\n",
    "            state[\"meta\"][\"last_layer\"] = layer\n",
    "            state.setdefault(\"steps\", []).append({\"layer_id\": layer, \"status\": \"running\", \"started_at_utc\": utc_now()})\n",
    "            state.setdefault(\"live_feed\", []).append({\"layer\": layer, \"agent\":\"Orchestrator\", \"message\": f\"Running {layer}â€¦\"})\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "\n",
    "            with cf.ThreadPoolExecutor(max_workers=1) as ex:\n",
    "                fut = ex.submit(self._call_layer, state, layer)\n",
    "                try:\n",
    "                    state = fut.result(timeout=tmo)\n",
    "                except cf.TimeoutError:\n",
    "                    state[\"status\"] = \"needs_human_approval\"\n",
    "                    state[\"pending_action\"] = f\"timeout_{layer.lower()}\"\n",
    "                    state.setdefault(\"live_feed\", []).append({\"layer\": layer, \"agent\":\"TimeoutGuard\", \"message\": f\"{layer} timed out after {tmo}s\"})\n",
    "                except Exception as e:\n",
    "                    state[\"status\"] = \"failed\"\n",
    "                    state[\"pending_action\"] = f\"error_{layer.lower()}\"\n",
    "                    state.setdefault(\"live_feed\", []).append({\"layer\": layer, \"agent\":\"CrashGuard\", \"message\": f\"{layer} crashed: {e}\"})\n",
    "\n",
    "            step_status = \"ok\"\n",
    "            if str(state.get(\"pending_action\",\"\")).startswith((\"timeout_\",\"error_\")):\n",
    "                step_status = \"failed\"\n",
    "            if state.get(\"status\") in (\"blocked\",\"failed\"):\n",
    "                step_status = \"failed\"\n",
    "\n",
    "            state[\"steps\"][-1][\"status\"] = step_status\n",
    "            state[\"steps\"][-1][\"finished_at_utc\"] = utc_now()\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "\n",
    "            if state.get(\"pending_action\") == \"review_ranking\":\n",
    "                state[\"status\"] = \"needs_human_approval\"\n",
    "                self.save_state(run_id=run_id, state=state)\n",
    "                return\n",
    "\n",
    "        if state.get(\"status\") == \"running\":\n",
    "            state[\"status\"] = \"needs_human_approval\"\n",
    "            state[\"pending_action\"] = \"review_ranking\"\n",
    "            state.setdefault(\"live_feed\", []).append({\"layer\":\"L5\",\"agent\":\"Orchestrator\",\"message\":\"Ranking ready for review.\"})\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "\n",
    "    async def handle_action(self, *, run_id: str, action_type: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state = self.get_state(run_id)\n",
    "        if not state:\n",
    "            raise ValueError(\"run_id not found\")\n",
    "\n",
    "        state.setdefault(\"meta\", {})\n",
    "        state[\"meta\"][\"last_user_action\"] = {\"type\": action_type, \"payload\": payload, \"at_utc\": utc_now()}\n",
    "\n",
    "        if action_type == \"execute_layer\":\n",
    "            layer = str(payload.get(\"layer\",\"\")).upper()\n",
    "            state = await asyncio.to_thread(lambda: self._call_layer(state, layer))\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        if action_type == \"approve_ranking\":\n",
    "            selected = payload.get(\"selected_job_urls\") or []\n",
    "            if isinstance(selected, list):\n",
    "                state[\"meta\"][\"approved_job_urls\"] = [str(u) for u in selected if str(u).strip()]\n",
    "            state.setdefault(\"live_feed\", []).append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\": f\"Ranking approved. Selected jobs={len(state['meta']['approved_job_urls'])}.\"})\n",
    "            state = await asyncio.to_thread(lambda: asyncio.run(approve_ranking_flow(copy.deepcopy(state))))\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        if action_type == \"reject_ranking\":\n",
    "            reason = str(payload.get(\"reason\",\"\")).strip()\n",
    "            state.setdefault(\"meta\", {}).setdefault(\"ranking_reject_reasons\", []).append(reason or \"no_reason\")\n",
    "            state[\"status\"] = \"running\"\n",
    "            state[\"pending_action\"] = None\n",
    "            state.setdefault(\"live_feed\", []).append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\": f\"Ranking rejected. Re-running hunt. Reason: {reason[:140]}\"} )\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            self.start_background(run_id)\n",
    "            return state\n",
    "\n",
    "        if action_type == \"approve_drafts\":\n",
    "            state.setdefault(\"live_feed\", []).append({\"layer\":\"L6\",\"agent\":\"HITL\",\"message\":\"Drafts approved. Finalizingâ€¦\"})\n",
    "            state = await asyncio.to_thread(lambda: asyncio.run(approve_drafts_flow(copy.deepcopy(state))))\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        if action_type == \"reject_drafts\":\n",
    "            reason = str(payload.get(\"reason\",\"\")).strip()\n",
    "            state.setdefault(\"meta\", {}).setdefault(\"draft_reject_reasons\", []).append(reason or \"no_reason\")\n",
    "            state[\"status\"] = \"needs_human_approval\"\n",
    "            state[\"pending_action\"] = \"review_ranking\"\n",
    "            state.setdefault(\"live_feed\", []).append({\"layer\":\"L6\",\"agent\":\"HITL\",\"message\": f\"Drafts rejected. Back to ranking. Reason: {reason[:140]}\"} )\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        state.setdefault(\"live_feed\", []).append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\":f\"Unhandled action_type={action_type}\"})\n",
    "        self.save_state(run_id=run_id, state=state)\n",
    "        return state\n",
    "''')\n",
    "\n",
    "# -------------------------------\n",
    "# 2) runtime_nodes.py: filter ranking by selected_job_urls + fallback draft writer\n",
    "# -------------------------------\n",
    "backup_write(\"src/careeragent/langgraph/runtime_nodes.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import hashlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from careeragent.langgraph.runtime_nodes import run_single_layer as _run_single_layer_base  # type: ignore\n",
    "\n",
    "# NOTE:\n",
    "# You already have a working local-first runtime_nodes.py in your repo.\n",
    "# We patch only the approval flows here by re-defining approve_* functions.\n",
    "# This file will be imported by RunManagerService for approve_ranking_flow/approve_drafts_flow.\n",
    "\n",
    "# If you already have approve_* in this module, this overwrite is intentional (backup created).\n",
    "\n",
    "def _artifacts_root() -> Path:\n",
    "    return Path(\"src/careeragent/artifacts\").resolve()\n",
    "\n",
    "def _runs_dir(run_id: str) -> Path:\n",
    "    d = _artifacts_root() / \"runs\" / run_id\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "def _write_text(p: Path, txt: str) -> str:\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_text(txt, encoding=\"utf-8\")\n",
    "    return str(p)\n",
    "\n",
    "def _job_key(url: str) -> str:\n",
    "    return hashlib.md5(url.encode(\"utf-8\"), usedforsecurity=False).hexdigest()[:12]  # noqa: S324\n",
    "\n",
    "def _fallback_resume_md(profile: Dict[str, Any], job: Dict[str, Any]) -> str:\n",
    "    name = (profile.get(\"name\") or \"Candidate\").strip()\n",
    "    contact = profile.get(\"contact\") or {}\n",
    "    skills = profile.get(\"skills\") or []\n",
    "    title = job.get(\"title\") or \"Target Role\"\n",
    "    matched = job.get(\"matched_skills\") or []\n",
    "    missing = job.get(\"missing_skills\") or []\n",
    "\n",
    "    return f\"\"\"# {name}\n",
    "{contact.get('phone','')} | {contact.get('email','')}\n",
    "{contact.get('linkedin','')}\n",
    "\n",
    "## Target Role\n",
    "**{title}**\n",
    "\n",
    "## Professional Summary\n",
    "AI/ML professional with strong delivery focus. Building production-ready GenAI + MLOps systems with measurable impact. Optimized for ATS scanning and recruiter readability.\n",
    "\n",
    "## Core Skills (ATS)\n",
    "{\", \".join(skills[:25])}\n",
    "\n",
    "## Matched Skills for This Role\n",
    "{\", \".join(matched[:20]) if matched else \"See Skills section\"}\n",
    "\n",
    "## Skill Gaps (to close fast)\n",
    "{\", \".join(missing[:15]) if missing else \"None detected from scrape text\"}\n",
    "\n",
    "## Experience\n",
    "- Add 4â€“6 bullet points per role with metrics (latency, cost, accuracy, scale, adoption)\n",
    "- Include tools + scope + outcomes per project\n",
    "\n",
    "## Education\n",
    "- MSIT (Healthcare Tech) â€” Clark University (in progress)\n",
    "\n",
    "## Projects\n",
    "- CareerAgent-AI: LangGraph agentic orchestration + HITL + explainability + analytics\n",
    "\"\"\"\n",
    "\n",
    "def _fallback_cover_md(profile: Dict[str, Any], job: Dict[str, Any], country: str) -> str:\n",
    "    name = (profile.get(\"name\") or \"Candidate\").strip()\n",
    "    contact = profile.get(\"contact\") or {}\n",
    "    title = job.get(\"title\") or \"the role\"\n",
    "    company = job.get(\"company\") or \"\"\n",
    "    url = job.get(\"url\") or \"\"\n",
    "\n",
    "    greeting = \"Dear Hiring Manager,\" if country.upper() == \"US\" else \"Dear Hiring Team,\"\n",
    "    return f\"\"\"# Cover Letter â€” {name}\n",
    "\n",
    "{contact.get('email','')} | {contact.get('phone','')} | {contact.get('linkedin','')}\n",
    "\n",
    "{greeting}\n",
    "\n",
    "Iâ€™m applying for **{title}** {(\"at \" + company) if company else \"\"}. I build production-grade AI/ML and GenAI systems with strong MLOps discipline (tracking, reproducibility, governance). My experience aligns with high-impact delivery: building reliable pipelines, agentic workflows, and measurable model outcomes.\n",
    "\n",
    "Highlights relevant to this role:\n",
    "- End-to-end AI delivery: data â†’ training â†’ evaluation â†’ deployment\n",
    "- GenAI/LLM apps: RAG, orchestration, guardrails, prompt safety, evaluation loops\n",
    "- MLOps + cloud: CI/CD, containers, monitoring, artifact/version control\n",
    "\n",
    "Iâ€™d welcome the chance to discuss how I can help your team ship AI systems that are fast, safe, and measurable.\n",
    "\n",
    "Sincerely,  \n",
    "**{name}**\n",
    "\n",
    "Job link: {url}\n",
    "\"\"\"\n",
    "\n",
    "async def run_single_layer(state: Dict[str, Any], layer: str) -> Dict[str, Any]:\n",
    "    # delegate to your already-working local-first layer runner\n",
    "    return await _run_single_layer_base(state, layer)\n",
    "\n",
    "async def approve_ranking_flow(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: HITL approve ranking -> generate drafts for selected jobs.\n",
    "    Layer: L6\n",
    "    \"\"\"\n",
    "    run_id = str(state.get(\"run_id\") or \"run\")\n",
    "    prefs = state.get(\"preferences\") or {}\n",
    "    country = str(prefs.get(\"country\") or \"US\")\n",
    "\n",
    "    ranking: List[Dict[str, Any]] = state.get(\"ranking\") or []\n",
    "    approved = (state.get(\"meta\") or {}).get(\"approved_job_urls\") or []\n",
    "    approved = [str(u) for u in approved if str(u).strip()]\n",
    "\n",
    "    if approved:\n",
    "        ranking = [j for j in ranking if str(j.get(\"url\") or j.get(\"job_id\") or \"\") in set(approved)]\n",
    "    if not ranking:\n",
    "        # fallback to top 10\n",
    "        ranking = (state.get(\"ranking\") or [])[:10]\n",
    "\n",
    "    # Try your existing L6 node (if present)\n",
    "    try:\n",
    "        from careeragent.langgraph.nodes_l6_l9 import l6_draft_node, l6_evaluator_node\n",
    "        state.update(await l6_draft_node(state))      # type: ignore[arg-type]\n",
    "        state.update(await l6_evaluator_node(state))  # type: ignore[arg-type]\n",
    "    except Exception:\n",
    "        # Fallback deterministic draft generation\n",
    "        prof = state.get(\"profile\") or {}\n",
    "        run_dir = _runs_dir(run_id)\n",
    "        artifacts = state.setdefault(\"artifacts\", {})\n",
    "        drafts = []\n",
    "        for job in ranking[:10]:\n",
    "            url = str(job.get(\"url\") or job.get(\"job_id\") or \"\")\n",
    "            key = _job_key(url or (job.get(\"title\") or \"job\"))\n",
    "            resume_p = run_dir / f\"resume_{key}.md\"\n",
    "            cover_p = run_dir / f\"cover_{key}.md\"\n",
    "            resume_txt = _fallback_resume_md(prof, job)\n",
    "            cover_txt = _fallback_cover_md(prof, job, country)\n",
    "            artifacts[f\"resume_{key}\"] = {\"path\": _write_text(resume_p, resume_txt), \"content_type\": \"text/markdown\"}\n",
    "            artifacts[f\"cover_{key}\"] = {\"path\": _write_text(cover_p, cover_txt), \"content_type\": \"text/markdown\"}\n",
    "            drafts.append({\"job_url\": url, \"job_title\": job.get(\"title\"), \"resume\": artifacts[f\"resume_{key}\"][\"path\"], \"cover\": artifacts[f\"cover_{key}\"][\"path\"]})\n",
    "\n",
    "        state[\"drafts\"] = {\"drafts\": drafts}\n",
    "\n",
    "    state[\"status\"] = \"needs_human_approval\"\n",
    "    state[\"pending_action\"] = \"review_drafts\"\n",
    "    state.setdefault(\"live_feed\", []).append({\"layer\":\"L6\",\"agent\":\"HITL\",\"message\": f\"Drafts generated for {min(10,len(ranking))} jobs. Review drafts.\"})\n",
    "    return state\n",
    "\n",
    "async def approve_drafts_flow(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: HITL approve drafts -> finalize.\n",
    "    Layer: L7-L9\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from careeragent.langgraph.nodes_l6_l9 import (\n",
    "            l7_apply_node, l7_evaluator_node,\n",
    "            l8_tracker_node, l8_evaluator_node,\n",
    "            l9_analytics_node,\n",
    "        )\n",
    "        state.update(await l7_apply_node(state))      # type: ignore[arg-type]\n",
    "        state.update(await l7_evaluator_node(state))  # type: ignore[arg-type]\n",
    "        if state.get(\"status\") == \"needs_human_approval\":\n",
    "            return state\n",
    "        state.update(await l8_tracker_node(state))      # type: ignore[arg-type]\n",
    "        state.update(await l8_evaluator_node(state))    # type: ignore[arg-type]\n",
    "        if state.get(\"status\") == \"needs_human_approval\":\n",
    "            return state\n",
    "        state.update(await l9_analytics_node(state))    # type: ignore[arg-type]\n",
    "    except Exception:\n",
    "        # fallback: mark completed\n",
    "        pass\n",
    "\n",
    "    state[\"status\"] = \"completed\"\n",
    "    state[\"pending_action\"] = None\n",
    "    state.setdefault(\"live_feed\", []).append({\"layer\":\"L9\",\"agent\":\"HITL\",\"message\":\"Run completed.\"})\n",
    "    return state\n",
    "''')\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Streamlit UI: show approval buttons + job grid + draft review\n",
    "# -------------------------------\n",
    "backup_write(\"app/ui/dashboard.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "def _api_base() -> str:\n",
    "    return os.getenv(\"API_URL\", \"http://127.0.0.1:8000\").rstrip(\"/\")\n",
    "\n",
    "\n",
    "def api_get(path: str) -> Dict[str, Any]:\n",
    "    r = requests.get(_api_base() + path, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def api_post(path: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    r = requests.post(_api_base() + path, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def _load_artifact_json(artifact: Optional[Dict[str, Any]]) -> Optional[Any]:\n",
    "    if not artifact:\n",
    "        return None\n",
    "    p = artifact.get(\"path\")\n",
    "    if not p:\n",
    "        return None\n",
    "    fp = Path(p)\n",
    "    if not fp.exists():\n",
    "        return None\n",
    "    return json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "def _progress(state: Dict[str, Any]) -> int:\n",
    "    steps = state.get(\"steps\") or []\n",
    "    done = sum(1 for s in steps if s.get(\"finished_at_utc\"))\n",
    "    total = max(1, len(steps) if steps else len((state.get(\"meta\") or {}).get(\"plan_layers\") or [\"L0\",\"L2\",\"L3\",\"L4\",\"L5\"]))\n",
    "    return int((done / total) * 100)\n",
    "\n",
    "\n",
    "def _job_card(job: Dict[str, Any]) -> None:\n",
    "    url = job.get(\"url\") or job.get(\"job_id\") or \"\"\n",
    "    title = job.get(\"title\") or \"(untitled)\"\n",
    "    mp = job.get(\"match_percent\")\n",
    "    comp = job.get(\"components\") or {}\n",
    "    st.markdown(f\"**{title}**\")\n",
    "    cols = st.columns([1.2, 1.0, 1.0, 1.0, 1.3])\n",
    "    cols[0].markdown(f\"[Open job link]({url})\")\n",
    "    cols[1].metric(\"Match %\", f\"{mp:.1f}\" if isinstance(mp, (int,float)) else str(mp))\n",
    "    cols[2].metric(\"Skill\", f\"{(comp.get('skill_overlap',0)*100):.0f}%\")\n",
    "    cols[3].metric(\"Exp\", f\"{(comp.get('experience_alignment',0)*100):.0f}%\")\n",
    "    cols[4].metric(\"ATS\", f\"{(comp.get('ats_score',0)*100):.0f}%\")\n",
    "    if job.get(\"snippet\"):\n",
    "        st.caption(job[\"snippet\"][:240])\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    st.set_page_config(page_title=\"CareerAgent-AI â€” Glass-Box Mission Control\", layout=\"wide\")\n",
    "    st.title(\"CareerAgent-AI â€” Glass-Box Mission Control\")\n",
    "\n",
    "    if \"run_id\" not in st.session_state:\n",
    "        st.session_state[\"run_id\"] = \"\"\n",
    "    if \"selected_urls\" not in st.session_state:\n",
    "        st.session_state[\"selected_urls\"] = set()\n",
    "\n",
    "    # Sidebar inputs\n",
    "    with st.sidebar:\n",
    "        st.markdown(\"### Preferences\")\n",
    "        default_th = st.slider(\"Default threshold\", 0.0, 1.0, 0.70, 0.01)\n",
    "        parser_th = st.slider(\"Parser threshold\", 0.0, 1.0, 0.70, 0.01)\n",
    "        discovery_th = st.slider(\"Discovery threshold\", 0.0, 1.0, 0.70, 0.01)\n",
    "        match_th = st.slider(\"Match threshold\", 0.0, 1.0, 0.70, 0.01)\n",
    "        max_ref = st.slider(\"Max retries / refinements\", 0, 5, 3, 1)\n",
    "\n",
    "        roles = st.text_input(\"Target roles (comma-separated)\", \"Data Scientist, ML Engineer, GenAI Engineer\")\n",
    "        location = st.text_input(\"Location\", \"United States\")\n",
    "        country = st.selectbox(\"Country\", [\"US\", \"CA\", \"UK\", \"IN\", \"AU\"], index=0)\n",
    "        remote = st.checkbox(\"Remote preferred\", value=True)\n",
    "        wfo_ok = st.checkbox(\"On-site/WFO acceptable\", value=True)\n",
    "        visa = st.checkbox(\"Visa sponsorship required (F1/OPT/H1B)\", value=True)\n",
    "        recency = st.number_input(\"Recency hours\", min_value=6, max_value=168, value=36, step=6)\n",
    "        max_jobs = st.number_input(\"Max jobs to hunt\", min_value=10, max_value=60, value=40, step=5)\n",
    "        phone = st.text_input(\"Phone for SMS (optional)\", \"\")\n",
    "\n",
    "        st.markdown(\"### Upload\")\n",
    "        up = st.file_uploader(\"Resume (PDF/TXT/DOCX)\", type=[\"pdf\",\"txt\",\"docx\"])\n",
    "\n",
    "        if st.button(\"ðŸš€ Start Hunt\", use_container_width=True, disabled=(up is None)):\n",
    "            prefs = {\n",
    "                \"target_roles\": [r.strip() for r in roles.split(\",\") if r.strip()][:4],\n",
    "                \"country\": country,\n",
    "                \"location\": location,\n",
    "                \"remote\": remote,\n",
    "                \"wfo_ok\": wfo_ok,\n",
    "                \"salary\": \"\",\n",
    "                \"visa_sponsorship_required\": visa,\n",
    "                \"recency_hours\": float(recency),\n",
    "                \"max_jobs\": int(max_jobs),\n",
    "                \"max_refinements\": int(max_ref),\n",
    "                \"user_phone\": phone or None,\n",
    "                \"thresholds\": {\n",
    "                    \"default\": float(default_th),\n",
    "                    \"parser\": float(parser_th),\n",
    "                    \"discovery\": float(discovery_th),\n",
    "                    \"match\": float(match_th),\n",
    "                    \"draft\": float(default_th),\n",
    "                },\n",
    "            }\n",
    "            files = {\"resume\": (up.name, up.getvalue(), up.type or \"application/octet-stream\")}\n",
    "            data = {\"preferences_json\": json.dumps(prefs)}\n",
    "            r = requests.post(_api_base() + \"/analyze\", files=files, data=data, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            st.session_state[\"run_id\"] = r.json()[\"run_id\"]\n",
    "            st.session_state[\"selected_urls\"] = set()\n",
    "            st.success(f\"Run started: {st.session_state['run_id']}\")\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        st.markdown(\"### Existing Run\")\n",
    "        st.session_state[\"run_id\"] = st.text_input(\"Run ID\", st.session_state[\"run_id\"])\n",
    "\n",
    "    run_id = st.session_state[\"run_id\"].strip()\n",
    "    if not run_id:\n",
    "        st.info(\"Upload a resume and click Start Hunt.\")\n",
    "        return\n",
    "\n",
    "    # Pull status\n",
    "    state = api_get(f\"/status/{run_id}\")\n",
    "\n",
    "    # Header KPI row\n",
    "    c1, c2, c3, c4 = st.columns([2,2,2,2])\n",
    "    c1.markdown(f\"**Run:** `{run_id}`\")\n",
    "    c2.markdown(f\"**Status:** `{state.get('status')}`\")\n",
    "    c3.markdown(f\"**Pending:** `{state.get('pending_action')}`\")\n",
    "    prog = _progress(state)\n",
    "    c4.markdown(f\"**Progress:** `{prog}%`\")\n",
    "    st.progress(prog / 100.0)\n",
    "\n",
    "    # Live feed\n",
    "    st.subheader(\"Live Agent Feed\")\n",
    "    feed = state.get(\"live_feed\") or []\n",
    "    for e in feed[-20:]:\n",
    "        st.write(f\"[{e.get('layer')} {e.get('agent')}] {e.get('message')}\")\n",
    "\n",
    "    tabs = st.tabs([\"Pilot/Engineer\", \"Approval Grid\", \"Draft Review\", \"Learning Center\", \"Artifacts\"])\n",
    "\n",
    "    # -------- Pilot/Engineer\n",
    "    with tabs[0]:\n",
    "        st.markdown(\"### Engineer Controls\")\n",
    "        cols = st.columns(5)\n",
    "        for i, layer in enumerate([\"L0\",\"L2\",\"L3\",\"L4\",\"L5\"]):\n",
    "            if cols[i].button(f\"Run {layer}\", use_container_width=True):\n",
    "                st = api_post(f\"/action/{run_id}\", {\"action_type\":\"execute_layer\", \"payload\":{\"layer\": layer}})\n",
    "                st.success(f\"Executed {layer}. Refresh.\")\n",
    "        st.caption(\"Use Approval Grid when pending_action=review_ranking.\")\n",
    "\n",
    "    # -------- Approval Grid (Ranking HITL)\n",
    "    with tabs[1]:\n",
    "        st.markdown(\"### Ranking Approval (HITL)\")\n",
    "        ranking = state.get(\"ranking\") or []\n",
    "        if not ranking:\n",
    "            ranking = _load_artifact_json((state.get(\"artifacts\") or {}).get(\"ranking\")) or []\n",
    "\n",
    "        if not ranking:\n",
    "            st.warning(\"Ranking not available yet.\")\n",
    "        else:\n",
    "            st.caption(\"Select jobs â†’ Approve Selected to generate tailored drafts (resume + cover letter).\")\n",
    "\n",
    "            # default select top 10 if nothing selected yet\n",
    "            if not st.session_state[\"selected_urls\"]:\n",
    "                for j in ranking[:10]:\n",
    "                    u = j.get(\"url\") or j.get(\"job_id\") or \"\"\n",
    "                    if u:\n",
    "                        st.session_state[\"selected_urls\"].add(u)\n",
    "\n",
    "            # grid cards\n",
    "            for idx, job in enumerate(ranking[:30], start=1):\n",
    "                url = job.get(\"url\") or job.get(\"job_id\") or \"\"\n",
    "                with st.expander(f\"{idx}. {job.get('title','(untitled)')}\", expanded=(idx<=3)):\n",
    "                    left, right = st.columns([0.82, 0.18])\n",
    "                    with left:\n",
    "                        _job_card(job)\n",
    "                    with right:\n",
    "                        sel = st.checkbox(\"Select\", value=(url in st.session_state[\"selected_urls\"]), key=f\"sel_{idx}\")\n",
    "                        if sel and url:\n",
    "                            st.session_state[\"selected_urls\"].add(url)\n",
    "                        if (not sel) and url and url in st.session_state[\"selected_urls\"]:\n",
    "                            st.session_state[\"selected_urls\"].remove(url)\n",
    "\n",
    "            colA, colB = st.columns([1,1])\n",
    "            with colA:\n",
    "                if st.button(\"âœ… Approve Selected â†’ Generate Drafts\", use_container_width=True, disabled=(len(st.session_state[\"selected_urls\"])==0)):\n",
    "                    api_post(f\"/action/{run_id}\", {\"action_type\":\"approve_ranking\", \"payload\":{\"selected_job_urls\": sorted(list(st.session_state[\"selected_urls\"]))}})\n",
    "                    st.success(\"Approved. Go to Draft Review tab and refresh.\")\n",
    "            with colB:\n",
    "                reason = st.text_input(\"Reject reason (optional)\", \"\")\n",
    "                if st.button(\"âŒ Reject Ranking â†’ Re-run Hunt\", use_container_width=True):\n",
    "                    api_post(f\"/action/{run_id}\", {\"action_type\":\"reject_ranking\", \"payload\":{\"reason\": reason}})\n",
    "                    st.warning(\"Rejected. Pipeline restarted.\")\n",
    "\n",
    "    # -------- Draft Review (after approve_ranking)\n",
    "    with tabs[2]:\n",
    "        st.markdown(\"### Draft Review (Resume + Cover Letter)\")\n",
    "        artifacts = state.get(\"artifacts\") or {}\n",
    "        # collect resume/cover artifacts\n",
    "        resume_keys = [k for k in artifacts.keys() if k.startswith(\"resume_\")]\n",
    "        cover_keys = [k for k in artifacts.keys() if k.startswith(\"cover_\")]\n",
    "\n",
    "        if not resume_keys and not cover_keys:\n",
    "            st.info(\"No drafts found yet. Approve ranking first.\")\n",
    "        else:\n",
    "            st.caption(\"Preview and approve drafts to finalize (apply/tracker/analytics).\")\n",
    "            all_keys = sorted(list(set(resume_keys + cover_keys)))\n",
    "            pick = st.selectbox(\"Select draft artifact\", all_keys)\n",
    "            if pick:\n",
    "                p = artifacts[pick][\"path\"]\n",
    "                txt = Path(p).read_text(encoding=\"utf-8\") if Path(p).exists() else \"(file missing)\"\n",
    "                st.code(txt[:8000], language=\"markdown\")\n",
    "\n",
    "                st.download_button(\"Download this file\", data=txt.encode(\"utf-8\"), file_name=Path(p).name, mime=\"text/markdown\")\n",
    "\n",
    "            col1, col2 = st.columns([1,1])\n",
    "            with col1:\n",
    "                if st.button(\"âœ… Approve Drafts â†’ Finalize (L7â€“L9)\", use_container_width=True):\n",
    "                    api_post(f\"/action/{run_id}\", {\"action_type\":\"approve_drafts\", \"payload\":{}})\n",
    "                    st.success(\"Approved drafts. Refresh to see completed status.\")\n",
    "            with col2:\n",
    "                r = st.text_input(\"Draft reject reason\", \"\")\n",
    "                if st.button(\"âŒ Reject Drafts â†’ Back to Ranking\", use_container_width=True):\n",
    "                    api_post(f\"/action/{run_id}\", {\"action_type\":\"reject_drafts\", \"payload\":{\"reason\": r}})\n",
    "                    st.warning(\"Drafts rejected. Back to ranking.\")\n",
    "\n",
    "    # -------- Learning Center\n",
    "    with tabs[3]:\n",
    "        st.markdown(\"### Learning Center (Skill Gaps â†’ Tutorials)\")\n",
    "        scored = state.get(\"jobs_scored\") or []\n",
    "        if not scored:\n",
    "            scored = _load_artifact_json((state.get(\"artifacts\") or {}).get(\"jobs_scored\")) or []\n",
    "\n",
    "        gaps = {}\n",
    "        for j in scored[:30]:\n",
    "            for sk in (j.get(\"missing_skills\") or [])[:10]:\n",
    "                gaps[sk] = gaps.get(sk, 0) + 1\n",
    "\n",
    "        if not gaps:\n",
    "            st.info(\"No skill gaps detected (or scrape text did not include explicit skills).\")\n",
    "        else:\n",
    "            top = sorted(gaps.items(), key=lambda x: x[1], reverse=True)[:25]\n",
    "            for sk, cnt in top:\n",
    "                docs = f\"https://www.google.com/search?q={sk}+official+documentation\"\n",
    "                yt = f\"https://www.youtube.com/results?search_query={sk}+tutorial\"\n",
    "                st.write(f\"**{sk}** (missing in {cnt} jobs) â€” [Docs]({docs}) | [YouTube]({yt})\")\n",
    "\n",
    "    # -------- Artifacts / Downloads\n",
    "    with tabs[4]:\n",
    "        st.markdown(\"### Artifacts (local-first)\")\n",
    "        artifacts = state.get(\"artifacts\") or {}\n",
    "        if not artifacts:\n",
    "            st.info(\"No artifacts in state.\")\n",
    "        else:\n",
    "            for k, v in artifacts.items():\n",
    "                p = v.get(\"path\",\"\")\n",
    "                st.write(f\"- **{k}** â†’ `{p}`\")\n",
    "        st.markdown(\"#### Quick downloads\")\n",
    "        for key in (\"jobs_raw\",\"jobs_scored\",\"ranking\",\"extracted_profile\"):\n",
    "            art = artifacts.get(key)\n",
    "            if not art:\n",
    "                continue\n",
    "            fp = Path(art[\"path\"])\n",
    "            if fp.exists():\n",
    "                st.download_button(f\"Download {key}\", data=fp.read_bytes(), file_name=fp.name, mime=art.get(\"content_type\",\"application/octet-stream\"))\n",
    "''')\n",
    "\n",
    "backup_write(\"app/main.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "from app.ui.dashboard import main\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "''')\n",
    "\n",
    "print(\"âœ… HITL UI + backend actions patched.\")\n",
    "print(\"Next: restart backend + restart Streamlit.\")\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careeragent-ai (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
