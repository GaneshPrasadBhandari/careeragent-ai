{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''a FastAPI /action system that matches the Streamlit “Glass-Box Mission Control” UI, \n",
    "supports Engineer View (run L0–L9), HITL approvals, and background execution with real-time state polling.'''\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Auto-chdir to repo root even from notebooks_v2\n",
    "ROOT = Path.cwd().resolve()\n",
    "if ROOT.name == \"notebooks_v2\":\n",
    "    os.chdir(ROOT.parent)\n",
    "ROOT = Path.cwd().resolve()\n",
    "assert (ROOT / \"src\").exists(), f\"Not at repo root. CWD={ROOT}\"\n",
    "print(\"✅ CWD =\", ROOT)\n",
    "\n",
    "def backup_write(rel_path: str, content: str) -> None:\n",
    "    p = ROOT / rel_path\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if p.exists():\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        bak = p.with_suffix(p.suffix + f\".bak_{ts}\")\n",
    "        bak.write_text(p.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "        print(\"BACKUP:\", bak)\n",
    "    p.write_text(content, encoding=\"utf-8\")\n",
    "    print(\"WROTE:\", p)\n",
    "\n",
    "# ---------- src/careeragent/api/request_models.py ----------\n",
    "backup_write(\"src/careeragent/api/request_models.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, Optional\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "\n",
    "class AnalyzeResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: Response for /analyze.\n",
    "    Layer: L8\n",
    "    Input: run_id + status\n",
    "    Output: JSON response\n",
    "    \"\"\"\n",
    "    model_config = ConfigDict(extra=\"ignore\")\n",
    "    run_id: str\n",
    "    status: str\n",
    "\n",
    "\n",
    "class ActionRequest(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: Generic action request for /action/{run_id}.\n",
    "    Layer: L5\n",
    "    Input: action_type + payload\n",
    "    Output: used by API handlers\n",
    "    \"\"\"\n",
    "    model_config = ConfigDict(extra=\"ignore\")\n",
    "    action_type: str = Field(..., description=\"execute_layer|approve_ranking|reject_ranking|approve_drafts|reject_drafts|approve_job|reject_job|resume_cleanup_submit|...\")\n",
    "    payload: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "class StatusResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Description: Response for /status/{run_id}.\n",
    "    Layer: L8\n",
    "    Input: run_id\n",
    "    Output: full state snapshot\n",
    "    \"\"\"\n",
    "    model_config = ConfigDict(extra=\"allow\")\n",
    "''')\n",
    "\n",
    "# ---------- src/careeragent/api/run_manager_service.py ----------\n",
    "backup_write(\"src/careeragent/api/run_manager_service.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "from uuid import uuid4\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from careeragent.services.db_service import SqliteStateStore\n",
    "\n",
    "# Optional artifacts root helper\n",
    "try:\n",
    "    from careeragent.config import artifacts_root  # type: ignore\n",
    "except Exception:  # fallback\n",
    "    def artifacts_root() -> Path:\n",
    "        return Path(\"src/careeragent/artifacts\").resolve()\n",
    "\n",
    "# Tool-resilient nodes runner\n",
    "from careeragent.langgraph.runtime_nodes import (\n",
    "    run_full_pipeline,\n",
    "    run_single_layer,\n",
    "    approve_ranking_flow,\n",
    "    approve_drafts_flow,\n",
    ")\n",
    "\n",
    "\n",
    "def utc_now() -> str:\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "\n",
    "class RunManagerService:\n",
    "    \"\"\"\n",
    "    Description: Run manager for background LangGraph-style execution with state polling.\n",
    "    Layer: L8\n",
    "    Input: resume + prefs + actions\n",
    "    Output: persisted state snapshots\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._store = SqliteStateStore()\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def _runs_dir(self, run_id: str) -> Path:\n",
    "        d = artifacts_root() / \"runs\" / run_id\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "        return d\n",
    "\n",
    "    def create_run(self, *, resume_filename: str, resume_text: str, resume_bytes: bytes, preferences: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: Create new run record and persist initial state.\n",
    "        Layer: L8\n",
    "        Input: resume + prefs\n",
    "        Output: created state snapshot\n",
    "        \"\"\"\n",
    "        run_id = uuid4().hex\n",
    "        run_dir = self._runs_dir(run_id)\n",
    "\n",
    "        # Persist resume file for MCP/local auditing\n",
    "        (run_dir / \"resume_upload.bin\").write_bytes(resume_bytes)\n",
    "        (run_dir / \"resume_raw.txt\").write_text(resume_text, encoding=\"utf-8\")\n",
    "\n",
    "        thresholds = (preferences.get(\"thresholds\") or {})\n",
    "        if \"default\" in thresholds:\n",
    "            # allow a global default override\n",
    "            default_th = float(thresholds[\"default\"])\n",
    "            thresholds.setdefault(\"parser\", default_th)\n",
    "            thresholds.setdefault(\"discovery\", default_th)\n",
    "            thresholds.setdefault(\"match\", default_th)\n",
    "            thresholds.setdefault(\"draft\", default_th)\n",
    "\n",
    "        state: Dict[str, Any] = {\n",
    "            \"run_id\": run_id,\n",
    "            \"status\": \"running\",\n",
    "            \"pending_action\": None,\n",
    "            \"hitl_reason\": None,\n",
    "            \"hitl_payload\": {},\n",
    "            \"thresholds\": thresholds,\n",
    "            \"max_retries\": int(preferences.get(\"max_refinements\", 3)),\n",
    "            \"layer_retry_count\": {},\n",
    "            \"preferences\": preferences,\n",
    "            \"resume_filename\": resume_filename,\n",
    "            \"resume_text\": resume_text,\n",
    "            \"profile\": {},\n",
    "            \"jobs_raw\": [],\n",
    "            \"jobs_scraped\": [],\n",
    "            \"jobs_scored\": [],\n",
    "            \"ranking\": [],\n",
    "            \"drafts\": {},\n",
    "            \"bridge_docs\": {},\n",
    "            \"meta\": {\"created_at_utc\": utc_now()},\n",
    "            \"live_feed\": [{\"layer\": \"L1\", \"agent\": \"API\", \"message\": \"Run created. Starting background pipeline…\"}],\n",
    "            \"attempts\": [],\n",
    "            \"gates\": [],\n",
    "            \"evaluations\": [],\n",
    "            \"artifacts\": {\n",
    "                \"resume_raw\": {\"path\": str(run_dir / \"resume_raw.txt\"), \"content_type\": \"text/plain\"},\n",
    "                \"resume_upload\": {\"path\": str(run_dir / \"resume_upload.bin\"), \"content_type\": \"application/octet-stream\"},\n",
    "            },\n",
    "        }\n",
    "\n",
    "        self._store.upsert_state(run_id=run_id, status=state[\"status\"], state=state, updated_at_utc=utc_now())\n",
    "        return state\n",
    "\n",
    "    def get_state(self, run_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Description: Load run state snapshot.\n",
    "        Layer: L8\n",
    "        Input: run_id\n",
    "        Output: state dict or None\n",
    "        \"\"\"\n",
    "        return self._store.get_state(run_id=run_id)\n",
    "\n",
    "    def save_state(self, *, run_id: str, state: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Description: Persist run state snapshot.\n",
    "        Layer: L8\n",
    "        Input: state dict\n",
    "        Output: stored snapshot\n",
    "        \"\"\"\n",
    "        self._store.upsert_state(run_id=run_id, status=str(state.get(\"status\",\"unknown\")), state=state, updated_at_utc=utc_now())\n",
    "\n",
    "    def start_background(self, run_id: str) -> None:\n",
    "        \"\"\"\n",
    "        Description: Start full pipeline in background thread (LangGraph-style node chain).\n",
    "        Layer: L6\n",
    "        Input: run_id\n",
    "        Output: async execution\n",
    "        \"\"\"\n",
    "        t = threading.Thread(target=self._bg_runner, args=(run_id,), daemon=True)\n",
    "        t.start()\n",
    "\n",
    "    def _bg_runner(self, run_id: str) -> None:\n",
    "        # Run async pipeline in dedicated loop\n",
    "        asyncio.run(self._bg_async(run_id))\n",
    "\n",
    "    async def _bg_async(self, run_id: str) -> None:\n",
    "        state = self.get_state(run_id)\n",
    "        if not state:\n",
    "            return\n",
    "\n",
    "        # run the full pipeline (L0-L5). Stops automatically if HITL required.\n",
    "        state = await run_full_pipeline(state)\n",
    "        self.save_state(run_id=run_id, state=state)\n",
    "\n",
    "    async def execute_layer(self, *, run_id: str, layer: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: Engineer view — execute a single layer node.\n",
    "        Layer: L6\n",
    "        Input: run_id + layer id\n",
    "        Output: updated state\n",
    "        \"\"\"\n",
    "        state = self.get_state(run_id) or {}\n",
    "        state = await run_single_layer(state, layer.upper())\n",
    "        self.save_state(run_id=run_id, state=state)\n",
    "        return state\n",
    "\n",
    "    async def handle_action(self, *, run_id: str, action_type: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Description: HITL & operational actions for the UI.\n",
    "        Layer: L5\n",
    "        Input: action_type + payload\n",
    "        Output: updated state\n",
    "        \"\"\"\n",
    "        state = self.get_state(run_id)\n",
    "        if not state:\n",
    "            raise ValueError(\"run_id not found\")\n",
    "\n",
    "        # Store last action for audit\n",
    "        state.setdefault(\"meta\", {})\n",
    "        state[\"meta\"][\"last_user_action\"] = {\"type\": action_type, \"payload\": payload, \"at_utc\": utc_now()}\n",
    "\n",
    "        # Resume cleanup submit: overwrite resume_text and restart pipeline\n",
    "        if action_type == \"resume_cleanup_submit\":\n",
    "            txt = str(payload.get(\"resume_text\", \"\")).strip()\n",
    "            if not txt:\n",
    "                state[\"live_feed\"].append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\":\"Resume cleanup submitted but empty.\"})\n",
    "                self.save_state(run_id=run_id, state=state)\n",
    "                return state\n",
    "\n",
    "            # persist new text artifact\n",
    "            run_dir = self._runs_dir(run_id)\n",
    "            (run_dir / \"resume_raw.txt\").write_text(txt, encoding=\"utf-8\")\n",
    "            state[\"resume_text\"] = txt\n",
    "            state[\"artifacts\"][\"resume_raw\"] = {\"path\": str(run_dir / \"resume_raw.txt\"), \"content_type\": \"text/plain\"}\n",
    "\n",
    "            state[\"status\"] = \"running\"\n",
    "            state[\"pending_action\"] = None\n",
    "            state[\"live_feed\"].append({\"layer\":\"L2\",\"agent\":\"HITL\",\"message\":\"Resume updated. Restarting pipeline…\"})\n",
    "\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            self.start_background(run_id)\n",
    "            return state\n",
    "\n",
    "        # Approve / reject individual jobs\n",
    "        if action_type in (\"approve_job\", \"reject_job\"):\n",
    "            jid = str(payload.get(\"job_id\",\"\"))\n",
    "            state.setdefault(\"meta\", {})\n",
    "            state[\"meta\"].setdefault(\"approved_jobs\", [])\n",
    "            state[\"meta\"].setdefault(\"rejected_jobs\", [])\n",
    "            if action_type == \"approve_job\":\n",
    "                state[\"meta\"][\"approved_jobs\"].append({\"job_id\": jid, \"at_utc\": utc_now()})\n",
    "                state[\"live_feed\"].append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\":f\"Approved job {jid[:24]}…\"})\n",
    "            else:\n",
    "                state[\"meta\"][\"rejected_jobs\"].append({\"job_id\": jid, \"at_utc\": utc_now()})\n",
    "                state[\"live_feed\"].append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\":f\"Rejected job {jid[:24]}…\"})\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        # Ranking approval -> generate drafts + bridge docs\n",
    "        if action_type == \"approve_ranking\":\n",
    "            state = await approve_ranking_flow(state)\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        if action_type == \"reject_ranking\":\n",
    "            reason = str(payload.get(\"reason\",\"\")).strip()\n",
    "            state.setdefault(\"meta\", {})\n",
    "            state[\"meta\"].setdefault(\"refinement_notes\", [])\n",
    "            if reason:\n",
    "                state[\"meta\"][\"refinement_notes\"].append(reason)\n",
    "            state[\"status\"] = \"running\"\n",
    "            state[\"pending_action\"] = None\n",
    "            state[\"live_feed\"].append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\":\"Ranking rejected. Re-running pipeline…\"})\n",
    "\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            self.start_background(run_id)\n",
    "            return state\n",
    "\n",
    "        # Draft approval/rejection\n",
    "        if action_type == \"approve_drafts\":\n",
    "            state = await approve_drafts_flow(state)\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        if action_type == \"reject_drafts\":\n",
    "            state[\"status\"] = \"needs_human_approval\"\n",
    "            state[\"pending_action\"] = \"review_ranking\"\n",
    "            state[\"live_feed\"].append({\"layer\":\"L6\",\"agent\":\"HITL\",\"message\":\"Drafts rejected. Returning to ranking review.\"})\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        # Engineer: execute layer\n",
    "        if action_type == \"execute_layer\":\n",
    "            layer = str(payload.get(\"layer\",\"\")).upper()\n",
    "            state = await run_single_layer(state, layer)\n",
    "            self.save_state(run_id=run_id, state=state)\n",
    "            return state\n",
    "\n",
    "        # Unknown action\n",
    "        state[\"live_feed\"].append({\"layer\":\"L5\",\"agent\":\"HITL\",\"message\":f\"Unhandled action_type={action_type}\"})\n",
    "        self.save_state(run_id=run_id, state=state)\n",
    "        return state\n",
    "''')\n",
    "\n",
    "# ---------- src/careeragent/langgraph/runtime_nodes.py ----------\n",
    "backup_write(\"src/careeragent/langgraph/runtime_nodes.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import httpx\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "from careeragent.agents.parser_agent_service import ParserAgentService\n",
    "from careeragent.agents.parser_evaluator_service import ParserEvaluatorService\n",
    "\n",
    "# Optional artifacts root\n",
    "try:\n",
    "    from careeragent.config import artifacts_root  # type: ignore\n",
    "except Exception:\n",
    "    def artifacts_root() -> Path:\n",
    "        return Path(\"src/careeragent/artifacts\").resolve()\n",
    "\n",
    "# ---------------- Settings ----------------\n",
    "class RuntimeSettings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Description: Runtime settings for tools.\n",
    "    Layer: L0\n",
    "    \"\"\"\n",
    "    model_config = SettingsConfigDict(env_file=\".env\", extra=\"ignore\")\n",
    "\n",
    "    SERPER_API_KEY: Optional[str] = None\n",
    "    FIRECRAWL_API_KEY: Optional[str] = None\n",
    "    MCP_SERVER_URL: Optional[str] = None\n",
    "    MCP_AUTH_TOKEN: Optional[str] = None\n",
    "    MCP_API_KEY: Optional[str] = None  # supports either naming\n",
    "    OLLAMA_BASE_URL: Optional[str] = None\n",
    "    OLLAMA_MODEL: str = \"llama3.2\"\n",
    "\n",
    "\n",
    "def mcp_token(s: RuntimeSettings) -> Optional[str]:\n",
    "    return s.MCP_API_KEY or s.MCP_AUTH_TOKEN\n",
    "\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "JOB_BOARDS = [\n",
    "    (\"LinkedIn Jobs\", \"linkedin.com/jobs\"),\n",
    "    (\"Indeed\", \"indeed.com\"),\n",
    "    (\"Glassdoor\", \"glassdoor.com\"),\n",
    "    (\"ZipRecruiter\", \"ziprecruiter.com\"),\n",
    "    (\"Monster\", \"monster.com\"),\n",
    "    (\"Dice\", \"dice.com\"),\n",
    "    (\"Lever\", \"jobs.lever.co\"),\n",
    "    (\"Greenhouse\", \"boards.greenhouse.io\"),\n",
    "]\n",
    "\n",
    "VISA_NEGATIVE = (\"unable to sponsor\",\"cannot sponsor\",\"no sponsorship\",\"do not sponsor\",\"not sponsor\",\"without sponsorship\",\"no visa\",\"cannot provide visa\")\n",
    "RARE_SKILL_SIGNALS = (\"langgraph\", \"mcp\", \"agentic\", \"vector db\", \"faiss\", \"chroma\", \"rlhf\")\n",
    "\n",
    "def feed(st: Dict[str, Any], layer: str, agent: str, message: str) -> None:\n",
    "    st.setdefault(\"live_feed\", [])\n",
    "    st[\"live_feed\"].append({\"layer\": layer, \"agent\": agent, \"message\": message})\n",
    "\n",
    "def inc_retry(st: Dict[str, Any], layer: str) -> int:\n",
    "    st.setdefault(\"layer_retry_count\", {})\n",
    "    st[\"layer_retry_count\"][layer] = int(st[\"layer_retry_count\"].get(layer, 0)) + 1\n",
    "    return int(st[\"layer_retry_count\"][layer])\n",
    "\n",
    "def threshold(st: Dict[str, Any], key: str, default: float = 0.70) -> float:\n",
    "    t = (st.get(\"thresholds\") or {})\n",
    "    return float(t.get(key, t.get(\"default\", default)))\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return re.findall(r\"[a-zA-Z][a-zA-Z0-9\\\\+\\\\#\\\\.-]{1,}\", (text or \"\").lower())\n",
    "\n",
    "def cosine(a: Dict[str,int], b: Dict[str,int]) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    dot = sum(v * b.get(k,0) for k,v in a.items())\n",
    "    na = math.sqrt(sum(v*v for v in a.values()))\n",
    "    nb = math.sqrt(sum(v*v for v in b.values()))\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return float(dot/(na*nb))\n",
    "\n",
    "def compute_interview_chance(skill_overlap: float, exp_align: float, ats: float, market: float) -> float:\n",
    "    market = max(1.0, float(market))\n",
    "    score = (0.45*skill_overlap + 0.35*exp_align + 0.20*ats) / market\n",
    "    return max(0.0, min(1.0, float(score)))\n",
    "\n",
    "def ats_score(text: str) -> float:\n",
    "    t = (text or \"\").lower()\n",
    "    s = 0.0\n",
    "    if re.search(r\"[\\\\w\\\\.-]+@[\\\\w\\\\.-]+\\\\.\\\\w+\", t): s += 0.20\n",
    "    if re.search(r\"\\\\+?\\\\d[\\\\d\\\\-\\\\s\\\\(\\\\)]{8,}\\\\d\", t): s += 0.10\n",
    "    for h in [\"summary\",\"skills\",\"experience\",\"education\",\"projects\"]:\n",
    "        if h in t: s += 0.12\n",
    "    if \"-\" in text or \"•\" in text: s += 0.10\n",
    "    if len(text) > 1200: s += 0.12\n",
    "    return max(0.0, min(1.0, s))\n",
    "\n",
    "\n",
    "async def serper_search(s: RuntimeSettings, query: str, num: int = 10, tbs: Optional[str] = None) -> Tuple[bool, float, Any, Optional[str]]:\n",
    "    if not s.SERPER_API_KEY:\n",
    "        return False, 0.0, None, \"SERPER_API_KEY missing\"\n",
    "    headers = {\"X-API-KEY\": s.SERPER_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    body: Dict[str, Any] = {\"q\": query, \"num\": num}\n",
    "    if tbs:\n",
    "        body[\"tbs\"] = tbs\n",
    "    async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "        r = await client.post(\"https://google.serper.dev/search\", headers=headers, json=body)\n",
    "    if r.status_code == 403:\n",
    "        return False, 0.0, None, \"Serper 403 quota\"\n",
    "    if r.status_code >= 400:\n",
    "        return False, 0.0, None, f\"Serper {r.status_code}\"\n",
    "    organic = (r.json().get(\"organic\") or [])\n",
    "    out = [{\"title\": x.get(\"title\") or \"\", \"link\": x.get(\"link\") or \"\", \"snippet\": x.get(\"snippet\") or \"\"} for x in organic]\n",
    "    conf = 0.75 if out else 0.25\n",
    "    return True, conf, out, None\n",
    "\n",
    "\n",
    "async def mcp_invoke(s: RuntimeSettings, tool: str, payload: Dict[str, Any]) -> Tuple[bool, float, Any, Optional[str]]:\n",
    "    if not (s.MCP_SERVER_URL and mcp_token(s)):\n",
    "        return False, 0.0, None, \"MCP not configured\"\n",
    "    url = s.MCP_SERVER_URL.rstrip(\"/\") + \"/invoke\"\n",
    "    headers = {\"Authorization\": f\"Bearer {mcp_token(s)}\", \"Content-Type\": \"application/json\"}\n",
    "    async with httpx.AsyncClient(timeout=35.0) as client:\n",
    "        r = await client.post(url, headers=headers, json={\"tool\": tool, \"payload\": payload})\n",
    "    if r.status_code >= 400:\n",
    "        return False, 0.0, None, f\"MCP {r.status_code}: {r.text[:150]}\"\n",
    "    return True, 0.85, r.json(), None\n",
    "\n",
    "\n",
    "async def scrape_http(url: str) -> Tuple[bool, float, Any, Optional[str]]:\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=18.0, follow_redirects=True) as client:\n",
    "            r = await client.get(url, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "        if r.status_code >= 400:\n",
    "            return False, 0.0, None, f\"HTTP {r.status_code}\"\n",
    "        html = r.text\n",
    "        txt = re.sub(r\"<(script|style)[^>]*>.*?</\\\\1>\", \" \", html, flags=re.S|re.I)\n",
    "        txt = re.sub(r\"<[^>]+>\", \" \", txt)\n",
    "        txt = re.sub(r\"\\\\s+\", \" \", txt).strip()\n",
    "        conf = 0.65 if len(txt) > 1200 else 0.35\n",
    "        return True, conf, {\"text\": txt[:20000]}, None\n",
    "    except Exception as e:\n",
    "        return False, 0.0, None, str(e)\n",
    "\n",
    "\n",
    "def log_attempt(st: Dict[str, Any], *, layer: str, agent: str, tool: str, model: Optional[str], status: str, confidence: float, error: Optional[str]) -> None:\n",
    "    st.setdefault(\"attempts\", [])\n",
    "    st[\"attempts\"].append({\n",
    "        \"layer_id\": layer,\n",
    "        \"agent\": agent,\n",
    "        \"tool\": tool,\n",
    "        \"model\": model,\n",
    "        \"status\": status,\n",
    "        \"confidence\": float(confidence),\n",
    "        \"error\": error,\n",
    "    })\n",
    "\n",
    "\n",
    "def log_gate(st: Dict[str, Any], *, layer: str, target: str, score: float, threshold_v: float, decision: str, feedback: List[str], reasoning_chain: Optional[List[str]] = None) -> None:\n",
    "    st.setdefault(\"gates\", [])\n",
    "    st[\"gates\"].append({\n",
    "        \"layer_id\": layer,\n",
    "        \"target\": target,\n",
    "        \"score\": float(score),\n",
    "        \"threshold\": float(threshold_v),\n",
    "        \"decision\": decision,\n",
    "        \"feedback\": feedback,\n",
    "        \"reasoning_chain\": reasoning_chain or [],\n",
    "    })\n",
    "\n",
    "\n",
    "def gate_decision(score: float, threshold_v: float, retries: int, max_retries: int) -> str:\n",
    "    if score >= threshold_v:\n",
    "        return \"pass\"\n",
    "    if retries < max_retries:\n",
    "        return \"retry\"\n",
    "    return \"hitl\"\n",
    "\n",
    "\n",
    "# ---------------- L0 ----------------\n",
    "async def L0_security(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    s = RuntimeSettings()\n",
    "    txt = st.get(\"resume_text\") or \"\"\n",
    "    inj = \"ignore previous instructions\" in txt.lower()\n",
    "    ok = not inj\n",
    "    conf = 0.9 if ok else 0.1\n",
    "    log_attempt(st, layer=\"L0\", agent=\"SanitizeAgent\", tool=\"local.injection_heuristic\", model=None, status=(\"ok\" if ok else \"failed\"), confidence=conf, error=None if ok else \"prompt_injection\")\n",
    "    feed(st, \"L0\", \"SanitizeAgent\", \"Security passed.\" if ok else \"Blocked: prompt injection detected.\")\n",
    "    if not ok:\n",
    "        st[\"status\"] = \"blocked\"\n",
    "        st[\"pending_action\"] = \"security_blocked\"\n",
    "    return st\n",
    "\n",
    "\n",
    "# ---------------- L2 ----------------\n",
    "async def L2_parse(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    parser = ParserAgentService()\n",
    "    txt = st.get(\"resume_text\") or \"\"\n",
    "    prof = parser.parse(raw_text=txt, orchestration_state=None, feedback=[])\n",
    "    st[\"profile\"] = prof.to_json_dict()\n",
    "    log_attempt(st, layer=\"L2\", agent=\"ParserAgent\", tool=\"local.regex_parser\", model=None, status=\"ok\", confidence=0.65, error=None)\n",
    "    feed(st, \"L2\", \"ParserAgent\", \"Intake bundle created.\")\n",
    "    return st\n",
    "\n",
    "\n",
    "async def EVAL_parser(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    prefs = st.get(\"preferences\") or {}\n",
    "    th = float((st.get(\"thresholds\") or {}).get(\"parser\", prefs.get(\"resume_threshold\", 0.70)))\n",
    "    prof = st.get(\"profile\") or {}\n",
    "    skills = len(prof.get(\"skills\") or [])\n",
    "    contact = prof.get(\"contact\") or {}\n",
    "    has_contact = bool(contact.get(\"email\") or contact.get(\"phone\"))\n",
    "    score = min(1.0, 0.35 + (skills / 30.0) + (0.15 if has_contact else 0.0))\n",
    "    fb = []\n",
    "    if not has_contact:\n",
    "        fb.append(\"Missing contact info. Continue, but ATS + recruiter trust improves with email/phone.\")\n",
    "    if skills < 8:\n",
    "        fb.append(\"Skill density low. Add more relevant tools/keywords.\")\n",
    "\n",
    "    retries = int((st.get(\"layer_retry_count\") or {}).get(\"L2\", 0))\n",
    "    decision = gate_decision(score, th, retries, int(st.get(\"max_retries\", 3)))\n",
    "    log_gate(st, layer=\"L2\", target=\"parser\", score=score, threshold_v=th, decision=decision, feedback=fb)\n",
    "\n",
    "    feed(st, \"L3\", \"EvaluatorAgent\", f\"Parser score={score:.2f} decision={decision}\")\n",
    "    if decision == \"hitl\":\n",
    "        st[\"status\"] = \"needs_human_approval\"\n",
    "        st[\"pending_action\"] = \"resume_cleanup_optional\"\n",
    "        st[\"hitl_reason\"] = \"Parser threshold not met\"\n",
    "        st[\"hitl_payload\"] = {\"feedback\": fb, \"score\": score, \"threshold\": th}\n",
    "    elif decision == \"retry\":\n",
    "        inc_retry(st, \"L2\")\n",
    "    return st\n",
    "\n",
    "\n",
    "# ---------------- L3 Discovery (3 tools) ----------------\n",
    "async def L3_discovery(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    s = RuntimeSettings()\n",
    "    prefs = st.get(\"preferences\") or {}\n",
    "    roles = prefs.get(\"target_roles\") or [prefs.get(\"target_role\") or \"Data Scientist\"]\n",
    "    roles = [r.strip() for r in roles if str(r).strip()][:4]\n",
    "    location = str(prefs.get(\"location\",\"United States\"))\n",
    "    visa_req = bool(prefs.get(\"visa_sponsorship_required\", False))\n",
    "    recency_h = float(prefs.get(\"recency_hours\", 36))\n",
    "    tbs = \"qdr:d\" if recency_h <= 36 else None\n",
    "\n",
    "    prof = st.get(\"profile\") or {}\n",
    "    skills_hint = \" \".join((prof.get(\"skills\") or [])[:6])\n",
    "\n",
    "    def build_query(role: str) -> str:\n",
    "        visa_part = '\"visa sponsorship\" OR h1b OR opt OR cpt' if visa_req else \"\"\n",
    "        return f'{role} {location} {skills_hint} ({visa_part}) apply'\n",
    "\n",
    "    queries = [build_query(r) for r in roles]\n",
    "    st[\"discovery_queries\"] = queries\n",
    "\n",
    "    # Tool A: Serper\n",
    "    all_hits: List[Dict[str, Any]] = []\n",
    "    serper_ok = True\n",
    "    for q in queries:\n",
    "        ok, conf, data, err = await serper_search(s, q, num=20, tbs=tbs)\n",
    "        log_attempt(st, layer=\"L3\", agent=\"DiscoveryAgent\", tool=\"serper.search\", model=None,\n",
    "                    status=(\"ok\" if ok and conf >= 0.55 else (\"low_conf\" if ok else \"failed\")),\n",
    "                    confidence=conf, error=err)\n",
    "        if ok:\n",
    "            for it in data:\n",
    "                it[\"query\"] = q\n",
    "                it[\"source\"] = \"serper\"\n",
    "            all_hits.extend(data)\n",
    "        else:\n",
    "            serper_ok = False\n",
    "\n",
    "    # Tool B: MCP fallback\n",
    "    if (not all_hits) or (not serper_ok):\n",
    "        ok2, conf2, data2, err2 = await mcp_invoke(s, \"jobs.search\", {\"queries\": queries, \"recency_hours\": recency_h})\n",
    "        log_attempt(st, layer=\"L3\", agent=\"DiscoveryAgent\", tool=\"mcp.jobs.search\", model=None,\n",
    "                    status=(\"ok\" if ok2 and conf2 >= 0.55 else (\"low_conf\" if ok2 else \"failed\")),\n",
    "                    confidence=conf2, error=err2)\n",
    "        if ok2 and isinstance(data2, dict):\n",
    "            hits = data2.get(\"results\") or data2.get(\"jobs\") or []\n",
    "            for it in hits:\n",
    "                it[\"source\"] = \"mcp\"\n",
    "            all_hits.extend(hits)\n",
    "\n",
    "    # Dedup by link\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for it in all_hits:\n",
    "        link = it.get(\"link\") or it.get(\"url\") or \"\"\n",
    "        if link and link not in seen:\n",
    "            seen.add(link)\n",
    "            # normalize keys\n",
    "            uniq.append({\"title\": it.get(\"title\") or \"\", \"link\": link, \"snippet\": it.get(\"snippet\") or \"\", \"source\": it.get(\"source\") or \"unknown\"})\n",
    "    st[\"jobs_raw\"] = uniq\n",
    "    feed(st, \"L3\", \"DiscoveryAgent\", f\"Found {len(uniq)} unique jobs across boards.\")\n",
    "    return st\n",
    "\n",
    "\n",
    "async def EVAL_discovery(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    prefs = st.get(\"preferences\") or {}\n",
    "    th = float((st.get(\"thresholds\") or {}).get(\"discovery\", prefs.get(\"discovery_threshold\", 0.70)))\n",
    "    n = len(st.get(\"jobs_raw\") or [])\n",
    "    score = 0.2 if n < 8 else (0.6 if n < 20 else 0.85)\n",
    "    fb = []\n",
    "    if n < 20:\n",
    "        fb.append(\"Low job volume after filters. Broaden roles, raise recency window, or loosen visa filter.\")\n",
    "    retries = int((st.get(\"layer_retry_count\") or {}).get(\"L3\", 0))\n",
    "    decision = gate_decision(score, th, retries, int(st.get(\"max_retries\", 3)))\n",
    "    log_gate(st, layer=\"L3\", target=\"discovery\", score=score, threshold_v=th, decision=decision, feedback=fb)\n",
    "    feed(st, \"L5\", \"EvaluatorAgent\", f\"Discovery score={score:.2f} decision={decision}\")\n",
    "    if decision == \"hitl\":\n",
    "        st[\"status\"] = \"needs_human_approval\"\n",
    "        st[\"pending_action\"] = \"discovery_low_confidence\"\n",
    "        st[\"hitl_reason\"] = \"Discovery threshold not met\"\n",
    "        st[\"hitl_payload\"] = {\"feedback\": fb, \"score\": score, \"threshold\": th}\n",
    "    elif decision == \"retry\":\n",
    "        inc_retry(st, \"L3\")\n",
    "    return st\n",
    "\n",
    "\n",
    "# ---------------- L4 Scrape+Match (3 tools scrape + scoring) ----------------\n",
    "async def L4_match(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    s = RuntimeSettings()\n",
    "    prefs = st.get(\"preferences\") or {}\n",
    "    max_jobs = int(prefs.get(\"max_jobs\", 40))\n",
    "    visa_req = bool(prefs.get(\"visa_sponsorship_required\", False))\n",
    "\n",
    "    prof = st.get(\"profile\") or {}\n",
    "    resume_text = st.get(\"resume_text\") or \"\"\n",
    "    resume_skills = [str(x).lower() for x in (prof.get(\"skills\") or [])]\n",
    "    ats = ats_score(resume_text)\n",
    "\n",
    "    exp_text = \"\"\n",
    "    exp = prof.get(\"experience\") or []\n",
    "    if isinstance(exp, list) and exp:\n",
    "        # try bullets\n",
    "        e0 = exp[0] if isinstance(exp[0], dict) else {}\n",
    "        bullets = e0.get(\"bullets\") if isinstance(e0, dict) else []\n",
    "        if isinstance(bullets, list):\n",
    "            exp_text = \" \".join(bullets)\n",
    "    exp_text = exp_text or resume_text\n",
    "    exp_tokens = {}\n",
    "    for t in tokenize(exp_text):\n",
    "        exp_tokens[t] = exp_tokens.get(t, 0) + 1\n",
    "\n",
    "    jobs = (st.get(\"jobs_raw\") or [])[:max_jobs]\n",
    "    scored: List[Dict[str, Any]] = []\n",
    "\n",
    "    for idx, j in enumerate(jobs):\n",
    "        url = j.get(\"link\") or \"\"\n",
    "        snippet = j.get(\"snippet\") or \"\"\n",
    "        title = j.get(\"title\") or \"\"\n",
    "        source = j.get(\"source\") or \"unknown\"\n",
    "\n",
    "        # Tool A: HTTP scrape\n",
    "        ok, conf, data, err = await scrape_http(url)\n",
    "        log_attempt(st, layer=\"L4\", agent=\"ScraperAgent\", tool=\"httpx.scrape\", model=None,\n",
    "                    status=(\"ok\" if ok and conf >= 0.45 else (\"low_conf\" if ok else \"failed\")),\n",
    "                    confidence=conf, error=err)\n",
    "        text = (data or {}).get(\"text\") if ok else \"\"\n",
    "\n",
    "        # Tool B: MCP scrape if low confidence\n",
    "        if (not ok) or conf < 0.45 or not text:\n",
    "            ok2, conf2, data2, err2 = await mcp_invoke(s, \"web.scrape\", {\"url\": url})\n",
    "            log_attempt(st, layer=\"L4\", agent=\"ScraperAgent\", tool=\"mcp.web.scrape\", model=None,\n",
    "                        status=(\"ok\" if ok2 and conf2 >= 0.45 else (\"low_conf\" if ok2 else \"failed\")),\n",
    "                        confidence=conf2, error=err2)\n",
    "            if ok2 and isinstance(data2, dict):\n",
    "                text = data2.get(\"text\") or data2.get(\"content\") or text\n",
    "\n",
    "        text = text or snippet\n",
    "        low = text.lower()\n",
    "        visa_ok = not any(x in low for x in VISA_NEGATIVE)\n",
    "        if visa_req and not visa_ok:\n",
    "            continue\n",
    "\n",
    "        # Score locally (stable & explainable)\n",
    "        matched = [s for s in resume_skills if s and s in low][:30]\n",
    "        skill_overlap = (len(set(matched)) / max(1, len(set(resume_skills)))) if resume_skills else 0.0\n",
    "\n",
    "        job_tokens = {}\n",
    "        for t in tokenize(text):\n",
    "            job_tokens[t] = job_tokens.get(t, 0) + 1\n",
    "        exp_align = cosine(exp_tokens, job_tokens)\n",
    "\n",
    "        market = 1.0\n",
    "        score = compute_interview_chance(skill_overlap, exp_align, ats, market)\n",
    "\n",
    "        # Missing skills heuristic: detect common skill words in JD not in resume_skills\n",
    "        missing = []\n",
    "        for kw in [\"langgraph\",\"mcp\",\"kubernetes\",\"mlflow\",\"dvc\",\"airflow\",\"kafka\",\"terraform\",\"databricks\",\"snowflake\",\"faiss\",\"chroma\"]:\n",
    "            if kw in low and kw not in resume_skills:\n",
    "                missing.append(kw)\n",
    "\n",
    "        scored.append({\n",
    "            \"job_id\": url or f\"job_{idx}\",\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"source\": source,\n",
    "            \"snippet\": snippet,\n",
    "            \"full_text\": text[:8000],\n",
    "            \"visa_ok\": visa_ok,\n",
    "            \"components\": {\n",
    "                \"skill_overlap\": float(skill_overlap),\n",
    "                \"experience_alignment\": float(exp_align),\n",
    "                \"ats_score\": float(ats),\n",
    "                \"market_competition_factor\": float(market),\n",
    "            },\n",
    "            \"missing_skills\": missing[:12],\n",
    "            \"score\": float(score),\n",
    "            \"match_percent\": round(float(score) * 100.0, 2),\n",
    "        })\n",
    "\n",
    "    scored.sort(key=lambda x: float(x[\"score\"]), reverse=True)\n",
    "    st[\"jobs_scored\"] = scored\n",
    "    feed(st, \"L4\", \"MatcherAgent\", f\"Scored {len(scored)} jobs.\")\n",
    "    return st\n",
    "\n",
    "\n",
    "async def EVAL_match(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    prefs = st.get(\"preferences\") or {}\n",
    "    th = float((st.get(\"thresholds\") or {}).get(\"match\", prefs.get(\"discovery_threshold\", 0.70)))\n",
    "    jobs = st.get(\"jobs_scored\") or []\n",
    "    top = float(jobs[0][\"score\"]) if jobs else 0.0\n",
    "    score = top\n",
    "    fb = []\n",
    "    if top < th:\n",
    "        fb.append(\"Top match low. Try alternate role titles or improve resume keyword alignment.\")\n",
    "    retries = int((st.get(\"layer_retry_count\") or {}).get(\"L4\", 0))\n",
    "    decision = gate_decision(score, th, retries, int(st.get(\"max_retries\", 3)))\n",
    "    log_gate(st, layer=\"L4\", target=\"match\", score=score, threshold_v=th, decision=decision, feedback=fb)\n",
    "    feed(st, \"L5\", \"EvaluatorAgent\", f\"Match top={top:.2f} decision={decision}\")\n",
    "    if decision == \"hitl\":\n",
    "        st[\"status\"] = \"needs_human_approval\"\n",
    "        st[\"pending_action\"] = \"review_ranking\"\n",
    "        st[\"hitl_reason\"] = \"Ranking ready or match threshold not met\"\n",
    "        st[\"hitl_payload\"] = {\"feedback\": fb, \"score\": score, \"threshold\": th}\n",
    "    elif decision == \"retry\":\n",
    "        inc_retry(st, \"L4\")\n",
    "    return st\n",
    "\n",
    "\n",
    "# ---------------- L5 Rank + High Interview Potential bypass ----------------\n",
    "async def L5_rank(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    prefs = st.get(\"preferences\") or {}\n",
    "    top_n = int(prefs.get(\"top_n\", 30))\n",
    "    min_accept = float(prefs.get(\"min_match\", 0.50))\n",
    "    jobs = st.get(\"jobs_scored\") or []\n",
    "    if not jobs:\n",
    "        st[\"status\"] = \"needs_human_approval\"\n",
    "        st[\"pending_action\"] = \"no_jobs\"\n",
    "        return st\n",
    "\n",
    "    ranked = []\n",
    "    flagged = []\n",
    "    reasoning_chain = []\n",
    "\n",
    "    for j in jobs[:max(50, top_n)]:\n",
    "        s = float(j[\"score\"])\n",
    "        if s >= min_accept:\n",
    "            ranked.append(j)\n",
    "        else:\n",
    "            text = (j.get(\"full_text\") or \"\").lower()\n",
    "            if any(x in text for x in RARE_SKILL_SIGNALS):\n",
    "                reasoning_chain = [\n",
    "                    f\"Match score {s:.2f} < 0.50, but rare-skill signal detected in job.\",\n",
    "                    \"Rare skills reduce applicant pool and increase interview odds.\",\n",
    "                    \"Bypassing rejection → flagged for HITL review.\"\n",
    "                ]\n",
    "                flagged.append(j)\n",
    "\n",
    "    ranked.sort(key=lambda x: float(x[\"score\"]), reverse=True)\n",
    "    st[\"ranking\"] = ranked[:top_n]\n",
    "    st.setdefault(\"hitl_payload\", {})\n",
    "    st[\"hitl_payload\"][\"flagged_low_score_high_potential\"] = flagged[:20]\n",
    "    st[\"hitl_payload\"][\"reasoning_chain\"] = reasoning_chain\n",
    "\n",
    "    st[\"status\"] = \"needs_human_approval\"\n",
    "    st[\"pending_action\"] = \"review_ranking\"\n",
    "    feed(st, \"L5\", \"Ranker\", f\"Ranking ready: {len(st['ranking'])} jobs. Flagged={len(flagged)}\")\n",
    "    return st\n",
    "\n",
    "\n",
    "# ---------------- Public runners ----------------\n",
    "async def run_full_pipeline(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Run L0->L5 chain, stopping on HITL/blocked.\n",
    "    Layer: L6\n",
    "    \"\"\"\n",
    "    st[\"status\"] = \"running\"\n",
    "    st[\"pending_action\"] = None\n",
    "    feed(st, \"L1\", \"Orchestrator\", \"Automation active: running L0→L5…\")\n",
    "\n",
    "    st = await L0_security(st)\n",
    "    if st.get(\"status\") in (\"blocked\", \"needs_human_approval\"):\n",
    "        return st\n",
    "\n",
    "    st = await L2_parse(st)\n",
    "    st = await EVAL_parser(st)\n",
    "    # parser HITL is OPTIONAL; continue anyway if not blocked\n",
    "    if st.get(\"status\") == \"blocked\":\n",
    "        return st\n",
    "\n",
    "    st = await L3_discovery(st)\n",
    "    st = await EVAL_discovery(st)\n",
    "    if st.get(\"status\") in (\"blocked\", \"needs_human_approval\"):\n",
    "        return st\n",
    "\n",
    "    st = await L4_match(st)\n",
    "    st = await EVAL_match(st)\n",
    "    # If evaluator sets HITL, we stop here and let user approve ranking\n",
    "    if st.get(\"status\") in (\"blocked\", \"needs_human_approval\"):\n",
    "        # If match evaluator didn't set review_ranking, run rank anyway\n",
    "        if st.get(\"pending_action\") not in (\"review_ranking\",):\n",
    "            st = await L5_rank(st)\n",
    "        return st\n",
    "\n",
    "    # Proceed to ranking\n",
    "    st = await L5_rank(st)\n",
    "    return st\n",
    "\n",
    "\n",
    "async def run_single_layer(st: Dict[str, Any], layer: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Execute a single layer (Engineer View).\n",
    "    Layer: L6\n",
    "    \"\"\"\n",
    "    layer = layer.upper()\n",
    "    if layer == \"L0\":\n",
    "        return await L0_security(st)\n",
    "    if layer == \"L2\":\n",
    "        st = await L2_parse(st)\n",
    "        return await EVAL_parser(st)\n",
    "    if layer == \"L3\":\n",
    "        st = await L3_discovery(st)\n",
    "        return await EVAL_discovery(st)\n",
    "    if layer == \"L4\":\n",
    "        st = await L4_match(st)\n",
    "        return await EVAL_match(st)\n",
    "    if layer == \"L5\":\n",
    "        return await L5_rank(st)\n",
    "\n",
    "    feed(st, \"L1\", \"Engineer\", f\"Layer {layer} not implemented in runtime_nodes yet.\")\n",
    "    return st\n",
    "\n",
    "\n",
    "# ---------------- HITL flows ----------------\n",
    "def _runs_dir(run_id: str) -> Path:\n",
    "    d = artifacts_root() / \"runs\" / run_id\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "async def approve_ranking_flow(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: L6 draft generation + L9 bridge docs.\n",
    "    Layer: L6/L9\n",
    "    \"\"\"\n",
    "    run_id = st.get(\"run_id\",\"\")\n",
    "    run_dir = _runs_dir(run_id)\n",
    "    prof = st.get(\"profile\") or {}\n",
    "    ranking = st.get(\"ranking\") or []\n",
    "    top_n = int((st.get(\"preferences\") or {}).get(\"draft_count\", 10))\n",
    "    ranking = ranking[:top_n]\n",
    "\n",
    "    # Base ATS resume template built from intake\n",
    "    name = str(prof.get(\"name\") or \"Candidate\")\n",
    "    contact = prof.get(\"contact\") or {}\n",
    "    email = str(contact.get(\"email\") or \"\")\n",
    "    phone = str(contact.get(\"phone\") or \"\")\n",
    "    linkedin = str(contact.get(\"linkedin\") or \"\")\n",
    "    github = str(contact.get(\"github\") or \"\")\n",
    "    skills = \", \".join((prof.get(\"skills\") or [])[:25])\n",
    "\n",
    "    base_resume = f\"\"\"# {name}\n",
    "{email} | {phone} | {linkedin} | {github}\n",
    "\n",
    "## Summary\n",
    "AI/ML + GenAI builder focused on production-grade delivery (MLOps, evaluation, governance).\n",
    "\n",
    "## Skills\n",
    "{skills}\n",
    "\n",
    "## Experience\n",
    "- Add 4–6 impact bullets per role with metrics, scale, tools, and outcomes.\n",
    "\n",
    "## Education\n",
    "- (from intake)\n",
    "\"\"\"\n",
    "    (run_dir / \"ats_resume_base.md\").write_text(base_resume, encoding=\"utf-8\")\n",
    "    st.setdefault(\"artifacts\", {})\n",
    "    st[\"artifacts\"][\"ats_resume_base\"] = {\"path\": str(run_dir / \"ats_resume_base.md\"), \"content_type\": \"text/markdown\"}\n",
    "\n",
    "    # Draft packages + learning plan\n",
    "    drafts: List[Dict[str, Any]] = []\n",
    "    learning_plan: Dict[str, Any] = {}\n",
    "\n",
    "    settings = RuntimeSettings()\n",
    "\n",
    "    # Reuse Serper for learning links\n",
    "    async def serper_links(skill: str, q: str) -> List[Dict[str, Any]]:\n",
    "        ok, conf, data, err = await serper_search(settings, q, num=3, tbs=None)\n",
    "        if not ok or not data:\n",
    "            return []\n",
    "        return [{\"title\": x.get(\"title\"), \"link\": x.get(\"link\"), \"snippet\": x.get(\"snippet\")} for x in data[:3]]\n",
    "\n",
    "    for j in ranking:\n",
    "        jid = str(j.get(\"job_id\") or j.get(\"url\") or j.get(\"title\"))\n",
    "        title = str(j.get(\"title\") or \"Role\")\n",
    "        company = str(j.get(\"source\") or j.get(\"board\") or \"Company\")\n",
    "        url = str(j.get(\"url\") or \"\")\n",
    "\n",
    "        matched = (j.get(\"matched_skills\") or [])[:12]\n",
    "        missing = (j.get(\"missing_skills\") or [])[:10]\n",
    "\n",
    "        tailored = base_resume + f\"\\n\\n## Target Role Alignment\\n- Target: {title} @ {company}\\n- Matched Keywords: {', '.join(matched)}\\n- Gap Keywords: {', '.join(missing)}\\n\"\n",
    "        resume_path = run_dir / f\"resume_{jid[:10]}.md\"\n",
    "        resume_path.write_text(tailored, encoding=\"utf-8\")\n",
    "\n",
    "        cover = f\"\"\"{name}\n",
    "{email}\n",
    "\n",
    "Dear Hiring Manager,\n",
    "\n",
    "I’m applying for the {title} role. I bring production-grade AI/ML and GenAI experience, including model evaluation, MLOps pipelines, and reliable API deployments.\n",
    "\n",
    "Keywords aligned to this role: {', '.join(matched[:8])}.\n",
    "\n",
    "I’d welcome a conversation about how I can help {company} deliver measurable AI impact.\n",
    "\n",
    "Sincerely,\n",
    "{name}\n",
    "\"\"\"\n",
    "        cover_path = run_dir / f\"cover_{jid[:10]}.md\"\n",
    "        cover_path.write_text(cover, encoding=\"utf-8\")\n",
    "\n",
    "        drafts.append({\n",
    "            \"job_id\": jid,\n",
    "            \"title\": title,\n",
    "            \"company\": company,\n",
    "            \"url\": url,\n",
    "            \"resume_path\": str(resume_path),\n",
    "            \"cover_path\": str(cover_path),\n",
    "            \"missing_skills\": missing,\n",
    "        })\n",
    "\n",
    "        if missing and settings.SERPER_API_KEY:\n",
    "            plan = {}\n",
    "            for sk in missing[:8]:\n",
    "                plan[sk] = {\n",
    "                    \"youtube\": await serper_links(sk, f\"{sk} tutorial youtube\"),\n",
    "                    \"docs\": await serper_links(sk, f\"{sk} official documentation\"),\n",
    "                    \"course\": await serper_links(sk, f\"best course learn {sk}\"),\n",
    "                }\n",
    "            learning_plan[jid] = plan\n",
    "\n",
    "    bundle = {\"drafts\": drafts, \"learning_plan\": learning_plan}\n",
    "    (run_dir / \"drafts_bundle.json\").write_text(json.dumps(bundle, indent=2), encoding=\"utf-8\")\n",
    "    st[\"drafts\"] = bundle\n",
    "    st[\"artifacts\"][\"drafts_bundle\"] = {\"path\": str(run_dir / \"drafts_bundle.json\"), \"content_type\": \"application/json\"}\n",
    "\n",
    "    feed(st, \"L6\", \"DraftAgent\", f\"Generated {len(drafts)} draft packages + learning plans.\")\n",
    "    st[\"status\"] = \"needs_human_approval\"\n",
    "    st[\"pending_action\"] = \"review_drafts\"\n",
    "    return st\n",
    "\n",
    "\n",
    "async def approve_drafts_flow(st: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: L7 apply simulation + mark completed.\n",
    "    Layer: L7\n",
    "    \"\"\"\n",
    "    feed(st, \"L7\", \"ApplyExecutor\", \"Drafts approved. Simulating submissions…\")\n",
    "    st.setdefault(\"meta\", {})\n",
    "    st[\"meta\"].setdefault(\"applied_jobs\", [])\n",
    "    drafts = (st.get(\"drafts\") or {}).get(\"drafts\") or []\n",
    "    for d in drafts[:10]:\n",
    "        st[\"meta\"][\"applied_jobs\"].append({\n",
    "            \"job_id\": d.get(\"job_id\"),\n",
    "            \"title\": d.get(\"title\"),\n",
    "            \"company\": d.get(\"company\"),\n",
    "            \"url\": d.get(\"url\"),\n",
    "            \"status\": \"Applied\",\n",
    "        })\n",
    "    st[\"status\"] = \"completed\"\n",
    "    st[\"pending_action\"] = None\n",
    "    feed(st, \"L9\", \"Analytics\", \"Run completed. Applied jobs recorded.\")\n",
    "    return st\n",
    "''')\n",
    "\n",
    "# ---------- src/careeragent/api/main.py ----------\n",
    "backup_write(\"src/careeragent/api/main.py\", r'''\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from fastapi import FastAPI, File, Form, UploadFile, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "from careeragent.api.request_models import AnalyzeResponse, ActionRequest\n",
    "from careeragent.api.run_manager_service import RunManagerService\n",
    "\n",
    "\n",
    "app = FastAPI(title=\"CareerAgent-AI Brain\", version=\"0.2.0\")\n",
    "\n",
    "# CORS for Streamlit local UI\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "RM = RunManagerService()\n",
    "\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Health endpoint.\n",
    "    Layer: L0\n",
    "    Input: None\n",
    "    Output: status JSON\n",
    "    \"\"\"\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "\n",
    "def _extract_text(filename: str, data: bytes) -> str:\n",
    "    \"\"\"\n",
    "    Description: Extract text from resume file upload.\n",
    "    Layer: L2\n",
    "    Input: filename + bytes\n",
    "    Output: raw text\n",
    "    \"\"\"\n",
    "    name = (filename or \"\").lower()\n",
    "    if name.endswith(\".txt\"):\n",
    "        return data.decode(\"utf-8\", errors=\"replace\")\n",
    "    if name.endswith(\".pdf\"):\n",
    "        try:\n",
    "            from pypdf import PdfReader  # type: ignore\n",
    "            import io\n",
    "            reader = PdfReader(io.BytesIO(data))\n",
    "            return \"\\n\".join([(pg.extract_text() or \"\") for pg in reader.pages])\n",
    "        except Exception:\n",
    "            return data.decode(\"utf-8\", errors=\"replace\")\n",
    "    if name.endswith(\".docx\"):\n",
    "        try:\n",
    "            import docx  # type: ignore\n",
    "            import io\n",
    "            d = docx.Document(io.BytesIO(data))\n",
    "            return \"\\n\".join([p.text for p in d.paragraphs if p.text])\n",
    "        except Exception:\n",
    "            return data.decode(\"utf-8\", errors=\"replace\")\n",
    "    return data.decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "\n",
    "@app.post(\"/analyze\", response_model=AnalyzeResponse)\n",
    "async def analyze(\n",
    "    resume: UploadFile = File(...),\n",
    "    preferences_json: str = Form(...),\n",
    ") -> AnalyzeResponse:\n",
    "    \"\"\"\n",
    "    Description: Start a new run (background pipeline).\n",
    "    Layer: L1-L6\n",
    "    Input: resume upload + preferences_json\n",
    "    Output: run_id + status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prefs = json.loads(preferences_json)\n",
    "    except Exception:\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid preferences_json\")\n",
    "\n",
    "    data = await resume.read()\n",
    "    text = _extract_text(resume.filename or \"resume.txt\", data)\n",
    "\n",
    "    state = RM.create_run(\n",
    "        resume_filename=resume.filename or \"resume.txt\",\n",
    "        resume_text=text,\n",
    "        resume_bytes=data,\n",
    "        preferences=prefs,\n",
    "    )\n",
    "\n",
    "    RM.start_background(state[\"run_id\"])\n",
    "    return AnalyzeResponse(run_id=state[\"run_id\"], status=state[\"status\"])\n",
    "\n",
    "\n",
    "@app.get(\"/status/{run_id}\")\n",
    "def status(run_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Poll run state.\n",
    "    Layer: L8\n",
    "    Input: run_id\n",
    "    Output: full state JSON\n",
    "    \"\"\"\n",
    "    st = RM.get_state(run_id)\n",
    "    if not st:\n",
    "        raise HTTPException(status_code=404, detail=\"run_id not found\")\n",
    "    return st\n",
    "\n",
    "\n",
    "@app.post(\"/action/{run_id}\")\n",
    "async def action(run_id: str, req: ActionRequest) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Description: Handle engineer actions + HITL approvals.\n",
    "    Layer: L5\n",
    "    Input: ActionRequest\n",
    "    Output: updated state\n",
    "    \"\"\"\n",
    "    try:\n",
    "        st = await RM.handle_action(run_id=run_id, action_type=req.action_type, payload=req.payload)\n",
    "        return st\n",
    "    except ValueError:\n",
    "        raise HTTPException(status_code=404, detail=\"run_id not found\")\n",
    "''')\n",
    "\n",
    "print(\"\\n✅ FastAPI /action + background LangGraph-style runtime written.\")\n",
    "print(\"Next: restart backend + UI.\\n\")\n",
    "print(\"Backend:\")\n",
    "print(\"  PYTHONPATH=src uv run python -m uvicorn careeragent.api.main:app --host 127.0.0.1 --port 8000 --reload\")\n",
    "print(\"UI:\")\n",
    "print(\"  API_URL=http://127.0.0.1:8000 PYTHONPATH='.:src' uv run streamlit run app/main.py --server.port 8501\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careeragent-ai (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
