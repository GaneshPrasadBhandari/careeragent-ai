from __future__ import annotations

import json
import math
import re
from collections import Counter
from typing import List, Optional, Tuple

from careeragent.orchestration.state import (
    EvaluationEvent,
    InterviewChanceBreakdown,
    InterviewChanceComponents,
    InterviewChanceWeights,
    OrchestrationState,
)
from careeragent.agents.parser_agent_service import ExtractedResume


class ParserEvaluatorService:
    """Description: L3 evaluator for the L2 Parser output (Recursive Gate twin).
    Layer: L3
    Input: ExtractedResume + raw_text + OrchestrationState
    Output: EvaluationEvent (score + feedback + InterviewChanceBreakdown)
    """

    HEADING_HINTS = ("skills", "experience", "education", "summary")
    BULLET_RE = re.compile(r"^\s*[-â€¢*]\s+", re.M)

    def evaluate(
        self,
        *,
        orchestration_state: OrchestrationState,
        raw_text: str,
        extracted: ExtractedResume,
        target_id: str,
        threshold: float = 0.80,
        retry_count: int = 0,
        max_retries: int = 3,
    ) -> EvaluationEvent:
        """Description: Evaluate parsing quality and generate gate feedback.
        Layer: L3
        Input: state + raw_text + extracted resume
        Output: EvaluationEvent appended to OrchestrationState
        """
        # --- JSON validity (should always pass due to Pydantic, but keep explicit)
        try:
            json.dumps(extracted.to_json_dict())
            json_ok = 1.0
        except Exception:
            json_ok = 0.0

        completeness, completeness_fb = self._completeness_score(extracted)
        ats_score, ats_fb = self._ats_score(orchestration_state, raw_text, extracted)

        # Primary evaluation score: completeness + ATS density + JSON sanity
        evaluation_score = max(
            0.0,
            min(
                1.0,
                (0.50 * completeness) + (0.45 * ats_score) + (0.05 * json_ok),
            ),
        )

        feedback = []
        feedback.extend(completeness_fb)
        feedback.extend(ats_fb)

        # InterviewChance breakdown using your deterministic weighted formula
        interview = self._interview_chance_breakdown(orchestration_state, raw_text, extracted)

        ev = orchestration_state.record_evaluation(
            layer_id="L3",
            target_id=target_id,
            generator_agent="parser_agent_service",
            evaluator_agent="parser_evaluator_service",
            evaluation_score=evaluation_score,
            threshold=threshold,
            feedback=feedback,
            retry_count=retry_count,
            max_retries=max_retries,
            interview_chance=interview,
        )
        return ev

    # ---------------- scoring internals ----------------

    def _completeness_score(self, extracted: ExtractedResume) -> Tuple[float, List[str]]:
        """Description: Score completeness of extracted fields.
        Layer: L3
        Input: ExtractedResume
        Output: (score, feedback)
        """
        fb: List[str] = []
        s = 0.0

        has_email = bool(extracted.contact.email)
        has_phone_or_links = bool(extracted.contact.phone) or bool(extracted.contact.links)
        has_contact = has_email and has_phone_or_links

        if has_contact:
            s += 0.40
        else:
            fb.append("Contact completeness low: include email + phone (or a professional link like LinkedIn/GitHub).")

        if extracted.skills:
            s += 0.35
        else:
            fb.append("Skills missing/empty: add a dedicated 'Skills' section with role-relevant keywords.")

        if extracted.experience and any(x.bullets for x in extracted.experience):
            s += 0.25
        else:
            fb.append("Experience section weak: add bullet points with measurable impact (metrics, scope, tools).")

        return max(0.0, min(1.0, s)), fb

    def _ats_score(
        self,
        orchestration_state: OrchestrationState,
        raw_text: str,
        extracted: ExtractedResume,
    ) -> Tuple[float, List[str]]:
        """Description: Compute ATS-oriented structure & keyword density score.
        Layer: L3
        Input: raw_text + extracted + state meta
        Output: (ats_score, feedback)
        """
        fb: List[str] = []
        t = (raw_text or "").lower()

        # Headings presence (structure)
        heading_hits = sum(1 for h in self.HEADING_HINTS if h in t)
        heading_score = min(1.0, heading_hits / 3.0)
        if heading_score < 0.67:
            fb.append("ATS structure: use standard headings exactly (Summary, Skills, Experience, Education).")

        # Bullet density
        bullet_hits = len(self.BULLET_RE.findall(raw_text or ""))
        bullet_score = min(1.0, bullet_hits / 8.0)
        if bullet_score < 0.5:
            fb.append("ATS formatting: use more bullet points under Experience to improve scanability.")

        # Keyword richness: overlap with target role keywords (if provided)
        target_keywords = orchestration_state.meta.get("target_role_keywords")
        target_set = set([k.strip().lower() for k in target_keywords]) if isinstance(target_keywords, list) else set()

        skills_set = set([s.strip().lower() for s in extracted.skills])
        overlap = len(skills_set.intersection(target_set)) if target_set else 0
        keyword_score = min(1.0, overlap / max(8, len(target_set) or 8))
        if target_set and keyword_score < 0.5:
            missing = sorted(list(target_set.difference(skills_set)))[:8]
            fb.append(f"Keyword density low: consider adding relevant skills (if true): {', '.join(missing)}.")

        # final ATS score (bounded)
        ats_score = max(0.0, min(1.0, (0.40 * heading_score) + (0.30 * bullet_score) + (0.30 * keyword_score)))
        return ats_score, fb

    def _interview_chance_breakdown(
        self,
        orchestration_state: OrchestrationState,
        raw_text: str,
        extracted: ExtractedResume,
    ) -> InterviewChanceBreakdown:
        """Description: Compute Interview Chance Score breakdown deterministically.
        Layer: L4
        Input: state meta + extracted resume
        Output: InterviewChanceBreakdown (score in [0,1])
        """
        target_keywords = orchestration_state.meta.get("target_role_keywords")
        target_set = set([k.strip().lower() for k in target_keywords]) if isinstance(target_keywords, list) else set()

        skills_set = set([s.strip().lower() for s in extracted.skills])

        # SkillOverlap: set-based math of keywords
        skill_overlap = 0.0
        if target_set:
            skill_overlap = len(skills_set.intersection(target_set)) / max(1, len(target_set))
            skill_overlap = max(0.0, min(1.0, float(skill_overlap)))

        # ExperienceAlignment: cosine similarity between resume experience text and target requirements text
        req_text = orchestration_state.meta.get("target_requirements_text")
        req_text = str(req_text) if req_text else ""
        exp_text = " ".join([" ".join(x.bullets) for x in extracted.experience if x and x.bullets])

        experience_alignment = self._cosine_sim(exp_text, req_text)

        # ATS_Score: structural check (proxy from headings/bullets/contact)
        ats_proxy, _ = self._ats_score(orchestration_state, raw_text, extracted)

        # MarketCompetitionFactor: penalty factor >= 1.0
        mcf = orchestration_state.meta.get("market_competition_factor", 1.0)
        try:
            mcf = float(mcf)
        except Exception:
            mcf = 1.0
        mcf = max(1.0, mcf)

        weights = InterviewChanceWeights(
            w1_skill_overlap=float(orchestration_state.meta.get("w1_skill_overlap", 0.45)),
            w2_experience_alignment=float(orchestration_state.meta.get("w2_experience_alignment", 0.35)),
            w3_ats_score=float(orchestration_state.meta.get("w3_ats_score", 0.20)),
        )

        components = InterviewChanceComponents(
            skill_overlap=skill_overlap,
            experience_alignment=experience_alignment,
            ats_score=ats_proxy,
            market_competition_factor=mcf,
        )

        return InterviewChanceBreakdown(weights=weights, components=components)

    @staticmethod
    def _cosine_sim(a: str, b: str) -> float:
        """Description: Lightweight cosine similarity for ExperienceAlignment without extra deps.
        Layer: L4
        Input: two strings
        Output: similarity in [0,1]
        """
        a = (a or "").lower().strip()
        b = (b or "").lower().strip()
        if not a or not b:
            return 0.0

        def toks(s: str) -> List[str]:
            return [t for t in re.split(r"[^a-z0-9\+\.#]+", s) if t and len(t) > 1]

        ca = Counter(toks(a))
        cb = Counter(toks(b))

        common = set(ca).intersection(set(cb))
        dot = sum(ca[t] * cb[t] for t in common)
        na = math.sqrt(sum(v * v for v in ca.values()))
        nb = math.sqrt(sum(v * v for v in cb.values()))
        if na == 0.0 or nb == 0.0:
            return 0.0
        sim = dot / (na * nb)
        return max(0.0, min(1.0, float(sim)))
